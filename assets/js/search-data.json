{
  
    
        "post0": {
            "title": "Lecture 5, Heat transports",
            "content": "import xarray as xr import numpy as np import matplotlib.pyplot as plt from ipywidgets import interact, interactive, fixed, interact_manual import ipywidgets as widgets from IPython.display import HTML from IPython.display import display . 1) Background: two-dimensional advection-diffusion . 1.1) The two-dimensional advection-diffusion equation . Recall from Lecture 5 that the one-dimensional advection-diffusion equation is written as . $$ frac{ partial T(x,t)}{ partial t} = -U frac{ partial T}{ partial x} + kappa frac{ partial^{2} T}{ partial x^{2}},$$ . where $T(x, t)$ is the temperature, $U$ is a constant advective velocity and $ kappa$ is the diffusivity. . The two-dimensional advection diffusion equation simply adds advection and diffusion operators acting in a second dimensions $y$ (orthogonal to $x$). . $$ frac{ partial T(x,y,t)}{ partial t} = u(x,y) frac{ partial T}{ partial x} + v(x,y) frac{ partial T}{ partial y} + kappa left( frac{ partial^{2} T}{ partial x^{2}} + frac{ partial^{2} T}{ partial y^{2}} right),$$ . where $ vec{u}(x,y) = (u, v) = u , mathbf{ hat{x}} + v , mathbf{ hat{y}}$ is a velocity vector field. . Throughout the rest of the Climate Modelling module, we will consider $x$ to be the longitundinal direction (positive from west to east) and $y$ to the be the latitudinal direction (positive from south to north). . 1.2) Multivariable shorthand notation . Conventionally, the two-dimensional advection-diffusion equation is written more succintly as . $$ frac{ partial T(x,y,t)}{ partial t} = - vec{u} cdot nabla T + kappa nabla^{2} T,$$ . using the following shorthand notation. . The gradient operator is defined as . $ nabla equiv ( frac{ partial}{ partial x}, frac{ partial }{ partial y})$ . such that . $ nabla T = ( frac{ partial T}{ partial x}, frac{ partial T}{ partial y})$ and . $ vec{u} cdot nabla T = (u, v) cdot ( frac{ partial T}{ partial x}, frac{ partial T}{ partial y}) = u frac{ partial T}{ partial x} + v frac{ partial T}{ partial y}.$ . The Laplacian operator $ nabla^{2}$ (sometimes denoted $ Delta$) is defined as . $ nabla^{2} = frac{ partial^{2}}{ partial x^{2}} + frac{ partial^{2}}{ partial y^{2}}$ . such that . $ nabla^{2} T = frac{ partial^{2} T}{ partial x^{2}} + frac{ partial^{2} T}{ partial y^{2}}.$ . The divergence operator is defined as $ nabla cdot [ quad]$, such that . $ nabla cdot vec{u} = left( frac{ partial}{ partial x}, frac{ partial}{ partial x} right) cdot (u,v) = frac{ partial u}{ partial x} + frac{ partial v}{ partial y}.$ . Note: Since seawater is largely incompressible, we can approximate ocean currents as a non-divergent flow, with $ nabla cdot vec{u} = frac{ partial u}{ partial x} + frac{ partial v}{ partial y} = 0$. Among other implications, this allows us to write: . begin{align} vec{u} cdot nabla T&amp;= u frac{ partial T(x,y,t)}{ partial x} + v frac{ partial T(x,y,t)}{ partial y} newline &amp;= u frac{ partial T}{ partial x} + v frac{ partial T}{ partial y} + T left( frac{ partial u}{ partial x} + frac{ partial v}{ partial y} right) newline &amp;= left( u frac{ partial T}{ partial x} + T frac{ partial u}{ partial x} right) + left( v frac{ partial T}{ partial y} + frac{ partial v}{ partial y} right) newline &amp;= frac{ partial (uT)}{ partial x} + frac{ partial (vT)}{ partial x} newline &amp;= nabla cdot ( vec{u}T) end{align}using the product rule (separately in both $x$ and $y$). . 1.3) The flux-form two-dimensional advection-diffusion equation . This lets us finally re-write the two-dimensional advection-diffusion equation as: . $ frac{ partial T}{ partial t} = - nabla cdot ( vec{u}T) + kappa nabla^{2} T$ . which is the form we will use in our numerical algorithm below. . 2) Numerical implementation . 2.1) Discretizing advection in two dimensions . In Lecture XX we saw that in one dimension we can discretize a first-partial derivative in space using the centered finite difference . $$ frac{ partial T(x_{i}, t_{n})}{ partial x} approx frac{T_{i+1}^{n} - T_{i-1}^{n}}{2 Delta x}.$$ . In two dimensions, we discretize the partial derivative the exact same way, except that we also need to keep track of the cell index $j$ in the $y$ dimension: . $$ frac{ partial T(x_{i}, y_{j}, t_{n})}{ partial x} approx frac{T_{i+1, , j}^{n} - T_{i-1, ,j}^{n}}{2 Delta x}.$$ . The x-gradient kernel below, implemented using the OffsetArray type, is shown below, and is reminiscent of the edge-detection or sharpening kernels used in image processing and machine learning: . plt.imshow([[-1,0,1]], cmap=plt.cm.RdBu_r) plt.xticks([0,1,2], labels=[-1,0,1]); plt.yticks([]); . The first-order partial derivative in $y$ is similarly discretized as: . $$ frac{ partial T(x_{i}, y_{j}, t_{n})}{ partial y} approx frac{T_{i, , j+1}^{n} - T_{i, ,j-1}^{n}}{2 Delta y}.$$ . Its kernel is shown below. . plt.imshow([[-1,-1],[0,0],[1,1]], cmap=plt.cm.RdBu); plt.xticks([]); plt.yticks([0,1,2], labels=[1,0,-1]); . Now that we have discretized the two derivate terms, we can write out the advective tendency for computing $T_{i, j, n+1}$ as . $$u frac{ partial T}{ partial x} + v frac{ partial T}{ partial y} approx u_{i, , j}^{n} frac{T_{i, , j+1}^{n} - T_{i, ,j-1}^{n}}{2 Delta y} + v_{i, , j}^{n} frac{T_{i, , j+1}^{n} - T_{i, ,j-1}^{n}}{2 Delta y}.$$ . We implement this in julia as a series of methods for the advect function. The first method computes the advective tendency (as a single Float64 type) for the $(i,j)$ grid cell while the second method returns an array of the tendencies for each grid cell using two nested for loops. . xkernel = np.zeros((1, 3)) xkernel[0, :] = np.array([-1,0,1]) . ykernel = np.zeros((3,1)) ykernel[:, 0] = np.array([-1,0,1]) . class OceanModel(): def __init__(T, u, v, deltay, deltax): self.T = T self.u = u self.v = v self.deltay = deltay self.deltax = deltax self.i = np.arange(0, len(T.shape[1])) self.j = np.arange(0, len(T.shape[0])) def advect(self, T, u, v, deltay, deltax, j, i): T_advect = np.zeros((T.shape[0], T.shape[1])) for j in range(1, T_advect.shape[0] - 1): for i in range(1, T_advect.shape[1] - 1): T_advect[j, i] = -(u[j, i] * np.sum(xkernel[0, :] * T[j, i-1:i+1])/(2*deltax) + v[j, i] * np.sum(ykernel[:, 0] * T[j-1:j+1, i])/(2*deltax)) . 2.3) No-flux boundary conditions . We want to impose the no-flux boundary conditions, which states that . $$u frac{ partial T}{ partial x} = kappa frac{ partial T}{ partial x} = 0$$at $x$ boundaries and . $$v frac{ partial T}{ partial y} = kappa frac{ partial T}{ partial y} = 0$$at the $y$ boundaries. . To impose this, we treat $i=1$ and $i=N_{x}$ as ghost cells, which do not do anything expect help us impose these boundaries conditions. Discretely, the boundary fluxes between $i=1$ and $i=2$ vanish if . $$ dfrac{T_{2, ,j}^{n} -T_{1, ,j}^{n}}{ Delta x} = 0$$or . $$T_{1, ,j}^{n} = T_{2, ,j}^{n}.$$ . Thus, we can implement the boundary conditions by updating the temperature of the ghost cells to match their interior-point neighbors: . 2.2) Discretizing diffusion in two dimensions . Just as with advection, the process for discretizing the diffusion operators effectively consists of repeating the one-dimensional process for $x$ in a second dimension $y$, separately: . $$ kappa left( frac{ partial^{2} T}{ partial x^{2}} + frac{ partial^{2} T}{ partial y^{2}} right) = kappa left( frac{T_{i+1, ;j}^{n} - 2T_{i, ;j}^{n} + T_{i-1, ;j}^{n}}{ left( Delta x right)^{2}} + frac{T_{i, ;j+1}^{n} - 2T_{i, ;j}^{n} + T_{i, ;j-1}^{n}}{ left( Delta y right)^{2}} right)$$The corresponding $x$ and $y$ second-derivative kernels are shown below: . plt.imshow([[1,1],[0,0],[1,1]], cmap=plt.cm.RdBu_r); plt.xticks([]); plt.yticks([0,1,2], labels=[1,-1,1]); . plt.imshow([[1,0,1]], cmap=plt.cm.RdBu_r); plt.xticks([0,1,2], labels=[1,-1,1]); plt.yticks([]); . Just as we did with advection, we implement a diffuse function using multiple dispatch: . xkernel_diff = np.zeros((1, 3)) xkernel_diff[0, :] = np.array([1,-2,1]) . ykernel_diff = np.zeros((3,1)) ykernel_diff[:, 0] = np.array([1,-2,1]) . class OceanModel(): def __init__(T, u, v, deltay, deltax): self.T = T self.u = u self.v = v self.deltay = deltay self.deltax = deltax self.i = np.arange(0, len(T.shape[1])) self.j = np.arange(0, len(T.shape[0])) def advect(self, T, u, v, deltay, deltax, j, i): T_advect = np.zeros((T.shape[0], T.shape[1])) for j in range(2, T_advect.shape[0] - 1): for i in range(2, T_advect.shape[1] - 1): T_advect[j, i] = -(u[j, i] * np.sum(xkernel[0, :] * T[j, i-1:i+1])/(2*deltax) + v[j, i] * np.sum(ykernel[:, 0] * T[j-1:j+1, i])/(2*deltax)) def diffuse(self): T_diffuse= np.zeros((self.j.shape, self.i.shape)) for j in range(self.j[1], self.j[-2]): for i in range(self.i[1], self.i[-2]): T_diffuse[j, i] = -(self.u[j, i] * np.sum(xkernel_diff[0, :] * T[j, i-1:i+1])/(self.deltax**2) + self.v [j, i] * np.sum(ykernel_diff[:, 0] * T[j-1:j+1, i])/(self.deltay**2)) . 2.3) No-flux boundary conditions . We want to impose the no-flux boundary conditions, which states that . $$u frac{ partial T}{ partial x} = kappa frac{ partial T}{ partial x} = 0$$at $x$ boundaries and . $$v frac{ partial T}{ partial y} = kappa frac{ partial T}{ partial y} = 0$$at the $y$ boundaries. . To impose this, we treat $i=1$ and $i=N_{x}$ as ghost cells, which do not do anything expect help us impose these boundaries conditions. Discretely, the boundary fluxes between $i=1$ and $i=2$ vanish if . $$ dfrac{T_{2, ,j}^{n} -T_{1, ,j}^{n}}{ Delta x} = 0$$or . $$T_{1, ,j}^{n} = T_{2, ,j}^{n}.$$ . Thus, we can implement the boundary conditions by updating the temperature of the ghost cells to match their interior-point neighbors: . def update_ghostcells(var, option=&quot;no-flux&quot;): A = var.copy() if option == &quot;no-flux&quot;: A[0, :] = A[1, :] A[:, 0] = A[:, 1] A[-1, :] = A[-2, :] A[:, -1] = A[:, -2] return A . B = np.random.rand(6,6) plt.pcolor(B) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7fe8fe80a8b0&gt; . plt.imshow(update_ghostcells(B)) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7fe8fe7b45b0&gt; . 2.4) Timestepping . class OceanModel(): def __init__(self, T, deltat, windfield, grid, kappa): self.T = [T] self.u = windfield.u self.v = windfield.v self.deltay = grid.deltay self.deltax = grid.deltax self.deltat = deltat self.kappa = kappa self.i = np.arange(0, self.T[0].shape[1]) self.j = np.arange(0, self.T[0].shape[0]) self.t = [0] self.diffuse_out = [] self.advect_out = [] self.t_ = [] def advect(self, T): T_advect = np.zeros((self.j.size, self.i.size)) for j in range(1, T_advect.shape[0] - 1): for i in range(1, T_advect.shape[1] - 1): T_advect[j, i] = -(self.u[j, i] * np.sum(xkernel[0, :] * T[j, i-1:i+2])/(2*self.deltax) + self.v[j, i] * np.sum(ykernel[:, 0] * T[j-1:j+2, i])/(2*self.deltax)) return T_advect def diffuse(self, T): T_diffuse= np.zeros((self.j.size, self.i.size)) for j in range(1, T_diffuse.shape[0] - 1): for i in range(1, T_diffuse.shape[1] - 1): T_diffuse[j, i] = self.kappa*(np.sum(xkernel_diff[0, :] * T[j, i-1:i+2])/(self.deltax**2) + np.sum(ykernel_diff[:, 0] * T[j-1:j+2, i])/(self.deltay**2)) return T_diffuse def timestep(self): T_ = self.T[-1].copy() T_ = update_ghostcells(T_) tendencies = self.advect(self.T[-1]) + self.diffuse(self.T[-1]) self.diffuse_out.append(self.diffuse(self.T[-1])) self.advect_out.append(self.advect(self.T[-1])) T_ = self.deltat * tendencies self.T.append(self.T[-1] + T_) self.t.append(self.t[-1] + self.deltat) . class grid: def __init__(self, N, L): self.deltax = L / N self.deltay = L / N self.xs = np.arange(0-self.deltax/2, L+self.deltax/2, self.deltax) self.ys = np.arange(-L-self.deltay/2, L+self.deltay/2, self.deltay) self.N = N self.L = L self.Nx = len(self.xs) self.Ny = len(self.ys) self.grid, _= np.meshgrid(self.ys, self.xs, sparse=False, indexing=&#39;ij&#39;) class windfield: def __init__(self, grid, option = &quot;zero&quot;): if option == &quot;zero&quot;: self.u = np.zeros((grid.grid.shape)) self.v = np.zeros((grid.grid.shape)) if option == &quot;single_gyre&quot;: u, v = PointVortex(my_grid) self.u = u self.v = v . my_grid = grid(10, 6e6) my_wind = windfield(my_grid) my_temp = np.zeros((my_grid.grid.shape)) my_temp[7:13, 3:8] = 1 . plt.pcolor(my_temp) plt.colorbar() plt.ylabel(&quot;Kilometers Latitude&quot;) . Text(0, 0.5, &#39;Kilometers Latitude&#39;) . deltat = 12*60*60 # 12 Hourse . my_model = OceanModel(T=my_temp, deltat=deltat, windfield=my_wind, grid=my_grid, kappa = 1e4) . def plot_func(my_model, steps): my_model = OceanModel(T=my_temp, deltat=deltat, windfield=my_wind, grid=my_grid, kappa = 1e4) for step in range(steps): my_model.timestep() plt.figure(figsize=(8,8)) plt.pcolor(my_model.T[-1], vmin = 0, vmax = 1) plt.colorbar() plt.title(&quot;{}&quot;.format(step/2)) plt.show() . interact(plot_func, my_model = fixed(my_model), steps = widgets.IntSlider(description=&quot;Timesteps&quot;, value = 1, min = 1, max = 10000, step = 1)); . def plot_func(my_model, steps): my_model = OceanModel(T=my_temp, deltat=deltat, windfield=my_wind, grid=my_grid, kappa = 1e4) for step in range(steps): my_model.timestep() plt.figure(figsize=(8,8)) plt.pcolor(my_model.T[-1] - my_model.T[-2], cmap = plt.cm.RdBu_r, vmin = -0.002, vmax = 0.002) plt.colorbar() plt.title(&quot;{}&quot;.format(step/2)) plt.show() . interact(plot_func, my_model = fixed(my_model), steps = widgets.IntSlider(description=&quot;Timesteps&quot;, value = 1, min = 1, max = 1000, step = 1)); . def diagnose_velocities(stream, G): dx = np.zeros((G.grid.shape)) dy = np.zeros((G.grid.shape)) dx = (stream[:, 1:] - stream[:, 0:-1])/G.deltax dy = (stream[1:, :] - stream[0:-1, :])/G.deltay u = np.zeros((G.grid.shape)) v = np.zeros((G.grid.shape)) u = 0.5*(dy[:, 1:] + dy[:, 0:-1]) v = -0.5*(dx[1:, :] + dx[0:-1, :]) return u, v . def impose_no_flux(u, v): u[0, :] = 0; v[0, :] = 0; u[-1,:] = 0; v[-1,:] = 0; u[:, 0] = 0; v[:, 0] = 0; u[:,-1] = 0; v[:,-1] = 0; return u, v . def PointVortex(G, omega = 0.5, a = 0.2, x0=0.5, y0 = 0.): x = np.arange(-G.deltax/G.L, 1 + G.deltax / G.L, G.deltax / G.L).reshape(1, -1) y = np.arange(-1-G.deltay/G.L, 1+ G.deltay / G.L, G.deltay / G.L).reshape(-1, 1) x = x[:,:-1] r = np.sqrt((y - y0)**2 + (x - x0)**2) stream = -omega/4*r**2 stream[r &gt; a] = -omega*a**2/4*(1. + 2*np.log(r[r &gt; a]/a)) u, v = diagnose_velocities(stream, G) # u = (0.1/1e3)/(2e-11*G.L*1000) * u; v = (0.1/1e3)/(2e-11*G.L*1000) * v u, v = impose_no_flux(u, v) u = u * G.L; v = v * G.L return u, v . (0.1/1e3)/(2e-11*6000000.0*1000) . 0.0008333333333333334 . my_wind = windfield(my_grid, option=&quot;single_gyre&quot;) plt.pcolor(my_wind.u) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7fe8fe964730&gt; . my_temp = np.zeros((my_grid.grid.shape)) my_temp[8:13, :] = 1 . my_model = OceanModel(T=my_temp, deltat=deltat, windfield=my_wind, grid=my_grid, kappa = 1e4) . my_model.timestep() . plt.contourf(my_model.advect_out[0]) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7fe8fe337130&gt; . def plot_func(my_model, steps): my_model = OceanModel(T=my_temp, deltat=deltat, windfield=my_wind, grid=my_grid, kappa = 1e4) for step in range(steps): my_model.timestep() plt.figure(figsize=(8,8)) plt.pcolor(my_model.T[-1], vmin = 0, vmax = 1) plt.quiver(my_wind.u, my_wind.v) plt.colorbar() plt.title(&quot;{}&quot;.format(step/2)) plt.show() . my_wind.v.shape my_wind.u.shape my_grid.grid.shape . (21, 11) . interact(plot_func, my_model = fixed(my_model), steps = widgets.IntSlider(description=&quot;Timesteps&quot;, value = 1, min = 1, max = 1000, step = 1)); . u, v = PointVortex(my_grid) u, v = u[1:], v[1:] . my_grid.grid.shape . (21, 11) . print(u.shape) . (20, 11) . epsilon = 0.05 xpsi = np.arange(-deltax, 1+deltax, deltax) ypsi = np.arange(-1-deltay, 1+deltay, deltay) def psihat(x, y): psi = np.zeros((x.size, y.size)) np.psi . NameError Traceback (most recent call last) &lt;ipython-input-40-9a1e6cb481da&gt; in &lt;module&gt; 1 epsilon = 0.05 -&gt; 2 xpsi = np.arange(-deltax, 1+deltax, deltax) 3 ypsi = np.arange(-1-deltay, 1+deltay, deltay) 4 5 def psihat(x, y): NameError: name &#39;deltax&#39; is not defined . psi = np.zeros((ypsi.size, xpsi.size)) for i, x in enumerate(xpsi): for j, y in enumerate(ypsi): psi[j, i] = np.pi * np.sin(np.pi * y) * ( 1 - x - np.exp(-x/(2*epsilon)) * (np.cos(np.sqrt(3)*x/(2*epsilon)) + (1 / np.sqrt(3)) * np.sin(np.sqrt(3)*x/(2*epsilon)))+epsilon*np.exp((x-1)/epsilon)) . plt.pcolor(psi) plt.colorbar() . np.pi * np.sin(np.pi * y) * ( 1 - x - np.exp(-x/(2*epsilon)) * (np.cos(np.sqrt(3)*x/(2*epsilon)) + (1 / np.sqrt(3)) * np.sin(np.sqrt(3)*x/(2*epsilon)))+epsilon*np.exp((x-1)/epsilon)) .",
            "url": "https://florianboergel.github.io/personal_blog/2020/12/02/heat-transport.html",
            "relUrl": "/2020/12/02/heat-transport.html",
            "date": " • Dec 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Lecture 5, Evolution in time and space, Advection and diffusion in 1D",
            "content": "import xarray as xr import numpy as np import matplotlib.pyplot as plt from ipywidgets import interact, interactive, fixed, interact_manual import ipywidgets as widgets from IPython.display import HTML from IPython.display import display . Evolution in time and space: Advection and diffusion in 1D . So far we have been looking at dynamics in time, for example how does the temperature of the Earth change over time. But the Earth does not have a single, uniform temperature; rather, at a particular moment in time, different places on Earth are at different temperatures, and those different temperatures change over time due to several mechanisms. . In this notebook we will look at two fundamental mechanisms: advection and diffusion. Let&#39;s think about the temperature in the ocean. Since the ocean is a fluid that is in motion, a warm &quot;parcel&quot; of water can flow (move) to a new location due to the physical motion of the water itself; this is advection. And even if the water doesn&#39;t move, temperature or a higher concentration of some substance dissolved in the fluid can spread out due to molecular mechanisms; this is diffusion. . In this notebook we will restrict ourselves to 1 space dimension. So we will think about the temperature $T$, for example, being a function $$T(t, x)$$ of . time: $t$ | space: $x$ | . We want to calculate a value of the temperature $T$ at each point $(t, x)$. . Temperature profiles and discretization . An ordinary differential equation needs an initial value for each variable. Similarly, we will need an initial function $T_0(x)$ that gives us the temperature at each position $x$. Let&#39;s suppose that the position is restricted to the interval $[0, L_x]$. . As usual, to represent the continuous function $T_0(x)$ on a computer, we will need to discretise it in some way, i.e. approximate the continuous function by a finite set of numbers in the computer. . The simplest (but far from the only!) discretisation method is to sample the function at discrete grid points (or nodes) $x_i$, for $i = 1, dots, N_x$. For simplicity we will take these equally spaced, with spacing $x_{i+1} - x_i =: delta x := L_x / N_x$. . For example, let&#39;s consider an initial temperature profile given by a sine curve: . def t0(x): return np.sin(2*np.pi * x) . and define the grid points as follows: . Nx = 20 Lx = 1.0 deltax = Lx / Nx xs = np.arange(0.025, Lx, deltax) . It turns out to be a good idea to take the grid points at the centre of each interval, so that we have $N_x$ intervals and $N_x$ grid points, starting at $x_1 = delta x/2$ and finishing at $x_N = L_x - delta x / 2$. . We call such a function of $x$ at a given time a temperature profile. Let&#39;s draw it as a function and as a heatmap: . t = np.arange(0,Lx, 0.001) plt.plot(t, t0(t), label = &quot;$T_0$&quot;, lw = 3, alpha = 0.5) plt.scatter(xs, t0(xs), label = &quot;sampled&quot;, color = &quot;orange&quot;) plt.scatter(xs, np.zeros((xs.size)), color =&quot;green&quot;, label = &quot;x nodes&quot;) plt.hlines(0,xmin=0, xmax = Lx, color = &quot;black&quot;, ls = &quot;--&quot;, lw = 0.5) for x in xs: plt.plot([x, x], [0, t0(x)], color = &quot;black&quot;, ls = &quot;--&quot;, lw = 0.5) plt.xlabel(&quot;x&quot;) plt.ylabel(&quot;$T_0$&quot;) plt.grid() plt.legend() . &lt;matplotlib.legend.Legend at 0x7fc1ae139430&gt; . We will denote by $T^0_i$ the initial temperature at grid point number $i$. . A useful way to think about $T^n_i$ is as the (spatial) average of $T(t_n, x)$ over the interval of positions between neighbouring grid points, so $T_i$ is the average over the interval between $x_i - frac{ delta x}{2}$ and $x_i + frac{ delta x}{2}$. We can thus think of the following piecewise constant approximation to the original continuous function: . t = np.arange(0, Lx, 0.001) plt.plot(t, t0(t), label = &quot;$T_0$&quot;, lw = 3, alpha = 0.5) plt.scatter(xs, t0(xs), label = &quot;sampled&quot;, color = &quot;orange&quot;) plt.scatter(xs, np.zeros((xs.size)), color =&quot;green&quot;, label = &quot;x nodes&quot;, alpha = 0.5) plt.hlines(0,xmin=0, xmax = Lx, color = &quot;black&quot;, ls = &quot;--&quot;, lw = 0.5) for x in xs: plt.plot([x, x], [0, t0(x)], color = &quot;black&quot;, ls = &quot;--&quot;, lw = 0.5) plt.xlabel(&quot;x&quot;) plt.hlines(t0(x), xmin = x-deltax/2, xmax = x+deltax/2, color = &quot;green&quot;) plt.vlines(x-deltax/2, ymin=0, ymax=t0(x), color = &quot;green&quot;, alpha = 0.5, ls=&quot;--&quot;, lw = 1) plt.vlines(x+deltax/2, ymin=0, ymax=t0(x), color = &quot;green&quot;, alpha = 0.5, ls=&quot;--&quot;, lw = 1) plt.ylabel(&quot;$T_0$&quot;) plt.grid() plt.legend() . &lt;matplotlib.legend.Legend at 0x7fc1ae03a2b0&gt; . Advection . Now let&#39;s think of this as the temperature in a fluid, and let&#39;s suppose that the fluid is moving to the right with a constant, uniform speed $U$. (Uniform here means that the speed is the same in all parts of the fluid.) Then the temperature profile should also move with the fluid. We call a quantity, such as the temperature, that is carried along with the fluid a tracer. . If we fix our attention at a single point in space, say the grid point $x_i$, the temperature there will vary over time due to the motion of the fluid. How it varies in time depends on the values at neighbouring grid points, since they determine how much heat will be transported into the current cell. . Let&#39;s think about a time-stepping algorithm, and let $ delta t$ be the duration of a time step. We&#39;ll denote by $T^n_i$ the approximate value of $T$ to calculate at position $x_i$ and at the $n$th time step $t_n$, i.e. an approximation of $T(t_n, x_i)$, where $t_n = n , delta t$. For example, $T^{n+1}_i simeq T(t_n + delta t, x_i)$ and $T^{n}_{i+1} simeq T(t_n, x_i + delta x)$. . Note that the superscript $n$ in these algorithms does not denote a power; it&#39;s just a label for the time step. We could write $T_i^{(n)}$ instead, but that is annoying to both write and read, so we suppress the parentheses. . Suppose the fluid is moving to the right with speed $U$. During a time step of duration $ delta t$, the temperature $T^n_i$ at cell $i$ changes due to the amount of heat that leaves cell $i$, and the amount that enters that cell. Most of the fluid that starts within cell $i$ remains within that cell during the time step (if the time step is short enough). Only fluid that is within a distance $U , delta t$ from the boundary of the cell will cross over that cell. So a proportion $(U , delta t) / delta x$ of the amount in cell $i$ crosses the boundary. . Hence, roughly an amount $T^n_i (U delta t) / delta x$ will leave cell number $i$ and cross into cell $i+1$ (the cell to the right). Similarly, an amount $T^n_{i-1} (U delta t) / delta x$ will enter cell $i$ from the neighbouring cell $i-1$ on the left. Hence we have $$T^{n+1}_i = T^{n}_i + (T^n_{i-1} - T^n_{i}) , U , delta t / delta x.$$ . Thus $$ frac{T^{n+1}_i - T^{n}_i}{ delta t} = frac{T^n_{i-1} - T^n_{i}}{ delta x} , U.$$ . Taking the continuum limit when $ delta t to 0$ and $ delta x to 0$, we recognise the definition of partial derivatives with respect to time and space variables from multivariable calculus. (Note the different indices that change on the two sides of the equation.) Denoting these partial derivatives using $ partial$, we arrive at the advection equation: $$ frac{ partial T(t, x)}{ partial t} = -U frac{ partial T(t, x)}{ partial x},$$ or for short $$ frac{ partial T}{ partial t} = -U frac{ partial T}{ partial x}.$$ Since $T$ is a function of both $x$ and $t$, and this equation involves partial derivatives with respect to both of the independent variables, this is a partial differential equation (PDE). It describes how the function $T(t, x)$ changes continuously as a function both of time and space. Although there are some analytical methods to solve PDEs, often it&#39;s necessary to use numerical methods. Here we&#39;ll look at simple numerical methods to solve such equations. . Numerics for the advection equation . Let&#39;s return to the version of the equation in which the value at the following time step is isolated: $$T^{n+1}_i = T^{n}_i - left( U frac{ delta t}{ delta x} right) (T^n_{i} - T^n_{i-1}).$$ In the last term on the right-hand side, we see that we require combinations of values of $T$ at the same time step from different places, with certain coefficients. . There are many approaches to implementing this numerically. The simplest is to directly transcribe the equation for the $i$th entry of the vector. Calling T the current vector, i.e. $ mathbf{T}^n := (T^n_i)_{i=1, ldots, N_x}$, and T′ the new vector at the next time step, we have the following basic expression: . T′[i] = T[i] + δt U (T[i-1] - T[i]) / δx . But now we realise a problem:What should we do when $i=0$? This will try to access the index -1 of the vector T, which does not exist! This illustrates the necessity of choosing boundary conditions that specify what happens at the edge of the domain. For simplicity we will choose to use periodic boundary conditions. This is a convenient mathematical fiction that allows us to treat all cells as being on the same footing, by wrapping the system around a torus, so that cells $i=0$ and $i=N_x$ are neighbours. . We can then write this as follows, where we separate out the case $i=0$: . def advection(T, deltat, deltax, U): N = len(T) T2 = T.copy() for i in range(1, N): T2[i] = T[i] - deltat * U * (T[i]-T[i-1]) / deltax T2[0] = T[0] - deltat * U * (T[0]-T[-1]) / deltax return T2 . We use a function plot_func that carries out a generic time evolution. This is basically the Euler method again, except now we apply it to a vector of values at different points in space at each step. . deltat = 0.001 U = 0.2 initcondition = t0(xs) . def plot_func(function, deltat, U, xs, steps, T0 = initcondition): T = T0.copy() deltax = xs[1] - xs[0] for step in range(steps): T = function(T, deltat, deltax, U) plt.figure(figsize=(8,8)) plt.plot(xs, T) plt.scatter(xs,T) plt.title(&quot;{}&quot;.format(step*deltat)) plt.xlabel(&quot;t&quot;) plt.ylabel(&quot;x(t)&quot;) plt.ylim([-1,1]) plt.grid() plt.tight_layout() plt.show() . interact(plot_func, function = fixed(advection), steps = widgets.IntSlider(description=&quot;Timesteps&quot;, value = 1, min = 1, max = 10000, step = 1), deltat = fixed(deltat), #widgets.FloatSlider(description = &quot;$ Delta t$&quot;,value = 0.001, min = 0.0001, max = 0.01, step = 0.0001, readout_format=&#39;.4f&#39;), U = fixed(U), xs = fixed(xs), T0 = fixed(advection(initcondition, deltat, xs[0], U))); . Unfortunately this does not behave as we expect: instead of preserving the shape of the profile over time, it is decaying. This is due to the way we are approximating. A better way to discretize the spatial derivative is using the following centered difference: $$ frac{ partial T(t_n, x_i)}{ partial x} simeq frac{T^n_{i+1} - T^n_{i-1}}{2 delta x}$$ . def advection2(T, deltat, deltax, U): N = len(T) T2 = T.copy() for i in range(1, N-1): T2[i] = T[i] - deltat * U * (T[i+1]-T[i-1]) / (2*deltax) T2[0] = T[0] - deltat * U * (T[1]-T[-1]) / (2*deltax) T2[-1] = T[-1] - deltat * U * (T[0]-T[-2]) / (2*deltax) return T2 . interact(plot_func, function = fixed(advection2), steps = widgets.IntSlider(description=&quot;Timesteps&quot;, value = 1, min = 1, max = 10000, step = 1), deltat = fixed(deltat),#widgets.FloatSlider(description = &quot;$ Delta t$&quot;,value = 0.001, min = 0.0001, max = 0.01, step = 0.0001, readout_format=&#39;.4f&#39;), U = fixed(U), xs = fixed(xs), T0 = fixed(advection(initcondition, deltat, xs[0], U))); . Diffusion . Another key physical process is diffusion. This models how temperature or mass spreads out from hot or high concentration regions towards regions where it is cold or where there is a low concentration. The PDE describing this is the heat equation, or diffusion equation: . $$ frac{ partial T}{ partial t} = D frac{ partial^2 T}{ partial x^2}.$$ . To obtain a numerical method to solve this equation, we again need to discretise this, in particular the second derivative. One possible discretisation is $$ frac{ partial^2 T}{ partial x^2}(t_n, x_i) simeq frac{T^n_{i+1} - 2 T^n_i + T^n_{i-1}}{ delta x^2}.$$ . This may again be transcribed directly into code: . def diffusion(T, deltat, deltax, D): N = len(T) T2 = T.copy() for i in range(1, N-1): T2[i] = T[i] + deltat * D * (T[i+1]-2*T[i] + T[i-1]) / (deltax**2) T2[0] = T[0] + deltat * D * (T[1]-2*T[0] + T[-1]) / (deltax**2) T2[N-1] = T[N-1] + deltat * D * (T[0]-2*T[N-1] + T[N-2]) / (deltax**2) return T2 . interact(plot_func, function = fixed(diffusion), steps = widgets.IntSlider(description=&quot;Timesteps&quot;, value = 1, min = 1, max = 10000, step = 1), deltat = fixed(deltat),#widgets.FloatSlider(description = &quot;$ Delta t$&quot;,value = 0.001, min = 0.0001, max = 0.01, step = 0.0001, readout_format=&#39;.4f&#39;), U = fixed(0.01), xs = fixed(xs), T0 = fixed(advection(initcondition, deltat, xs[0], U))); . Advection--diffusion . Finally we can combine both mechanisms, to describe a tracer that is both being advected at a constant speed and diffusing. This basically utilises the composition of the advection and diffusion functions: . def advection_diffusion(T, deltat, deltax, U): D = 0.01 temp = advection2(T, deltat, deltax, U) return diffusion(temp, deltat, deltax, D) . interact(plot_func, function = fixed(advection_diffusion), steps = widgets.IntSlider(description=&quot;Timesteps&quot;, value = 1, min = 1, max = 10000, step = 1), deltat = fixed(deltat),#widgets.FloatSlider(description = &quot;$ Delta t$&quot;,value = 0.001, min = 0.0001, max = 0.01, step = 0.0001, readout_format=&#39;.4f&#39;), U = fixed(0.2), xs = fixed(xs), T0 = fixed(advection(initcondition, deltat, xs[0], U))); .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/12/01/advection-diffusion.html",
            "relUrl": "/jupyter/2020/12/01/advection-diffusion.html",
            "date": " • Dec 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Exercise 2, melting the snowball earth",
            "content": "In the last lectures we implemented a energy balance model. The energy balance equation is give by . begin{gather} color{brown}{C frac{dT}{dt}} ; color{black}{=} ; color{orange}{ frac{(1 - α)S}{4}} ; color{black}{-} ; color{blue}{(A - BT)} ; color{black}{+} ; color{grey}{a ln left( frac{[ text{CO}₂]}{[ text{CO}₂]_{ text{PI}}} right)}, end{gather}Recall that in the last lecture we implemented a simplied ice albedo feedback by allowing the albedo to depend on temperature: . $$ alpha(T) = begin{cases} alpha_{i} &amp; mbox{if } ; ; T leq -10 text{°C} &amp; text{(completely frozen)} alpha_{i} + ( alpha_{0}- alpha_{i}) frac{T + 10}{20} &amp; mbox{if } ; ; -10 text{°C} leq T leq 10 text{°C} &amp; text{(partially frozen)} alpha_{0} &amp; mbox{if } ; ; T geq 10 text{°C} &amp; text{(no ice)} end{cases}$$ One thing that we did not adress in the last lecture was the impact of CO$_2$ increase. We simply set: . $ ln left( frac{ [ text{CO}₂]_{ text{PI}} }{[ text{CO}₂]_{ text{PI}}} right) = ln(1) = 0$ . We then evaluated how an increasing solar constant changes the equalibirum temperature on earth. In this excercise you keep $S$ at $1368 W/m^2$ and instead increase the $CO_2$ concentration. . Replot the bifurcations diagramm for $CO_2$ increase instead of solar radiation. . import numpy as np import xarray as xr import matplotlib.pyplot as plt from ipywidgets import interact, interactive, fixed, interact_manual import ipywidgets as widgets from IPython.display import HTML from IPython.display import display from energy_balance_model import ebm . def CO2_change(t): return 280 + co2 . Note that co2 is a global variable here. In general all variables that are assigned in a function call are private (only accessible within the function). However, if this variable is not defined within the function, python looks for a global variable that is called co2 (in your complete code). Therefore, remember to increase co2 for the following task. . Start by running the model for with different C02 concentrations and plot the equlibrium temperature. . Hint: You can copy nearly all code from the Lecture Snowball earth . plt.figure(figsize = (8,6)) plt.plot(co2vec[0:len(co2vec)//2], tvec[0:len(co2vec)//2], color = &quot;blue&quot;, label = &quot;cool branch&quot;, alpha = 0.3) plt.plot(co2vec[len(co2vec)//2:], tvec[len(co2vec)//2:], color = &quot;red&quot;, label = &quot;warm branch&quot;, alpha = 0.3) plt.axvline(1368, color = &quot;yellow&quot;, lw = 5, alpha = 0.2, label = &quot;Pre-industiral / present insolation&quot;) plt.plot(420, 14, marker=&quot;o&quot;, label=&quot;Our preindustrial climate&quot;, color=&quot;orange&quot;, markersize=8) plt.plot(420, -38, marker=&quot;o&quot;, label=&quot;Alternate preindustrial climate&quot;, color=&quot;lightblue&quot;, markersize=8) plt.plot(280, -48, marker=&quot;o&quot;, label=&quot;neoproterozoic (700 Mya)&quot;, color=&quot;lightgrey&quot;, markersize=8) plt.xlabel(&quot;CO$_2$ concentration [ppm]&quot;) plt.ylabel(&quot;Global temperature T [°C]&quot;) plt.legend() plt.grid() .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/15/climate-of-the-ocean-h2.html",
            "relUrl": "/jupyter/2020/11/15/climate-of-the-ocean-h2.html",
            "date": " • Nov 15, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Exercise 1, policy goals under uncertainty",
            "content": "Exercise 1, policy goals under uncertainty . A recent ground-breaking review paper produced the most comprehensive and up-to-date estimate of the climate feedback parameter, which they find to be . $B approx mathcal{N}(-1.3, 0.4),$ . i.e. our knowledge of the real value is normally distributed with a mean value $ overline{B} = -1.3$ W/m²/K and a standard deviation $ sigma = 0.4$ W/m²/K. These values are not very intuitive, so let us convert them into more policy-relevant numbers. . Definition: Equilibrium climate sensitivity (ECS) is defined as the amount of warming $ Delta T$ caused by a doubling of CO₂ (e.g. from the pre-industrial value 280 ppm to 560 ppm), at equilibrium. . At equilibrium, the energy balance model equation is: . $0 = frac{S(1 - α)}{4} - (A - BT_{eq}) + a ln left( frac{2 ; text{CO}₂_{ text{PI}}}{ text{CO}₂_{ text{PI}}} right)$ . From this, we subtract the preindustrial energy balance, which is given by: . $0 = frac{S(1-α)}{4} - (A - BT_{0}),$ . The result of this subtraction, after rearranging, is our definition of $ text{ECS}$: . $ text{ECS} equiv T_{eq} - T_{0} = - frac{a ln(2)}{B}$ . import xarray as xr import numpy as np import matplotlib.pyplot as plt from energy_balance_model import ebm . . def double_CO2(t): return 280 * 2 . f, ax = plt.subplots(1) EBM = ebm(14, 0, 1., double_CO2) EBM.run(300) ax.plot(EBM.t, EBM.T - EBM.T[0], label = &quot;$ Delta T (t) = T(t) - T_0$&quot;, color = &quot;red&quot;) ax.axhline(ecs(EBM.B, EBM.a), label = &quot;ECS&quot;, color = &quot;darkred&quot;, ls = &quot;--&quot;) ax.legend() ax.grid() ax.set_title(&quot;Transient response to instant doubling of CO$_2$&quot;) ax.set_ylabel(&quot;temperature [°C]&quot;) ax.set_xlabel(&quot;years after doubling&quot;) . The plot above provides an example of an &quot;abrupt 2xCO$_2$&quot; experiment, a classic experimental treatment method in climate modelling which is used in practice to estimate ECS for a particular model (Note: in complicated climate models the values of the parameters $a$ and $B$ are not specified a priori, but emerge as outputs for the simulation). . The simulation begins at the preindustrial equilibrium, i.e. a temperature °C is in balance with the pre-industrial CO$_2$ concentration of 280 ppm until CO$_2$ is abruptly doubled from 280 ppm to 560 ppm. The climate responds by rapidly warming, and after a few hundred years approaches the equilibrium climate sensitivity value, by definition. . # calculate the range from -2 to -0.1 with 0.1 as a step size # Note use plt.scatter for plotting and . Question: . (1) What does it mean for a climate system to have a more negative value of $B$? Explain why we call $B$ the climate feedback parameter. . Answer: . (2) What happens when $B$ is greater than or equal to zero? . Answer: . Exercise 1.2 - Doubling CO&#8322; . To compute ECS, we doubled the CO₂ in our atmosphere. This factor 2 is not entirely arbitrary: without substantial effort to reduce CO₂ emissions, we are expected to at least double the CO₂ in our atmosphere by 2100. . Right now, our CO₂ concentration is 415 ppm -- 1.482 times the pre-industrial value of 280 ppm from 1850. . The CO₂ concentrations in the future depend on human action. There are several models for future concentrations, which are formed by assuming different policy scenarios. A baseline model is RCP8.5 - a &quot;worst-case&quot; high-emissions scenario. In our notebook, this model is given as a function of t. . def CO2_RCP85(t): return 280 * (1+ ((t-1850)/220)**3 * np.maximum(1., np.exp(((t-1850)-170)/100))) . t = np.arange(1850, 2100) plt.ylabel(&quot;CO$_2$ concentration [ppm]&quot;) plt.plot(t, CO2_RCP85(t)); . Question: . In what year are we expected to have doubled the CO₂ concentration, under policy scenario RCP8.5? . Hint: the function . np.where() . might be useful . . Answer: . Exercise 1.3 - Uncertainty in B . The climate feedback parameter B is not something that we can control– it is an emergent property of the global climate system. Unfortunately, B is also difficult to quantify empirically (the relevant processes are difficult or impossible to observe directly), so there remains uncertainty as to its exact value. . A value of B close to zero means that an increase in CO₂ concentrations will have a larger impact on global warming, and that more action is needed to stay below a maximum temperature. In answering such policy-related question, we need to take the uncertainty in B into account. In this exercise, we will do so using a Monte Carlo simulation: we generate a sample of values for B, and use these values in our analysis. . Generate a probability distribution for for $B_{avg}$ above. Plot a histogram. . Hint: use the functions . np.random.normal() # with 50000 samples . and plot with . plt.hist() . sigma = 0.4 b_avg = -1.3 samples = # Enter code here . plt.xlabel(&quot;B [W/m²/K]&quot;) plt.ylabel(&quot;samples&quot;) . Generate a probability distribution for the ECS based on the probability distribution function for $B$ above. . values = # your code here . values = np.where((values &lt; -20) | (values &gt; 20) , np.nan, values) # drop outlier plt.hist(values, bins = 20) plt.xlim([0, 20]) plt.xlabel(&quot;Temperature [°C]&quot;) . It looks like the ECS distribution is not normally distributed, even though $B$ is. . Question: How does $ overline{ text{ECS}(B)}$ compare to $ text{ECS}( overline{B})$? What is the probability that $ text{ECS}(B)$ lies above $ text{ECS}( overline{B})$? . . Question: Does accounting for uncertainty in feedbacks make our expectation of global warming better (less implied warming) or worse (more implied warming)? . Answer: . Exercise 1.5 - Running the model . In the lecture notebook we introduced a class ebm (energy balance model), which contains: . the parameters of our climate simulation (C, a, A, B, CO2_PI, alpha, S, see details below) | a function CO2, which maps a time t to the concentrations at that year. For example, we use the function t -&gt; 280 to simulate a model with concentrations fixed at 280 ppm. | . ebm also contains the simulation results, in two arrays: . T is the array of tempartures (°C, Float64). | t is the array of timestamps (years, Float64), of the same size as T. | . You can set up an instance of ebm like so: . def my_co2function(t): # here we imply NO co2 increase return 280 my_model = ebm(T=14, t=0, deltat=1., CO2=my_co2function) . my_model . Let&#39;s look into our ebm object . attrs = vars(my_model) print(&#39;, n&#39;.join(&quot;%s: %s&quot; % item for item in attrs.items())) . What function do we have? . help(my_model) . EBM = ebm(14, 1850, 1, my_co2function) EBM.run(10) . Again, look inside simulated_model and notice that T and t have accumulated the simulation results. . In this simulation, we used T0 = 14 and CO2 = 280, which is why T is constant during our simulation. These parameters are the default, pre-industrial values, and our model is based on this equilibrium. . Question: Run a simulation starting at 1850 with policy scenario RCP8.5, and plot the computed temperature graph. What is the global temperature at 2100? . def CO2_RCP85(t): return 280 * (1+ ((t-1850)/220)**3 * np.maximum(1., np.exp(((t-1850)-170)/100))) . . We can change values before running the model. . EBM = ebm(15, 1850, 1, my_co2function) EBM.B = -2 EBM.run(10) . EBM.T . Exercise 1.6 - Application to policy relevant questions (BONUS) . We talked about two emissions scenarios: RCP2.6 (strong mitigation - controlled CO2 concentrations) and RCP8.5 (no mitigation - high CO2 concentrations). These are given by the following functions . def CO2_RCP26(t): return 280 * (1+ ((t-1850)/220)**3 * np.minimum(1., np.exp(-((t-1850)-170)/100))) def CO2_RCP85(t): return 280 * (1+ ((t-1850)/220)**3 * np.maximum(1., np.exp(((t-1850)-170)/100))) . We are interested in how the uncertainty in our input $B$ (the climate feedback paramter) propagates through our model to determine the uncertainty in our output $T(t)$, for a given emissions scenario. The goal of this exercise is to answer the following by using Monte Carlo Simulation for uncertainty propagation: . What is the probability that we see more than 2°C of warming by 2100 under the low-emissions scenario RCP2.6? What about under the high-emissions scenario RCP8.5? .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/14/climate-of-the-ocean-h1.html",
            "relUrl": "/jupyter/2020/11/14/climate-of-the-ocean-h1.html",
            "date": " • Nov 14, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Lecture 4, Snowball Earth, the ice-albedo feedback, and multiple equilibria",
            "content": "Thanks a lot to Henri Drake for providing the lecture. . The original lecture is part of the MIT class Introduction to Computational Thinking. . This class uses the Julia programming language. The orignal code can be found under https://github.com/hdrake/simplEarth/blob/master/2_ebm_multiple_equilibria.jl . Snowball Earth, the ice-albedo feedback, and multiple equilibria . Source (New York Times) . Review of Lecture 2 . Recall from the last Lecture that the zero-dimensional energy balance equation is . begin{gather} color{brown}{C frac{dT}{dt}} ; color{black}{=} ; color{orange}{ frac{(1 - α)S}{4}} ; color{black}{-} ; color{blue}{(A - BT)} ; color{black}{+} ; color{grey}{a ln left( frac{[ text{CO}₂]}{[ text{CO}₂]_{ text{PI}}} right)}, end{gather} . Today, we will ignore changes in CO$_2$, so that . $ ln left( frac{ [ text{CO}₂]_{ text{PI}} }{[ text{CO}₂]_{ text{PI}}} right) = ln(1) = 0$ . and the model simplifies to . begin{gather} color{brown}{C frac{dT}{dt}} ; color{black}{=} ; color{orange}{ frac{(1 - α)S}{4}} ; color{black}{-} ; color{blue}{(A - BT)}. end{gather}The dynamics of this Ordinary Differential Equation (ODE) are quite simple because it is linear: we can rewrite it in the form . $$ dot{T} = f(T(t))$$ . where . $$f(x) = alpha x + beta$$ . is a linear function of x. A linear ODE permits only one stable solution, $ dot{T} = 0$, which in Lecture 1 we found was Earth&#39;s pre-industrial temperature $T_{0} = 14$°C. . In this lecture, we show how a small modification that makes one term in our simple climate model non-linear completely changes its dynamics, allowing us to explain the existence of both &quot;Snowball Earth&quot; and the relatively warm pre-industrial climate that allowed humans to thrive. . import numpy as np import xarray as xr import matplotlib.pyplot as plt from ipywidgets import interact, interactive, fixed, interact_manual import ipywidgets as widgets from IPython.display import HTML from IPython.display import display . 1) Background: Snowball Earth . Geological evidence shows that the Neoproterozoic Era (550 to 1000 million years ago) is marked by two global glaciation events, in which Earth&#39;s surface was covered in ice and snow from the Equator to the poles (see review by Pierrehumbert et al. 2011. . . 1.1) The ice-albedo feedback . In Lecture 1, we used a constant value $α = 0.3$ for Earth&#39;s planetary albedo, which is a reasonable thing to do for small climate variations relative to the present (such as the difference between the present-day and preindustrial climates). In the case of large variations, however, this approximation is not very reliable. . While oceans are dark and absorbant, $α_{ocean} approx 0.05$, ice and snow are bright and reflective: $ alpha_{ice, ,snow} approx 0.5$ to $0.9$. Thus, if much of the ocean&#39;s surface freezes over, we expect Earth&#39;s albedo to rise dramatically, causing more sunlight to be reflected to space, which in turn causes even more cooling and more of the ocean to freeze, etc. This non-linear positive feedback effect is referred to as the ice-albedo feedback (see illustration below). . . We can represent the ice-albedo feedback crudely in our energy balance model by allowing the albedo to depend on temperature: . $$ alpha(T) = begin{cases} alpha_{i} &amp; mbox{if } ; ; T leq -10 text{°C} &amp; text{(completely frozen)} alpha_{i} + ( alpha_{0}- alpha_{i}) frac{T + 10}{20} &amp; mbox{if } ; ; -10 text{°C} leq T leq 10 text{°C} &amp; text{(partially frozen)} alpha_{0} &amp; mbox{if } ; ; T geq 10 text{°C} &amp; text{(no ice)} end{cases}$$ 1.2) Adding the ice-albedo feedback to our simple climate model . First, we program albedo as a function of temperature. . def calc_alpha(T, alpha0, alphai = 0.5, deltaT=10.): if T &lt; - deltaT: return alphai elif -deltaT &lt;= T &lt; deltaT: return alphai + (alpha0 - alphai)*(T + deltaT) / (2*deltaT) elif T &gt;= deltaT: return alpha0 . calc_alpha_vec = np.vectorize(calc_alpha) # boolean evaluations need to be vectorized T_example = np.arange(-20, 20) plt.plot(T_example, calc_alpha_vec(T_example[:], 0.3), color = &quot;black&quot;) plt.ylim(0.2,0.6) plt.plot([-20, -10], [0.2, 0.2]) plt.fill_between([-20, -10], y1=0.2, y2=0.6, color = &quot;lightblue&quot;, alpha = 0.2) plt.fill_between([10, 20], y1=0.2, y2=0.6, color = &quot;red&quot;, alpha = 0.12) plt.ylabel(&quot;albedo $α$ n(planetary reflectivity)&quot;) plt.xlabel(&quot;Temperature [°C]&quot;) plt.text(-18.5, 0.252, s=&quot;completely nfrozen&quot;, size=10, color=&quot;darkblue&quot;) plt.text(-3, 0.252, s=&quot;partiall frozen&quot;, size=10, color=&quot;darkgrey&quot;) plt.text(13, 0.252, s=&quot;no ice&quot;, size=10, color=&quot;darkred&quot;) . Text(13, 0.252, &#39;no ice&#39;) . To add this function into our energy balance model from Lecture 1 (which we&#39;ve copied into the cell below), all we have to do is overwrite the definition of the timestep! method to specify that the temperature-dependent albedo should be updated based on the current state: . class ebm(): &quot;&quot;&quot; Zero order energy balance model &quot;&quot;&quot; def __init__(self, T, t, deltat, CO2): self.T = np.array(T) self.t = t self.deltat = deltat self.C = 51. self.a = 5. self.B = -1.3 self.co2_pi = 280. self.alpha = 0.3 self.S = 1368. self.co2 = CO2 self.CO2_PI = 280. self.A = 221.2 def absorbed_solar_radiation(self): return (self.S*(1-self.alpha2)/4.) # [W/m^2] def outgoing_thermal_radiation(self): if self.T.size == 1: return self.A - self.B*self.T else: return self.A - self.B*self.T[-1] def greenhouse_effect(self): if self.T.size == 1: return self.a*np.log(self.co2(self.t)/self.CO2_PI) else: return self.a*np.log(self.co2(self.t[-1])/self.CO2_PI) def tendency(self): if self.T.size == 1: return 1. / self.C * ( + self.absorbed_solar_radiation() - self.outgoing_thermal_radiation() + self.greenhouse_effect() ) else: return 1. / self.C * ( + self.absorbed_solar_radiation() - self.outgoing_thermal_radiation() + self.greenhouse_effect() ) def run(self, end_year): for year in range(end_year): self.timestep() def timestep(self): if self.T.size == 1: self.alpha2 = calc_alpha(self.T, alpha0=self.alpha) # Added the function call here self.T = np.append(self.T, self.T + self.deltat * self.tendency()) self.t = np.append(self.t, self.t + self.deltat) else: self.alpha2 = calc_alpha(self.T[-1], alpha0=self.alpha) # Added the function call here self.T = np.append(self.T, self.T[-1] + self.deltat * self.tendency()) self.t = np.append(self.t, self.t[-1] + self.deltat) . 2) Multiple Equilibria . OR: the existence of &quot;alternate Earths&quot; . Human civilization flourished over the last several thousand years in part because Earth&#39;s global climate has been remarkably stable and forgiving. The preindustrial combination of natural greenhouse effect and incoming solar radiation yielded temperatures between the freezing and boiling points of water across most of the planet, allowing ecoystems based on liquid water to thrive. . The climate system, however, is rife with non-linear effects like the ice-albedo effect, which reveal just how fragile our habitable planet is and just how unique our stable pre-industrial climate was. . We learned in the last lecture that in response to temperature fluctuations, net-negative feedbacks act to restore Earth&#39;s temperature back towards a single equilibrium state in which absorbed solar radiation is balanced by outgoing thermal radiation. Here, we explore how non-linear positive feedbacks can temporarily result in a net-positive feedback and modify Earth&#39;s state space. . def CO2_const(t): # define CO2 scenario return 280 . f, (ax) = plt.subplots(1, figsize = (8,8)) for count, T0_sample in enumerate(range(-60, 30, 5)): EBM = ebm(T0_sample, 0, 1., CO2_const) EBM.run(200) ax.plot(EBM.t, EBM.T) ax.set_xlabel(&quot;year&quot;) ax.set_ylabel(&quot;Temperature [°C]&quot;) ax.set_ylim(-60,30) ax.text(120,-25, s=&quot;Completly frozen&quot;, size = 10, color = &quot;darkblue&quot;) ax.fill_between([0, 200], y1=-60, y2=-10, color = &quot;lightblue&quot;, alpha = 0.2) ax.fill_between([0, 200], y1=10, y2=30, alpha=0.09, color=&quot;red&quot;) ax.text(120,20, s=&quot;no ice&quot;, size = 10, color = &quot;darkred&quot;) T_un = 7.5472 deltaTs = 1e-2*np.array([-2, -1., 0., 1., 2.]) for deltaT in deltaTs: ebm_un = ebm(T_un+deltaT, 0., 1, CO2_const) ebm_un.run(200) ax.plot(ebm_un.t, ebm_un.T, ls = &quot;--&quot;) ax.grid() ax.plot(200, 14, marker=&quot;o&quot;, label=&quot;Our pre-industrial climate (stable &#39;&#39;warm&#39;&#39; branch)&quot;, color=&quot;orange&quot;, markersize=8) ax.plot(200, -38.3, marker=&quot;o&quot;, label=&quot;Alternate universe pre-industrial climate (stable &#39;&#39;cold&#39;&#39; branch)&quot;, color=&quot;aqua&quot;, markersize=8) ax.plot(200, T_un, marker=&quot;o&quot;, label=&quot;Impossible alternate climate (unstable branch&quot;, color=&quot;lightgrey&quot;, markersize=8) ax.legend(loc=4) . &lt;matplotlib.legend.Legend at 0x7efe0f539eb0&gt; . We see that for T₀ ⪆ 7.55 °C, all of the curves seem to converge on the T = 14°C equilibrium (or fixed point) that we saw in Lecture 20. Curves that start below this value warm up and while curves that start above this value will cool down. For T₀ ⪅ 7.55 °C, however, the temperatures converge on a much colder equilibrium around T = -40°C. This is the Snowball Earth equilibrium. These two states are referred to as stable equilibria because even if the state gets temporarily pushed slightly away from its equilibrium, it will eventually converge right back to its equilibrium. . So what happens is T₀ ≈ 7.55 °C? For some exact temperature near there, there is indeed an equilibrim state: if you start with that temperature you will stay there forever. However, if the temperature starts off even one one-hundredth of a degree above or below this exact value, we see that temperatures eventually converge to one of the other two equilibria. Thus, we call this intermediate equilibrium an unstable equilibrium, because any infinitesimal push away will cause it to careen away towards another state. . Excourse: . Nonlinear dynamics: stability and bifurcations | . https://github.com/mitmath/18S191/blob/master/lecture_notebooks/week11/nonlinear_dynamics_bifurcations.jl . 2.2) Radiative stability analysis . We can understand why our model has two stable equilibria and one unstable equilibrium by applying concepts from dynamical systems theory. . Recall that, with fixed CO₂ concentrations, our energy balance model differential equation can be expressed as: . $$C frac{dT}{dT} = ASR(T) - OTR(T)$$ . where now the Absorbed Solar Radiatio (ASR) is also temperature dependent because the albedeo $ alpha (T)$ is. . In particular, by plotting the right-hand-side tendency terms as a function of the state variable $T$, we can plot a stability diagram for our system that tells us whether the plan will warm ($C frac{dT}{dt}$ &gt; 0) or cool ($C frac{dT}{dt}$ &lt; 0) . EBM = ebm(T_un, 0., 1, CO2_const) temp_range = np.arange(-60, 30) OTR, ASR = np.zeros((len(temp_range))), np.zeros((len(temp_range))) for count, i in enumerate(temp_range): EBM.T = np.array(i) EBM.alpha2 = calc_alpha(EBM.T, EBM.alpha) OTR[count] = EBM.outgoing_thermal_radiation() ASR[count] = EBM.absorbed_solar_radiation() imbalance = ASR - OTR . f, (ax, bx) = plt.subplots(1,2, figsize=(8,4)) ax.plot(temp_range, OTR, label= &quot;Outgoing Thermal Radiation&quot;) ax.plot(temp_range, ASR, label = &quot;Absorbed Solar Radiation&quot;) ax.set_xlabel(&quot;temperature [°C]&quot;) ax.set_ylabel(&quot;energy flux [W/$m^2$]&quot;) bx.fill_between([-60, 30], y1=0, y2=40, alpha=0.2, color=&quot;red&quot;) bx.fill_between([-60, 30], y1=-50, y2=0, alpha=0.2, color=&quot;blue&quot;) bx.set_xlabel(&quot;temperature [°C]&quot;) bx.set_ylabel(&quot;energy flux [W/$m^2$]&quot;) bx.set_ylim(-50,40) bx.plot(temp_range, imbalance, color = &quot;black&quot;, label = &quot;Radiative Imbalance n (ASR-OTR)&quot;) bx.text(-60, 35, &quot;warming&quot;, color =&quot;darkred&quot;, size = 12) bx.text(-60, -40, &quot;cooling&quot;, color =&quot;darkblue&quot;, size = 12) ax.legend(); bx.legend() ax.grid(); bx.grid() f.tight_layout() . 3) Transitioning to and from Snowball Earth . 3.1) Turning up the Sun . Over the entire history of the Earth, the Sun is thought to have brightened by about 40%. . . In the Neoproterozoic (~700 million years ago), the Sun was 93% as bright as it is today, such that the incoming solar radiation was $S$ = 1272 W/m², Earth&#39;s average temperature plunged to $T = -50$°C, and Earth&#39;s ice-covered surface had a high albedo (reflectivity) of $ alpha_i = 0.5$. . 3.2) Did the increasing brightness of the Sun melt the Snowball? . If we start out in the Neoproterozoic climate and all we do is increase solar insolation to today&#39;s value of $ S = 1368 W/m^2$, can we warm the planet up to the pre-industrial temperature of T = 14°C? . smin = 1200 smax = 1800 smax_limited = 1650 svec = np.arange(smin, smax) svec = np.append(svec, svec[::-1]) tvec = np.zeros(svec.size) . t_restart = -100 for i, S in enumerate(svec): EBM = ebm(t_restart, 0., 5., CO2_const); EBM.S = S EBM.run(400) t_restart = EBM.T[-1] tvec[i] = EBM.T[-1] . plt.figure(figsize = (8,6)) plt.plot(svec[0:len(svec)//2], tvec[0:len(svec)//2], color = &quot;blue&quot;, label = &quot;cool branch&quot;, alpha = 0.3) plt.plot(svec[len(svec)//2:], tvec[len(svec)//2:], color = &quot;red&quot;, label = &quot;warm branch&quot;, alpha = 0.3) plt.axvline(1368, color = &quot;yellow&quot;, lw = 5, alpha = 0.2, label = &quot;Pre-industiral / present insolation&quot;) plt.plot(1368, tvec[svec==1368][1], marker=&quot;o&quot;, label=&quot;Our preindustrial climate&quot;, color=&quot;orange&quot;, markersize=8) plt.plot(1368, tvec[svec==1368][0], marker=&quot;o&quot;, label=&quot;Alternate preindustrial climate&quot;, color=&quot;lightblue&quot;, markersize=8) plt.plot(1368*0.93, -48, marker=&quot;o&quot;, label=&quot;neoproterozoic (700 Mya)&quot;, color=&quot;lightgrey&quot;, markersize=8) plt.xlabel(&quot;solar insolation S [W/m$^2$]&quot;) plt.ylabel(&quot;Global temperature T [°C]&quot;) plt.fill_between([1200, 1800], y1=-60, y2=-10, color = &quot;lightblue&quot;, alpha = 0.2) plt.fill_between([1200, 1800], y1=10, y2=70, alpha=0.09, color=&quot;red&quot;) plt.ylim(-60,70) plt.xlim(1200,1800) plt.legend() plt.grid() . Abrupt climate transitions . In this model, temperature variations are fairly smooth unless temperatures rise above -10°C or fall below 10°C, in which case the ice-albedo positive feedback kicks in and causes an abrupt climate transition. While this is just a simple hypothetical model, these kinds of abrupt climate transitions show up all the time in the paleoclimate record and in more realistic climate model simulations. . This simulation teaches us that we should not take the stability of our climate for granted and that pushing our present climate outside of its historical regime of stability could trigger catastrophic abrupt climate transitions. . 3.3) If not the Sun, how did Snowball Earth melt? . The leading theory is that a slow but steady outgassing of CO$_2$ from volcanoes eventually caused a strong enough greenhouse gas effect to offset the cooling effect of the frozen surface&#39;s high albedo and raise temperatures above the melting point $-10$°C. . . In Homework 1, you will extend the above model to include the effect of CO₂ and determine how much CO2 would need to be added to the snowball for it to melt. . Towards realistic climate modelling . In this simple model, the preindustrial climate of °C is so warm that there is no ice anywhere on the planet. Indeed, the only two valid stable climates are one with no ice or one with ice everywhere. . So how did Earth&#39;s preindustrial climate, which was relatively stable for thousands of years, have substantial ice caps at the poles? . The &quot;Aquaplanet&quot;, a simple three-dimensional ocean-world climate model . An &quot;Aquaplanet&quot; is a three-dimensional global climate simulation of a hypothetical planet covered entirely by a single global Ocean. While this is of course very different from Earth, where 27% of the planet is covered in land, the &quot;Aquaplanet&quot; exhibits many of the same characteristics as Earth and is much more realistic than our zero-dimensional climate model above. . The video below shows that the Aquaplanet simulation exhibits a third equilibrium state, with a mostly-liquid ocean but ice caps at the poles, in addition to the two we found in our zero-dimensional model. . In Homework 2, you will build a simple two-dimensional version of the aqua-planet and explore its stability. . youtube .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/13/ice-albedo.html",
            "relUrl": "/jupyter/2020/11/13/ice-albedo.html",
            "date": " • Nov 13, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Lecture 3, Nonlinear dynamics, stability and bifurcations",
            "content": "Thanks a lot to David P. Sanders for providing the lecture. The original lecture is part of the MIT class Introduction to Computational Thinking. . This class uses the Julia programming language. The orignal code can be found under github.com . import numpy as np import matplotlib.pyplot as plt from ipywidgets import interact, interactive, fixed, interact_manual import ipywidgets as widgets from IPython.display import HTML from IPython.display import display . import warnings warnings.filterwarnings(&quot;ignore&quot;) . %matplotlib inline . How does the climate change over time? In the last lecture we saw that our simple model is already quite good simulating how the climate changes over time. . Our simple model is based on ordinary differential equations (ODEs), where some variables change in time - with the rate of change as function of their current values. . $$ frac{dx(t)}{dt} = f(x(t)) $$ . The simplest numerical method to solve such an equation is the (forward) Euler method, in which we convert this equation into an explicit time-stepping routine: . $$ frac{dx(t)}{dt} = frac{x(t+ Delta t) - x(t)}{ Delta t}$$ . with the approximation . $$ x(t+ Delta t) simeq x(t) + Delta t f(x(t)) $$ . Solving the ODE: Euler method . Let&#39;s use this to simulate a simple nonlinear ODE that describes the dynamics of a population of bacteria. The bacteria will grow by reproduction at a rate $ lambda$ provided there is sufficient food, in which case we would have $ dot{x} = lambda x$. But the available food will actually always limit the sustainable population to a value $K$. A simple model for this is as follows: . $$ dot{x} = lambda , x , (K - x).$$ . When $x$ is close to $0$, the growth rate is $ lambda$, but that rate decreases as $x$ increases. . This is sometimes called the logistic differential equation (although the name does not seem particularly helpful). . Our goal is to use computational thinking, but we will actually not be interested so much in the exact dynamics in time, but rather in the qualitative features of the behaviour of the system. For example, at long times (formally $t to infty$) does the population get arbitrarily large? Or does it, for example, oscillate around a particular value? Or does it converge to a particular size? This forms the subject of nonlinear dynamics or dynamical systems theory. . Let&#39;s simulate the system using the Euler method to try to guess the answer to this question. We should never use the Euler method in practice, but should use a tried and tested library instead, and algorithms that provide much better accuracy in the solutions, if we are interested in faithful numerical results. . We&#39;ll rescale the variables to the simplest form: . $$ frac{dx}{dt} = x ,(1-x) $$ . $$ x_{n+1} = x_n + Delta t cdot text{tendency}(x_n; ...)$$ . def logistic(x, timesteps): x = np.asarray(x) for i in np.diff(timesteps): if x.size == 1: x = np.append(x, x + i * x * (1-x)) else: x = np.append(x, x[-1] + i * x[-1] * (1-x[-1])) return x . t1 = np.arange(0,20, 0.01) dxdt = logistic(0.5, t1) . plt.plot(t1, dxdt) . [&lt;matplotlib.lines.Line2D at 0x7fbe22157490&gt;] . We see that for this particular initial condition, the solution seems to settle down to a fixed value after some time, and then remains at that value thereafter. Such a value is called a fixed point or a stationary point of the ODE. . Qualitative behaviour: Fixed points and their stability . But what happens if we have a different initial condition: . tag = HTML(&#39;&#39;&#39;&lt;script&gt; code_show=true; function code_toggle() { if (code_show){ $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).hide(); } else { $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).show(); } code_show = !code_show } $( document ).ready(code_toggle); &lt;/script&gt; To show/hide this cell&#39;s raw code input, click &lt;a href=&quot;javascript:code_toggle()&quot;&gt;here&lt;/a&gt;.&#39;&#39;&#39;) display(tag) def plot_func(initial_condition): plt.figure(figsize=(8,8)) plt.plot(t1, logistic(initial_condition, t1)) plt.xlabel(&quot;t&quot;) plt.ylabel(&quot;x(t)&quot;) plt.xlim([0,10]) plt.ylim(-1, 2) plt.grid() plt.show() interact(plot_func, initial_condition = widgets.FloatSlider(value = 0.5, min = -1, max = 2, step = 0.1)) . To show/hide this cell&#39;s raw code input, click here. &lt;function __main__.plot_func(initial_condition)&gt; . To get an overview, we can draw all graphs in a single plot. . plt.figure(figsize=(8,8)) for initial_condition in np.arange(-1, 2, 0.1): plt.plot(t1, logistic(initial_condition, t1)) plt.xlabel(&quot;t&quot;) plt.ylabel(&quot;x(t)&quot;) plt.xlim([0,10]) plt.ylim(-1, 2) plt.grid() plt.show() . We see that all the curves starting near to $x_0=1.0$ seem to converge to 1 at long times. If the system starts exactly at 0 then it stays there forever. However, if it starts close to 0, on either side, then it moves away from 0 (on that same side of 0) -- starting from a negative value $x$ becomes ever more negative. (Even though negative populations have no meaning in the original interpretation as the dynamics of a population, we can still ask study the dynamics of the equation with negative initial conditions, since it may model other systems too.) . The special values $x^*_1=1$ and $x^*_2=0$ are called stationary points or fixed points of the differential equation. If we start at $x^*_i$, then the derivative there is $f&#39;(x^*_i) = 0$, and hence we cannot move away from $x^*_i$! The fixed points can be found as zeros or roots of the function $f$, i.e. values $x^*$ such that $f(x^*) = 0$. . We see, though, that the two types of fixed points are qualitatively different: trajectories that start close to $x^*_1 = 1$ move towards $x^*_1$, whereas trajectories that start close to $x^*_2 = 0$ move away from it. We say that $x^*_1$ is a stable fixed point and $x^*_2$ is an unstable fixed point. . In general it is not possible to find analytical formulas for the position and stability of fixed points; instead, we can use numerical root-finding algorithms, for example the Newton method. . State space: Vector field and phase portrait . If we want to find the whole trajectory for a given initial condition then we need to solve the equations, either numerically or analytically. . However, we may want less information about the system, for example the long-time or asymptotic dynamics. It turns out that we can obtain some information about that without explicitly solving the ODE! This is the qualitative approach to studying nonlinear systems. . Instead of drawing trajectories $x(t)$ as a function of time $t$, as we did above, let&#39;s use a different graphical representation, where we draw state space or phase space: This is the set (&quot;space&quot;) of all possible values of the dependent variables (&quot;states&quot;). For the above ODE there is only a single dependent variable, $x$, so the state space is the real line, $ mathbb{R}$. . At each possible value of $x$, the ODE gives us information about the rate of change of $x(t)$ at that point. Let&#39;s draw an arrow at that point, pointing in the direction that a particle placed at that point would move: to the right if $ dot{x} &gt; 0$ and to the left if $ dot{x} &lt; 0$. . tag = HTML(&#39;&#39;&#39;&lt;script&gt; code_show=true; function code_toggle() { if (code_show){ $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).hide(); } else { $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).show(); } code_show = !code_show } $( document ).ready(code_toggle); &lt;/script&gt; To show/hide this cell&#39;s raw code input, click &lt;a href=&quot;javascript:code_toggle()&quot;&gt;here&lt;/a&gt;.&#39;&#39;&#39;) display(tag) states = np.array([]) initial_conditions = np.arange(-1, 2, 0.1) for initial_condition in initial_conditions: states = np.append(states, logistic(initial_condition, t1)[-1]) X = np.ones(len(states)) Y = initial_conditions.copy() U = np.zeros(len(states)) V = np.ones(len(states)) V[states - initial_conditions &lt; 0] = -1 states[states == -np.inf] = 2 plt.figure(figsize=(2,8)) plt.quiver(X, Y, U, V, scale = 10, width = 0.02) plt.plot([1,1],[1,1], marker = &#39;o&#39;, markersize = 12) plt.plot([1,1],[0,0], marker = &#39;o&#39;, markersize = 12) plt.xlim([1,1]) plt.xlabel([]) . To show/hide this cell&#39;s raw code input, click here. Text(0.5, 0, &#39;[]&#39;) . This vector field indeed gives us a qualitative picture of the dynamics. It does not tell us how fast the dynamics will occur in each region, but it indicates what the tendency is. We have coded the fixed points according to their stability; this may be calculated using the derivative evaluated at the fixed point, $f&#39;(x^*)$, since this derivative controls the behaviour of nearby initial conditions $x^* + delta x$. . Bifurcations . Now suppose that there is a parameter $ mu$ in the system that can be varied. For each value of $ mu$ we have a different ODE . $$ dot{x} = f_ mu(x).$$ For example, $$ dot{x} = mu + x^2.$$ Let&#39;s draw the state space for each different value of $ mu$: . tag = HTML(&#39;&#39;&#39;&lt;script&gt; code_show=true; function code_toggle() { if (code_show){ $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).hide(); } else { $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).show(); } code_show = !code_show } $( document ).ready(code_toggle); &lt;/script&gt; To show/hide this cell&#39;s raw code input, click &lt;a href=&quot;javascript:code_toggle()&quot;&gt;here&lt;/a&gt;.&#39;&#39;&#39;) display(tag) def xdot(mu, x): return mu + x**2 t = np.arange(-5, 5, 0.001) def plot_func(initial_condition): plt.figure(figsize=(8,8)) a = xdot(mu = initial_condition, x = t) plt.plot(t, a) plt.xlabel(&quot;t&quot;) plt.ylabel(&quot;x(t)&quot;) plt.xlim([-5,5]) plt.ylim(-2, 2) plt.grid() try: zero_crossings = np.where(np.diff(np.signbit(a)))[0] plt.vlines(t[zero_crossings+1], ymin=-2,ymax=2) for arrows in np.arange(-5,t[zero_crossings[0]],0.5): plt.arrow(arrows, 0, 0.25, 0,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.05, color =&quot;blue&quot;) for arrows in np.arange(t[zero_crossings[0]]+0.5, t[zero_crossings[1]],0.5): plt.arrow(arrows, 0, -0.25, 0,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.05, color = &quot;blue&quot;) for arrows in np.arange(t[zero_crossings[1]], 5,0.5): plt.arrow(arrows, 0, +0.25, 0,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.05, color =&quot;red&quot;) plt.plot([t[zero_crossings],t[zero_crossings]],[0,0], marker=&#39;o&#39;, markersize = 12) except: for arrows in np.arange(-5,5,0.5): plt.arrow(arrows, 0, 0.25, 0,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.05, color =&quot;blue&quot;) plt.show() interact(plot_func, initial_condition = widgets.FloatSlider(value = -1, min = -2, max = 2, step = 0.1)) . To show/hide this cell&#39;s raw code input, click here. &lt;function __main__.plot_func(initial_condition)&gt; . Now let&#39;s collect all the vector fields into a single plot. We rotate the vector field to now be vertical, thinking of the dynamics of $x$ as occurring along the vertical direction. The horizontal axis now represents the different possible values of the parameter $ mu$: . tag = HTML(&#39;&#39;&#39;&lt;script&gt; code_show=true; function code_toggle() { if (code_show){ $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).hide(); } else { $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).show(); } code_show = !code_show } $( document ).ready(code_toggle); &lt;/script&gt; To show/hide this cell&#39;s raw code input, click &lt;a href=&quot;javascript:code_toggle()&quot;&gt;here&lt;/a&gt;.&#39;&#39;&#39;) display(tag) saddle_points0 = np.array([]) saddle_points1 = np.array([]) stepsize = 0.1 for mu in np.arange(-2, 2, stepsize): a = xdot(mu = mu, x = t) zero_crossings = np.where(np.diff(np.signbit(a)))[0] if zero_crossings.size &gt; 1: saddle_points0 = np.append(saddle_points0, t[zero_crossings[0]]) saddle_points1 = np.append(saddle_points1, t[zero_crossings[1]]) for arrows in np.arange(-5,t[zero_crossings[0]],0.25): plt.arrow(mu, arrows, 0.0, 0.1,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.025, color =&quot;blue&quot;) for arrows in np.arange(t[zero_crossings[0]], t[zero_crossings[1]],0.25): plt.arrow(mu, arrows, 0.0, -0.1,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.025, color =&quot;red&quot;) for arrows in np.arange(t[zero_crossings[1]],2,0.25): plt.arrow(mu, arrows, 0.0, 0.1,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.025, color =&quot;blue&quot;) elif zero_crossings.size == 1: saddle_points0 = np.append(saddle_points0, t[zero_crossings]) saddle_points1 = np.append(saddle_points0, np.nan) else: saddle_points0 = np.append(saddle_points0, np.nan) saddle_points1 = np.append(saddle_points1, np.nan) for arrows in np.arange(-2,2,0.25): plt.arrow(mu, arrows, 0.0, 0.1,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.025, color =&quot;blue&quot;) plt.ylim(-2,2) plt.xlim(-2,2) plt.scatter(np.arange(-2,2,stepsize), saddle_points0, color=&quot;green&quot;, marker=&#39;D&#39;) plt.scatter(np.arange(-2,2,stepsize), saddle_points1, color=&quot;black&quot;, marker=&#39;o&#39;) plt.ylabel(&quot;fixed points and dynamics with given $ mu$&quot;) plt.xlabel(&quot;$ mu$&quot;) . To show/hide this cell&#39;s raw code input, click here. Text(0.5, 0, &#39;$ mu$&#39;) . Now let&#39;s collect all the vector fields into a single plot. We rotate the vector field to now be vertical, thinking of the dynamics of $x$ as occurring along the vertical direction. The horizontal axis now represents the different possible values of the parameter $ mu$: . We see that at the critical value $ mu_c = 0$ there is a qualitative change in behaviour in the system: for $ mu_c &lt; 0$ there are two fixed points, whereas for $ mu_c &gt; 0$ there are no fixed points at all. In this particular ODE the two fixed points collide in a saddle--node or fold bifurcation. . Bistability and hysteresis . Now let&#39;s look at the dynamics of the following system: . $$ dot{x} = mu + x - x^3.$$ . def h(mu, x): return mu + x - x**3 . saddle_points = [] stepsize = 0.1 for mu in (np.arange(-2, 2, stepsize)): a = h(mu = mu, x = t) zero_crossings = np.where(np.diff(np.signbit(a)))[0] plt.scatter(np.ones(len(zero_crossings))*mu, t[zero_crossings], color=&quot;green&quot;, marker=&#39;D&#39;) plt.grid() plt.title(&quot;Bifurcation Diagramm&quot;) plt.ylabel(&quot;fixed points and dynamics with given $ mu$&quot;) plt.xlabel(&quot;$ mu$&quot;) plt.ylim(-2,2) plt.xlim(-2,2) . (-2.0, 2.0) . We see that there is a range of values of $ mu$ for which there are three coexisting fixed points, two stable and one unstable. Since there are two stable fixed points in which the system can remain, we say that the system is bistable. . Now that we understand what the plots mean and the dynamics, let&#39;s plot just the fixed points $x^*( mu)$ as a function of $ mu$. Such a plot is called a bifurcation diagram: . The pieces of curve are called branches. . Hysteresis . Suppose we now think about slowly varying the parameter $ mu$. If we change the parameter $ mu$ by a little, the system is no longer at a fixed point, since the position of the fixed point moves when $ mu$ changes. However, the system will then relax by following the dynamics at the new value of $ mu$, and will rapidly converge to the new fixed point nearby. For example, starting at $ mu=-2$, the system will stay on the lower black (stable) branch until $ mu=0.4$ or so. At that point, two fixed points collide and annihilate each other! After that there is no longer a fixed point nearby. However, there is another fixed point much further up that will now attract all trajectories, so the system rapidly transitions to that fixed point. Now suppose we decrease the parameter again. The system will now track the upper branch until $ mu=-0.4$ or so, when again it will jump back down. For each parameter value $ mu$ in the interval $[-0.4, 0.4]$ there is bistability, i.e. coexistence of two fixed points with the same value of $ mu$ (together with a third, unstable fixed point that is not observable). The fact that the system tracks different stable branches depending on where we started, i.e. on the history, is known as hysteresis. . Hysteretic behaviour like this is found in many scientific and engineering contexts, including switches in biology, for example genetic switches, and in the historical dynamics of the earth&#39;s climate. . Slow--fast systems . What are we actually doing when we let the parameter $ mu$ vary? Effectively we now have a system with two equations, for example . $$ dot{x} = mu + x - x^3;$$ $$ dot{ mu} = epsilon,$$ . where $ mu$ varies at some slow speed $ epsilon$. On a time scale much shorter than $1 / epsilon$, the dynamics of $x$ &quot;does not know&quot; that $ mu$ is changing, so it will converge to a fixed point $x^*( mu)$ for the current value of $ mu$. [An associated term is adiabatic approximation.] However, $ mu$ does gradually change, so the value of $x$ will effectively &quot;slide along&quot; the curve $x(t) simeq x^*( mu(t))$, tracking the curve of fixed points as $ mu$ changes. Once $ mu$ reaches a critical value $ mu_c$, however, there is no longer a nearby fixed point, and the dynamics will rapidly transition to the far away alternative fixed point. If we now reverse the dynamics of $ mu$, we slide back along the upper branch. &quot;&quot;&quot; .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/12/non-linear-dynamics.html",
            "relUrl": "/jupyter/2020/11/12/non-linear-dynamics.html",
            "date": " • Nov 12, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Lecture 2, A "zero-dimensional" energy balance model of Earth's climate",
            "content": "Thanks a lot to Henri Drake for providing the lecture. . The original lecture is part of the MIT class Introduction to Computational Thinking. . This class uses the Julia programming language. The orignal code can be found under https://github.com/hdrake/simplEarth/blob/master/1_energy_balance_model.jl . import xarray as xr import numpy as np import matplotlib.pyplot as plt . 1) Background: climate physics . The simplest climate model can be conceptualized as: . change in heat content = . $+$ absorbed solar radiation (energy from the Sun&#39;s rays) . $-$ outgoing thermal radiation (i.e. blackbody cooling to space) . $+$ human-caused greenhouse effect (trapped outgoing radiation) . where each of these is interpreted as an average over the entire globe (hence &quot;zero-dimensional&quot;). . . To make this simple conceptual model quantitative, we need a mathematical formulation for each of these four processes. . 1.1 Absorbed solar radiation . At Earth&#39;s orbital distance from the Sun, the power of the Sun&#39;s rays that intercept the Earth is equal to . S = 1368 # solar insolation [W/m^2] (energy per unit time per unit area) . A small fraction . alpha = 0.3 # albedo, or planetary reflectivity [unitless] . of this incoming solar radiation is reflected back out to space (by reflective surfaces like white clouds, snow, and ice), with the remaining fraction $(1- alpha)$ being absorbed. Since the incoming solar rays are all approximately parallel this far from the Sun, the cross-sectional area of the Earth that intercepts them is just a disc of area $ pi R^{2}$. Since all of the other terms we will consider act on the entire surface area $4 pi R^{2}$ of the spherical Earth, the absorbed solar radiation per unit surface area (averaged over the entire globe) is reduced by a factor of 4. . . The absorbed solar radiation per unit area is thus . $ text{absorbed solar radiation} equiv frac{S(1- alpha)}{4}$ . def absorbed_solar_radiation(S, alpha): return (S*(1-alpha)/4) # [W/m^2] . 1.2) Outgoing thermal radiation . The outgoing thermal radiation term (or &quot;blackbody cooling to space&quot;) represents the combined effects of negative feedbacks that dampen warming, such as blackbody radiation, and positive feedbacks that amplify warming, such as the water vapor feedback. . Since these physics are too complicated to deal with here, we linearize the model by considering only the first term of a Taylor Series expansion . $$ G(T) sim G(T_0) + G^{&#39;}(T_0) (T-T_0) = G^{&#39;}(T_0)T + (G(T_0)-G^{&#39;}(T_0)T_0) $$ . around the pre-industrial equilibrium temperature . T0 = 14. # preindustrial temperature [°C] . To simplify the expression, we define: . $ A equiv G^{&#39;}(T_0)T_0 $ . $ B equiv - G^{&#39;}(T_0) text{ (the climate feedback parameter),}$ . which gives . $$ text{outgoing thermal radiation} equiv G(T) sim A - BT$$ . def outgoing_thermal_radiation(T, A, B): return A - B*T . The value of the climate feedback parameter used here, . B = -1.3 # climate feedback parameter [W/m^2/°C], . comes from a bottom-up estimate based on the best understanding of the various climate feedbacks (read more here). . Note: Since $B&lt;0$ , this tells us that the overall climate feedback is negative (i.e. stabilizing). Positivefeedbacks cause to become less negative, reducing the efficiency with which Earth cools itself by radiating thermal energy to space, and thus amplifying warming. . The value $A$ of is given by the definition of a preindustrial equilibrium, i.e. the fact that before human influence, Earth&#39;s energy budget was perfectly balanced: . absorbed solar radiation = outgoing thermal radiation . or . $ frac{S (1- alpha)}{4} equiv A - BT_0$ . By rearanging this equation, we find that the value of $A$ is given by . A = S*(1. - alpha)/4 + B*T0 # [W/m^2]. A . 221.2 . Human-caused greenhouse effect . Empirically, the greenhouse effect is known to be a logarithmic function of gaseous carbon dioxide (CO$_2$) concentrations . $$ text{Human-caused greenhouse effect} = a * ln frac{CO_2}{CO{_2}_{PI}} $$ . where . a = 5 # CO2 forcing coefficient [W/m^2] . CO2_PI = 280 # preindustrial CO2 concentration [parts per million; ppm]; . def greenhouse_effect(CO2, a=5, CO2_PI = 280): return a*np.log(CO2/CO2_PI) . co2_present = 420 co2_range = 280*2**np.linspace(-1,3,100) plt.plot(co2_range, greenhouse_effect(co2_range), color = &quot;black&quot;) plt.ylabel(&#39;Radiative forcing [$W/m^2$]&#39;) plt.xlabel(&#39;$CO_2$ concentration [ppm]&#39;) plt.plot(CO2_PI, greenhouse_effect(CO2_PI), marker=&quot;.&quot;, markersize = 20, label = &quot;pre-industrial (PI)&quot;, color = &quot;blue&quot;) plt.plot(co2_present, greenhouse_effect(co2_present), marker=&quot;.&quot;, markersize = 20, label = &quot;present day (2020)&quot;, color = &quot;red&quot;) plt.xticks([280, 280*2, 280*4, 280*8]) plt.legend(loc = 4) plt.grid() . 1.4) Change in heat content . The heat content $CT$ is determined by the temperature $T$ (in Kelvin) and the heat capacity of the climate system. While we are interested in the temperature of the atmosphere, which has a very small heat capacity, its heat is closely coupled with that of the upper ocean, which has a much larger heat capacity of . C = 51 . The change in heat content over time is thus simply given by $ frac{d(CT)}{dt}$. Since the heat capacity of sea water hardly changes with temperature, we can rewrite this in terms of the change in temperature with time as: . $$ text{change in heat content} = C frac{dT}{dt} $$ . 1.5) &quot;zero-dimensional&quot; climate model equation . Combining all of these subcomponent models, we write the governing equation of the &quot;zero-dimensional&quot; energy balance climate model as the Ordinary Differential Equation (ODE) . $$ C frac{dT}{dt} = frac{S (1- alpha)}{4} - ( A - BT_0) + a * ln frac{CO_2}{CO{_2}_{PI}} $$ . which determines the time evolution of Earth&#39;s globally-averaged surface temperature. . 2) Numerical solution method and data structures . 2.1) Discretization . The energy balance model equation above can be discretized in time as . $$ C frac{T(t+ Delta t) - T(t)}{ Delta t} = frac{S (1- alpha)}{4} - ( A - BT_0) + a * ln frac{CO_2}{CO{_2}_{PI}} $$ . Our finite difference equation, which results from a first-order truncation of the Taylor series expansion, approximates the exact ordinary differential equation above in the limit that $ Delta t rightarrow 0$. In practice, we can keep decreasing $ Delta t$ until the solution converges within a tolerable error. . Hereafter, we use the subscript $n$ to denote the $n$-th timestep, where $T_{n+1} equiv T(t_{n+1})$ denotes the temperature at the next timestep $t_{n+1} = t_n + Delta t$. . By re-arranging the equation, we can solve for the temperature at the next timestep $n+1$ based on the known temperature at the present timestep $n$: . $$ T_{n+1} = T_n + frac{ Delta t}{C} bigg[ frac{S (1- alpha)}{4} - ( A - BT_n) + a * ln frac{CO_2}{CO{_2}_{PI}} bigg] $$ . 2.2) Timestepping . More generally, we recognize this equation to be of the form: . $$ T_{n+1} = T_n + Delta t cdot text{tendency}(T_n; ...),$$ . which we implement below (don&#39;t forget to update the time as well, $t_{n+1} = t_n + Delta t$), which takes in an instance of our anticipated energy balance model EBM type as its only argument. . class ebm(): &quot;&quot;&quot; Zero order energy balance model &quot;&quot;&quot; def __init__(self, T, t, deltat, CO2): self.T = np.array(T) self.t = t self.deltat = deltat self.C = C self.a = a self.A = A self.B = B self.co2_pi = CO2_PI self.alpha = alpha self.S = S self.co2 = CO2 def tendency(self): if self.T.size == 1: return 1. / self.C * ( + absorbed_solar_radiation(alpha = self.alpha, S=self.S) - outgoing_thermal_radiation(self.T, A = self.A, B=self.B) + greenhouse_effect(self.co2(self.t), a = self.a, CO2_PI=self.co2_pi) ) else: return 1. / self.C * ( + absorbed_solar_radiation(alpha = self.alpha, S=self.S) - outgoing_thermal_radiation(self.T[-1], A = self.A, B=self.B) + greenhouse_effect(self.co2(self.t[-1]), a = self.a, CO2_PI=self.co2_pi) ) @property def timestep(self): if self.T.size == 1: self.T = np.append(self.T, self.T + self.deltat * self.tendency()) self.t = np.append(self.t, self.t + self.deltat) else: self.T = np.append(self.T, self.T[-1] + self.deltat * self.tendency()) self.t = np.append(self.t, self.t[-1] + self.deltat) . 2.4) Running simulations of the energy balance model . Let&#39;s define a function that runs an EBM simulation by timestepping forward until a given end_year. . def run_ebm(ebm, end_year): for year in range(end_year): ebm.timestep . For example, let us consider the case where CO₂ emissions increase by 1% year-over-year from the preindustrial value [CO$_2$] = $280.0$ ppm, starting at T=T₀=14°C in year t=0 and with a timestep Δt = 1 year. . def CO2_test(t): return CO2_PI ** (1 + 1/100)**t EBM = ebm(T0, t=0, deltat=1, CO2=CO2_test) . EBM.timestep . EBM.T . array([14., 14.]) . 3) Energy balance model applications . 3.1) Why was Earth&#39;s preindustrial climate so stable? . Let us consider the simple case where CO₂ concentrations remain at their pre-industrial temperatures. . def CO2_test(t): return 280 EBM = ebm(T0, 0, 1, CO2_test) . run_ebm(EBM, 200) . t0s = np.arange(0,28,2) for i in t0s: EBM = ebm(i, 0, 1, CO2_test) run_ebm(EBM, 200) plt.plot(EBM.T) plt.grid() plt.xlabel(&quot;year&quot;) plt.ylabel(&quot;temperature [°C]&quot;) . Text(0, 0.5, &#39;temperature [°C]&#39;) . This figure shows that, no matter where we start out, the overall negative feedbacks ($B&lt;0$) restore the temperature to the preindustrial equilibrum value of $T_0$ = 14.0 °C, over an exponential timescale of about 100 years. . 3.2) Historical global warming fueled by greenhouse gas emissions . Human greenhouse gas emissions have fundamentally altered Earth&#39;s energy balance, moving us away from the stable preindustrial climate of the past few thousand years. . Since human CO₂ emissions are the main driver of global warming, we expect that if we plug historical CO₂ increases into our model (&quot;forcing&quot; it), we should roughly reproduce the observed historical global warming. . The observed increase of CO2 concentrations can be fairly accurately modelled by the simple cubic formula below. . def co2_hist(t): return 280 * (1+ ((t-1850)/220)**3) . EBM = ebm(T0, 1850, 1, co2_hist) run_ebm(EBM, 170) . import pandas as pd url = &quot;https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt&quot; temp = pd.read_csv(url, header = None, skiprows=5, index_col=0, delimiter=&quot; &quot;) temp = temp + 14.15 CO2_url = &quot;https://scrippsco2.ucsd.edu/assets/data/atmospheric/stations/in_situ_co2/monthly/monthly_in_situ_co2_mlo.csv&quot; co2_data = pd.read_csv(CO2_url, header = 46,skiprows=8, index_col=0) co2_data = co2_data.iloc[4:] co2_data = pd.to_numeric(co2_data.iloc[:,5]) co2_data[co2_data&lt;= 0] = np.nan co2_data.index = pd.to_datetime(co2_data.index) co2_data = co2_data.groupby(co2_data.index.year).mean() . &lt;ipython-input-35-ad0381c77880&gt;:3: ParserWarning: Falling back to the &#39;python&#39; engine because the &#39;c&#39; engine does not support regex separators (separators &gt; 1 char and different from &#39; s+&#39; are interpreted as regex); you can avoid this warning by specifying engine=&#39;python&#39;. temp = pd.read_csv(url, header = None, . f, (ax, bx) = plt.subplots(1,2, figsize=(8,4)) ax.plot(np.arange(1850, 2020), co2_hist(np.arange(1850, 2020)), label = &quot;EBM model&quot;) ax.plot(co2_data.index, co2_data.values, label=&quot;Keeling Curve&quot;) ax.set_ylabel(&quot;$CO_2$ concentration [ppm]&quot;) ax.grid() ax.set_xlabel(&quot;Year&quot;) ax.legend() bx.plot(np.arange(1850, 2021), EBM.T, label=&quot;EBM model&quot;) temp.plot(ax = bx) bx.set_ylabel(&quot;Temperature [°C]&quot;) bx.grid() bx.legend([&quot;EBM Model&quot;, &quot;NASA Observations&quot;, &quot;NASA Obs roll. mean&quot;]) bx.set_xlabel(&quot;Year&quot;) f.tight_layout() . CO$_2$ emissions predict the trend, but what about the climate noise? . CO$_2$ emissions predict the trend, but what about the climate noise? Our model does a good job of predicting the long-term trend of increasing temperatures, but what about all of the noise in the observations? These are real signals due to natural variability of the Earth system, not artifacts due to instrumental noise. . This natural noise arises due to the turbulent and chaotic fluid dynamics of the atmosphere and ocean, which we will explore further in Lecture 4 and are illustrated below. . youtube . Now that we&#39;ve convinced ourselves that the model accurately reproduces historical warming, we can use it to project how much warming we might expect due to future CO₂ emissions. . 3.3) Best- and worst-case projections of future global warming . Consider two divergent hypothetical futures: . 1) a low-emissions world in which emissions decrease such that CO2 concentrations stay below 500 ppm by 2100 (known in climate circles as &quot;RCP2.6&quot;) and . 2) a high-emissions world in which emissions continue increasing and CO2 concentrations soar upwards of 1200 ppm (&quot;RCP8.5&quot;). . def CO2_RCP26(t): return 280 * (1+ ((t-1850)/220)**3 * np.minimum(1., np.exp(-((t-1850)-170)/100))) def CO2_RCP85(t): return 280 * (1+ ((t-1850)/220)**3 * np.maximum(1., np.exp(((t-1850)-170)/100))) . In the low-emissions scenario, the temperature increase stays below $ Delta T$ = 2 °C by 2100, while in the high-emissions scenario temperatures soar upwards of 3.5ºC above pre-industrial levels. . EBM1 = ebm(T0, 1850, 1, CO2_RCP26) EBM2 = ebm(T0, 1850, 1, CO2_RCP85) run_ebm(EBM1, 249) run_ebm(EBM2, 249) . f, (ax, bx) = plt.subplots(1,2, figsize = (8,4)) ax.plot(np.arange(1850, 2100), CO2_RCP26(np.arange(1850,2100)), color = &quot;Blue&quot;, label = &quot;RCP 2.6 low emissions&quot;) ax.plot(np.arange(1850, 2100), CO2_RCP85(np.arange(1850,2100)), color = &quot;Red&quot;, label = &quot;RCP 8.5 High emissions&quot;) ax.plot(2020, CO2_RCP26(2020), marker=&quot;.&quot;, markersize = 20, label = &quot;we are here&quot;, color = &quot;black&quot;) ax.set_ylabel(&quot;$CO_2$ concentration [ppm]&quot;) ax.legend() bx.plot(np.arange(1850, 2100), EBM1.T, color = &quot;Blue&quot;) bx.plot(np.arange(1850, 2100), EBM2.T, color = &quot;Red&quot;) bx.axhline(y = 16, label = &quot;Paris Agreement n threshold (2°C warming)&quot;, ls=&quot;--&quot;, color = &quot;black&quot;) bx.set_ylabel(&quot;Temperature [°C]&quot;) bx.plot(2020, EBM1.T[170], marker=&quot;.&quot;, markersize = 20, label = &quot;we are here&quot;, color = &quot;black&quot;) bx.legend() f.tight_layout() .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/11/energy-model.html",
            "relUrl": "/jupyter/2020/11/11/energy-model.html",
            "date": " • Nov 11, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Lecture 1, Introduction to python",
            "content": "Getting started . Introduction to Python . What are we doing during the course? . The course aims to introduce you to the first steps of data analysis . save data | organize and manipulate data | further tools for data analysis | . If you never coded before than starting with Python is perfect! Python is one of the easiest and most straight forward languages. . x = 1 . x = &quot;abcd&quot; . x as an integer and then a string? The same concept is applicable for many other different examples. Python has a minimalistic approech and follows a simple syntax. This is why source code is very easy to read. . x = 0 if x &gt; 0: statement = &quot;x is positive&quot; elif x &lt; 0: statement = &quot;x is negative&quot; else: statement = &quot;x is zero or none&quot; print(statement) . x is zero or none . x = 5 - 4 # Comments are made with a hash Raute y = &quot;Hello&quot; # Everything after the hash will be a comment if y == &quot;hallo&quot;: z = x * 2 y = y + &quot; World&quot; # This is how you combine strings! print(&quot;x :&quot;, x) # The letter x and the our variable x print(&quot;y :&quot;, y) . x : 1 y : Hello . First summary: . Indenting of the source code has a meaning! the indentation of your code organizes it into blocks within blocks within blocks. | . | the first assignment of a variable creates it we don&#39;t care if it is an integer, float or string | . | assignments of variables use =, to compare two variables we use == | also: logical operators are words (and, or, not) not symbols | . Variables and types . Variable . The value of a variable can be obtained by writing its name. . height = 1.79 weight = 68.7 weight . 68.7 . Second example: . Calculate your BMI . BMI = $ frac{weight [kg]}{size^2 [m]}$ . Exponentiation in Python is defined as . Variable ** 2 . . BMI = 60/(1.65**2) print(BMI) . 22.03856749311295 . Types . Without going into detail: . pi = 3.141516546859754674896794 days_of_week = 5 x = &#39;Hey Guys&#39; y = &quot;Also works this way ...&quot; z = True print(&#39;days_of_week: &#39;, type(days_of_week)) print(&#39;pi: &#39;, type(pi)) print(&#39;x: &#39;, type(x)) print(&#39;y: &#39;, type(y)) print(&#39;z: &#39;, type(z)) . days_of_week: &lt;class &#39;int&#39;&gt; pi: &lt;class &#39;float&#39;&gt; x: &lt;class &#39;str&#39;&gt; y: &lt;class &#39;str&#39;&gt; z: &lt;class &#39;bool&#39;&gt; . Does this really matter? Actually, no, since Python&#39;s use of variables is very intuitive. Still, keep in mind that a different variable type can lead to different behaviour: . 2 + 3 . 5 . &#39;ab&#39; + &#39;cd&#39; . &#39;abcd&#39; . a = 1 b = 5 c = a / b . What is the value of c? . print(c) . 0.2 . Lists . As opposed to int, bool etc., a list is a compound data type; you can group values together: . a = &quot;is&quot; b = &quot;nice&quot; my_list = [&quot;my&quot;, &quot;list&quot;, a, b] . After measuring the height of your family, you decide to collect some information on the house you&#39;re living in. The areas of the different parts of your house are stored in separate variables for now, as shown in the script. . List of lists . As a data scientist, you&#39;ll often be dealing with a lot of data, and it will make sense to group some of this data. . Instead of creating a flat list containing strings and floats, representing the names and areas of the rooms in your house, you can create a list of lists. The script on the right can already give you an idea. . Don&#39;t get confused here: &quot;hallway&quot; is a string, while hall is a variable that represents the float 11.25 you specified earlier. . hall = 11.25 kit = 18.0 liv = 20.0 bed = 10.75 bath = 9.50 # house information as list of lists house = [[&quot;hallway&quot;, hall], [&quot;kitchen&quot;, kit], [&quot;living room&quot;, liv]] # Print out house # Print out the type of house . Subset and conquer . Subsetting Python lists is a piece of cake. Take the code sample below, which creates a list x and then selects &quot;b&quot; from it. Remember that this is the second element, so it has index 1. You can also use negative indexing. . x = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;] x[1] x[-3] # same result! . Remember the areas list from before, containing both strings and floats? Its definition is already in the script. Can you add the correct code to do some Python subsetting? . Familiar functions . Out of the box, Python offers a bunch of built-in functions to make your life as a data scientist easier. You already know two such functions: print() and type(). You&#39;ve also used the functions str(), int(), bool() and float() to switch between data types. These are built-in functions as well. . Calling a function is easy. To get the type of 3.0 and store the output as a new variable, result, you can use the following: . result = type(3.0) . The general recipe for calling functions and saving the result to a variable is thus: . output = function_name(input) . var1 = [1, 2, 3, 4] var2 = False # Print out type of var1 print(type(var1)) # Print out length of var1 print(len(var1)) # Convert var2 to an integer: out2 int(var2) . &lt;class &#39;list&#39;&gt; 4 . 0 . Numpy . import numpy as np # List a = [1,2,3,4,5,6,7,8,9] # numpy array A = np.array([1,2,3,4,5,6,7,8,9]) print(&quot;This is a list: {} and looks like n {}&quot;.format(type(a), a)) print(&quot;This is an array: {} and looks like n {}&quot;.format(type(A), A)) . This is a list: &lt;class &#39;list&#39;&gt; and looks like [1, 2, 3, 4, 5, 6, 7, 8, 9] This is an array: &lt;class &#39;numpy.ndarray&#39;&gt; and looks like [1 2 3 4 5 6 7 8 9] . Create arrays of a give length . y_ar = np.arange(0, 1, 0.1) print(&quot;Lenght of array y_ar is {}.&quot;.format(len(y_ar))) print(y_ar) x_ar = np.linspace(1, 10, 5) #creates an array of length 5 between 1 and 10 print(&quot;Lenght of array x_ar is {}.&quot;.format(len(x_ar))) print(x_ar) . Lenght of array y_ar is 10. [0. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9] Lenght of array x_ar is 5. [ 1. 3.25 5.5 7.75 10. ] . Multidimensional arrays . z_ar = np.zeros((100)) #creates an array of shape (100,) with zeros print(&quot;Shape of z_ar is {}&quot;.format(z_ar.shape)) z_ar = np.zeros((100,1)) print(&quot;Shape of z_ar is {}&quot;.format(z_ar.shape)) z_ar = np.zeros((100, 1, 3, 5)) print(&quot;Shape of z_ar is {}&quot;.format(z_ar.shape)) z_ar[0, 0, 1, 2] . Shape of z_ar is (100,) Shape of z_ar is (100, 1) Shape of z_ar is (100, 1, 3, 5) . 0.0 . .shape gives you the dimensions of the array, while len() only returns the lenght of the first dimension! . import time a = [1, 2, 3] b = [3, 4, 5] print(a + b) c = [] for count in range(len(a)): c.append(a[count] + b [count]) print(c) . [1, 2, 3, 3, 4, 5] [4, 6, 8] . a = np.array([1., 2., 3.]) b = np.array([3., 4., 5.]) print(a + b) . [4. 6. 8.] . Why do we do this? . a = [1 for x in range(1000000)] b = [1 for x in range(1000000)] time1 = time.time() c = [] for count in range(len(a)): c.append(a[count] + b[count]) time2 = time.time() print(&#39;This took %0.3f ms&#39; % ((time2-time1)*1000.0)) a = np.ones(1000000) b = np.ones(1000000) time1 = time.time() c = a + b time2 = time.time() print(&#39;This took %0.3f ms&#39; % ((time2-time1)*1000.0)) . This took 190.984 ms This took 22.381 ms . Useful functions: . z = np.random.rand(10, 20, 30) print(z.shape) . (10, 20, 30) . z_mean = np.nanmean(z, axis = 1) print(z_mean.shape) z_mean = np.nanmean(z, axis = (1,2)) print(z_mean.shape) z_mean_sqrt = np.sqrt(z_mean) # square root . (10, 30) (10,) . masked arrays . z = np.random.rand(20, 20) mask = (z &lt; 0.5) print(mask) print(mask.shape) . [[False True True True False True False False False True True False True False True True True True False True] [False True False False True True False False False True True True False True True False True False True False] [ True False False False True False True True True True False True True True True True False True False True] [ True True True False False True False False False True True True False False True True True False True True] [ True True True False True False True True True False True True False True True False False True True True] [ True True True True False True False False True True True True False False True False False False False False] [False False True True True False False True False True False True False True False False False False True False] [ True False True True False False True True True True False False False False True False False False False True] [False True False False True True False True False False False True True True True False True False False False] [False False False False False False False True False True False False False False True False True False False False] [ True True True False False True True False False True False False False False False False True True True True] [ True False False True False False True False True True False False True False True False True False True True] [ True False False False False True True True True False False True False False False True False False True True] [False False True False True True False False False False True False False True True False False False False True] [ True False False False True True False True True True True True False False True True True True True False] [ True True False True True True True False False True False True True True False True False False False True] [ True True False True False True True False False True False True False True True True False True True True] [False False False True True False False False False True False False True True True False True True False False] [ True True False True False False True False True False False False True True False True False True True True] [False True True False True True True True True True True True True False False False True False False True]] (20, 20) . z_masked = np.ma.asarray(z) z_masked.mask = mask print(z_masked) . [[0.5978333056634115 -- -- -- 0.9152501522824146 -- 0.7916287392512159 0.7928566155462591 0.8296902624971217 -- -- 0.6852856720906341 -- 0.8341387004206775 -- -- -- -- 0.8094767459639305 --] [0.5284749786477574 -- 0.9692448492945632 0.5068885461498903 -- -- 0.9982033801792924 0.6446449735549381 0.8982505405882799 -- -- -- 0.8202508382388177 -- -- 0.5371093964909518 -- 0.8842660402220104 -- 0.7842271087394086] [-- 0.7127430422749206 0.6130407399050007 0.5077916555865725 -- 0.7123875777621683 -- -- -- -- 0.9257742767168362 -- -- -- -- -- 0.7893866060110892 -- 0.8219722516595986 --] [-- -- -- 0.9511395789894707 0.5064100784906008 -- 0.7628344896078808 0.6899599400205454 0.8545623119356198 -- -- -- 0.8966124582837998 0.6751098614621039 -- -- -- 0.5599346115350089 -- --] [-- -- -- 0.6866780820516447 -- 0.9612539063235854 -- -- -- 0.7549588003015492 -- -- 0.9815310576382813 -- -- 0.6690227959138888 0.8163426414073014 -- -- --] [-- -- -- -- 0.951122571524875 -- 0.7526234074825154 0.7814204821387767 -- -- -- -- 0.8856517620807556 0.6104034095672278 -- 0.9108432333505353 0.778538501878837 0.694587660065455 0.6362099310807572 0.5446806033519845] [0.765291341112839 0.5678977599825668 -- -- -- 0.7416145588543542 0.8235160533214866 -- 0.7707774894079225 -- 0.5023683957476383 -- 0.7408438608220037 -- 0.5296017698924947 0.5082239359783319 0.6419438019001998 0.7117301668945667 -- 0.657189876311379] [-- 0.8048803074817702 -- -- 0.5607659768586147 0.529414773085168 -- -- -- -- 0.9709522752112307 0.7176384967060485 0.6245701461766041 0.9152999699249196 -- 0.6950911056628933 0.6962333701452088 0.5117383305673276 0.6562077032544125 --] [0.7180394373263428 -- 0.9327420457969964 0.7313254081696123 -- -- 0.7834917208433687 -- 0.6564836814993806 0.9486566338745831 0.9503006501814885 -- -- -- -- 0.5000568267253331 -- 0.6698741053113492 0.5467225068483047 0.8331538309312719] [0.5215265735569622 0.8640238404698893 0.6408010961069202 0.5536938469380971 0.5200815875468717 0.8826848235280155 0.9053227732031718 -- 0.5533691730783306 -- 0.9810387471501621 0.8078583036076045 0.8484515454120168 0.6874302490110933 -- 0.8639022626997208 -- 0.8799500204693254 0.8718127716771297 0.8204912819617214] [-- -- -- 0.5795894406941741 0.9565448187520345 -- -- 0.7272968720111568 0.7831777859857665 -- 0.7436871646664872 0.8611617101928444 0.676023394786886 0.7450227896716436 0.9882858446251811 0.8853471456826659 -- -- -- --] [-- 0.6576507974124693 0.7491771982051983 -- 0.8574944676437715 0.9019680472758415 -- 0.6549695482515835 -- -- 0.520695721334124 0.6362144569619924 -- 0.7534416008072654 -- 0.6885848590222653 -- 0.6994537759876023 -- --] [-- 0.7188077162195455 0.6465685521337263 0.5600527195230722 0.7742831918520511 -- -- -- -- 0.5660026791003127 0.9032330848387855 -- 0.8763993137345346 0.6583560687724255 0.7959412900351969 -- 0.927068976533419 0.8568755032734119 -- --] [0.7476169752648986 0.5234545373235526 -- 0.904445394920723 -- -- 0.8712697529733069 0.915977932603021 0.6225238810151054 0.9404663455028375 -- 0.9591144618102622 0.7461094856964241 -- -- 0.9377281247401308 0.5513308605251162 0.8118229198135797 0.5270742341408144 --] [-- 0.6118588359307 0.5934121449766 0.5753664230566036 -- -- 0.9152199517735821 -- -- -- -- -- 0.608783502674255 0.7120681303458005 -- -- -- -- -- 0.8641303762940244] [-- -- 0.8518217111151136 -- -- -- -- 0.9189100974288652 0.5894730895585055 -- 0.9728163707667034 -- -- -- 0.6073285465931129 -- 0.8148482194462799 0.578153245458349 0.5084431399278518 --] [-- -- 0.598156557892885 -- 0.7035021684172477 -- -- 0.5334056944093172 0.905543047854529 -- 0.9522679680242473 -- 0.9378657320842904 -- -- -- 0.7456640454038644 -- -- --] [0.9956038986949931 0.7055672031819478 0.7235486594711124 -- -- 0.7537276307675379 0.6893951331706245 0.6175120103700737 0.9253538077205439 -- 0.7468392921370716 0.656673742458098 -- -- -- 0.5871707737184049 -- -- 0.6037769628317056 0.7816692644108565] [-- -- 0.6330044771323631 -- 0.8888459905368238 0.6809502172023364 -- 0.7768491453561011 -- 0.7901265574453287 0.6231098759671369 0.5124489616644249 -- -- 0.8968796664387609 -- 0.6682602708851448 -- -- --] [0.8033092843471001 -- -- 0.5285349139414175 -- -- -- -- -- -- -- -- -- 0.9578748973473007 0.7048769839177969 0.5168159767357904 -- 0.7133451231643838 0.5898115526109324 --]] . import matplotlib.pyplot as plt . plt.pcolor(z) . &lt;matplotlib.collections.PolyCollection at 0x7f6de7eb0d90&gt; . plt.pcolor(z_masked) . &lt;matplotlib.collections.PolyCollection at 0x7f6de86946a0&gt; . Functions . def multiply_constant(x, constant = 5): return x * constant print(multiply_constant(5)) print(multiply_constant(5, 3)) print(multiply_constant(x = 5, constant = 3)) print(multiply_constant(a, constant = 2.5)) . 25 15 15 [2.5 2.5 2.5 ... 2.5 2.5 2.5] . Data visualization . 1D Plot . import numpy as np import matplotlib.pyplot as plt import pandas as pd x = np.arange(0,300) # Numbers from 0 to 30 (30 not included) y = np.sin(np.arange(0,300)) + np.random.normal(0,5,300) # Create sinus ##signal and add noise dataFrame = pd.DataFrame({&#39;Intervals&#39;: x, &#39;values&#39;: y}) rolling_mean = dataFrame[&#39;values&#39;].rolling(10, min_periods=1, center=True).mean() plt.plot(x,y,label=&#39;Kurve&#39;, alpha=0.5) plt.plot(x, rolling_mean.values, label = &#39;Rolling Mean&#39;) plt.title(&#39;Sinus + Random&#39;) plt.xlabel(&#39;Interval&#39;) plt.ylabel(&#39;Values&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f6e101bdd60&gt; . 2D Plots . z = np.random.rand(20,20) levels = np.linspace(0, 1, 10) f, ax = plt.subplots(1) im = ax.pcolor(z) #im = ax.contourf(z, levels = levels) #ax.contour(z) ax.set_title(&#39;Random Noise from 0 - 1&#39;) f.colorbar(im) . &lt;matplotlib.colorbar.Colorbar at 0x7f6de59b43a0&gt; . netCDF4-files . import xarray as xr url = &quot;https://ds.nccs.nasa.gov/thredds/dodsC/CMIP5/ESGF/GISS/rcp45/E2-R_rcp45_r6i1p3_day/tos_day_GISS-E2-R_rcp45_r6i1p3_20910101-21001231.nc&quot; ds = xr.open_dataset(url) . ds.isel(time = 1) . Show/Hide data repr . . . Show/Hide attributes . . . . xarray.DatasetDimensions:bnds: 2 | lat: 90 | lon: 144 | . | Coordinates: (3)time()object2091-01-02 12:00:00bounds :time_bndsaxis :Tlong_name :timestandard_name :timearray(cftime.DatetimeNoLeap(2091-01-02 12:00:00), dtype=object) . | lat(lat)float64-89.0 -87.0 -85.0 ... 87.0 89.0bounds :lat_bndsunits :degrees_northaxis :Ylong_name :latitudestandard_name :latitudearray([-89., -87., -85., -83., -81., -79., -77., -75., -73., -71., -69., -67., -65., -63., -61., -59., -57., -55., -53., -51., -49., -47., -45., -43., -41., -39., -37., -35., -33., -31., -29., -27., -25., -23., -21., -19., -17., -15., -13., -11., -9., -7., -5., -3., -1., 1., 3., 5., 7., 9., 11., 13., 15., 17., 19., 21., 23., 25., 27., 29., 31., 33., 35., 37., 39., 41., 43., 45., 47., 49., 51., 53., 55., 57., 59., 61., 63., 65., 67., 69., 71., 73., 75., 77., 79., 81., 83., 85., 87., 89.]) . | lon(lon)float641.25 3.75 6.25 ... 356.2 358.8bounds :lon_bndsunits :degrees_eastaxis :Xlong_name :longitudestandard_name :longitudearray([ 1.25, 3.75, 6.25, 8.75, 11.25, 13.75, 16.25, 18.75, 21.25, 23.75, 26.25, 28.75, 31.25, 33.75, 36.25, 38.75, 41.25, 43.75, 46.25, 48.75, 51.25, 53.75, 56.25, 58.75, 61.25, 63.75, 66.25, 68.75, 71.25, 73.75, 76.25, 78.75, 81.25, 83.75, 86.25, 88.75, 91.25, 93.75, 96.25, 98.75, 101.25, 103.75, 106.25, 108.75, 111.25, 113.75, 116.25, 118.75, 121.25, 123.75, 126.25, 128.75, 131.25, 133.75, 136.25, 138.75, 141.25, 143.75, 146.25, 148.75, 151.25, 153.75, 156.25, 158.75, 161.25, 163.75, 166.25, 168.75, 171.25, 173.75, 176.25, 178.75, 181.25, 183.75, 186.25, 188.75, 191.25, 193.75, 196.25, 198.75, 201.25, 203.75, 206.25, 208.75, 211.25, 213.75, 216.25, 218.75, 221.25, 223.75, 226.25, 228.75, 231.25, 233.75, 236.25, 238.75, 241.25, 243.75, 246.25, 248.75, 251.25, 253.75, 256.25, 258.75, 261.25, 263.75, 266.25, 268.75, 271.25, 273.75, 276.25, 278.75, 281.25, 283.75, 286.25, 288.75, 291.25, 293.75, 296.25, 298.75, 301.25, 303.75, 306.25, 308.75, 311.25, 313.75, 316.25, 318.75, 321.25, 323.75, 326.25, 328.75, 331.25, 333.75, 336.25, 338.75, 341.25, 343.75, 346.25, 348.75, 351.25, 353.75, 356.25, 358.75]) . | . | Data variables: (4)time_bnds(bnds)object...array([cftime.DatetimeNoLeap(2091-01-02 00:00:00), cftime.DatetimeNoLeap(2091-01-03 00:00:00)], dtype=object) . | lat_bnds(lat, bnds)float64...array([[-90., -88.], [-88., -86.], [-86., -84.], [-84., -82.], [-82., -80.], [-80., -78.], [-78., -76.], [-76., -74.], [-74., -72.], [-72., -70.], [-70., -68.], [-68., -66.], [-66., -64.], [-64., -62.], [-62., -60.], [-60., -58.], [-58., -56.], [-56., -54.], [-54., -52.], [-52., -50.], [-50., -48.], [-48., -46.], [-46., -44.], [-44., -42.], [-42., -40.], [-40., -38.], [-38., -36.], [-36., -34.], [-34., -32.], [-32., -30.], [-30., -28.], [-28., -26.], [-26., -24.], [-24., -22.], [-22., -20.], [-20., -18.], [-18., -16.], [-16., -14.], [-14., -12.], [-12., -10.], [-10., -8.], [ -8., -6.], [ -6., -4.], [ -4., -2.], [ -2., 0.], [ 0., 2.], [ 2., 4.], [ 4., 6.], [ 6., 8.], [ 8., 10.], [ 10., 12.], [ 12., 14.], [ 14., 16.], [ 16., 18.], [ 18., 20.], [ 20., 22.], [ 22., 24.], [ 24., 26.], [ 26., 28.], [ 28., 30.], [ 30., 32.], [ 32., 34.], [ 34., 36.], [ 36., 38.], [ 38., 40.], [ 40., 42.], [ 42., 44.], [ 44., 46.], [ 46., 48.], [ 48., 50.], [ 50., 52.], [ 52., 54.], [ 54., 56.], [ 56., 58.], [ 58., 60.], [ 60., 62.], [ 62., 64.], [ 64., 66.], [ 66., 68.], [ 68., 70.], [ 70., 72.], [ 72., 74.], [ 74., 76.], [ 76., 78.], [ 78., 80.], [ 80., 82.], [ 82., 84.], [ 84., 86.], [ 86., 88.], [ 88., 90.]]) . | lon_bnds(lon, bnds)float64...array([[ 0. , 2.5], [ 2.5, 5. ], [ 5. , 7.5], ..., [352.5, 355. ], [355. , 357.5], [357.5, 360. ]]) . | tos(lat, lon)float32...standard_name :surface_temperaturelong_name :Sea Surface Temperaturecomment :temperature of liquid ocean. Note that the correct standard_name for this variable is &quot;&quot;sea_surface_temperature&quot;&quot;, not &quot;&quot;surface_temperature&quot;&quot;, but this was discovered too late to correct. To maintain consistency across CMIP5 models, the wrong standard_name will continue to be used.units :Koriginal_name :dummycell_methods :time: meancell_measures :area: areacellohistory :2012-09-27T15:35:07Z altered by CMOR: replaced missing value flag (-1e+30) with standard missing value (1e+20).associated_files :baseURL: http://cmip-pcmdi.llnl.gov/CMIP5/dataLocation gridspecFile: gridspec_ocean_fx_GISS-E2-R_rcp45_r0i0p0.nc areacello: areacello_fx_GISS-E2-R_rcp45_r0i0p0.ncarray([[ nan, nan, nan, ..., nan, nan, nan], [ nan, nan, nan, ..., nan, nan, nan], [ nan, nan, nan, ..., nan, nan, nan], ..., [271.45233, 271.45172, 271.49725, ..., 271.50067, 271.48697, 271.47012], [271.5155 , 271.50873, 271.50183, ..., 271.53275, 271.52777, 271.5219 ], [271.56015, 271.56015, 271.56015, ..., 271.56015, 271.56015, 271.56015]], dtype=float32) . | . | Attributes: (28)institution :NASA/GISS (Goddard Institute for Space Studies) New York, NYinstitute_id :NASA-GISSexperiment_id :rcp45source :GISS-E2-R-E134TcadiRCP45fF40oQ32 Atmosphere: GISS-E2; Ocean: Rmodel_id :GISS-E2-Rforcing :GHG, LU, Sl, Vl, BC, OC, SA, Oz (also includes orbital change - BC on snow - Nitrate aerosols - interactive CH4)parent_experiment_id :historicalparent_experiment_rip :r6i1p3branch_time :2006.0contact :Kenneth Lo (cdkkl@giss.nasa.gov)references :http://data.giss.nasa.gov/modelE/ar5initialization_method :1physics_version :3tracking_id :b2041a15-ef72-4217-914e-fbbb361a5f72product :outputexperiment :RCP4.5frequency :daycreation_date :2012-09-27T15:35:07Zhistory :2012-09-27T15:35:07Z CMOR rewrote data to comply with CF standards and CMIP5 requirements.Conventions :CF-1.4project_id :CMIP5table_id :Table day (27 April 2011) 86d1558d99b6ed1e7a886ab3fd717b58title :GISS-E2-R model output prepared for CMIP5 RCP4.5parent_experiment :historicalmodeling_realm :oceanrealization :6cmor_version :2.5.7DODS_EXTRA.Unlimited_Dimension :time | . ds.isel(time = 1).tos.plot() . &lt;matplotlib.collections.QuadMesh at 0x7f6de295a4f0&gt; . tmp = ds.sel(lon = slice(150,200)).isel(time = slice(1,100)).tos.mean([&quot;lon&quot;,&quot;lat&quot;]) . tmp.plot() . [&lt;matplotlib.lines.Line2D at 0x7f6de2770310&gt;] . tmp.rolling(time = 10, min_periods =1).mean().plot() . [&lt;matplotlib.lines.Line2D at 0x7f6de281cc10&gt;] .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/09/introduction_to_python.html",
            "relUrl": "/jupyter/2020/11/09/introduction_to_python.html",
            "date": " • Nov 9, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Red noise",
            "content": "Hasselmann (as explained by Dommenget and Latif, 2000) . Hasselmann (1976) attempts to explain the mechanism of natural climate variabilty by dividing the climate system into a fast system and a slow system. The fast system could be the atmosphere, represented as white noise. The slower component is the ocean and is explained by the integration of white noise (AR-1). In this picture the ocean is merely a passive part of the climate system, which amplifies long-term variability, due to its large heat capacity, but dynamical processes in the ocean are not considered. . The resulting stochastic model of the SST variability is described by an autoregressive process of the first order, which is the simplest statistical model that can be applied to a stationary process. The stochastic climate model by Hasselmann is tehrefore often chosen as the null hypothesis of SST variability. . Slab ocean-atmosphere models can be regarded as a numerical realization of the null hypothesis (AR(1)-process) of Hasselmann&#39;s stochastic climate model. . The null hypothesis of SST variability in the midlatitudes, described by Hasselmann&#39;s stochastic climate model, assumes that the SST variability is well described by the integration of the atmospheric heat flux with the heat capacity of the ocean&#39;s mixed layer. . $ frac{d SST}{dT} = frac{1}{C_p rho_w d_{mix}}* F + Delta T_c$ . $C_p$ = specifc heat of sea water . $ rho_w$ = density of sea water . $d_{mix}$ = depth of mixed layer . $F$ = net atmospheric heat flux . $ Delta T_c$ = climatology temperature correction . The only free parameter in this eqaution is the mixed layer depth, which was chosen to be 50 meters for all points. This value is roughly the global mean vlaue for the mixed layer depth as was determinded from the observations by Levitus (1982). . Redness of the SST anomalies . The standard deviation of the SST anoamlies do not aloine describe the large-scale character of the SST varaiblity. An important feature of the SSt variability is the increase of the variance in the SST power spectra with period, which is the so called redness of the spectra. If the SST anomalies follow an AR(1)-process than the redness can be estimated by the lag-1 correlation. . $C( omega) = frac{ sigma^2}{(1- alpha)^2+ omega^2}$ . $ sigma$ = standard deviation . $ omega$ = frequency . $ alpha$ = lag-1 correlation based on monthly mean time series . The increase of $C( omega)$ is only a function of $ alpha$, hence the redness $Q_{red}$ can be defined as . $Q_{red}$ = $ frac{1}{(1- alpha)^2}$ . Conclusions . fully coupled models are signifcantly different in terms of large-scale features of the SST variability than slab ocean models | only slab ocean models can be regarded as an AR(1) process | The diference between the AR(1)-process and the SST spectra in the simulations with fully dynamical ocean models is characterized by a slower increase of the SST variance from the shorter time periods to the longer time periods, which leads to increased variance of the SST on the seasonal and the decadal timescale relative to the fitted AR(1)-process. AMO and AMOC. . Simple red noise null hypothesis . c1 = 1 c2 = 0.86 c3 = 0.01 f, ax = plt.subplots(3, figsize = (12,4)) ax = ax.ravel() for realisation in range(0,3): white_noise_sequence = np.random.normal(0, 1, 1000) red_noise_sequence1 = np.zeros((len(white_noise_sequence))) red_noise_sequence2 = np.zeros((len(white_noise_sequence))) red_noise_sequence3 = np.zeros((len(white_noise_sequence))) for i in range(1, len(white_noise_sequence)): red_noise_sequence1[i] = c1 * red_noise_sequence1[i-1] + white_noise_sequence[i] red_noise_sequence2[i] = c2 * red_noise_sequence2[i-1] + white_noise_sequence[i] red_noise_sequence3[i] = c3 * red_noise_sequence3[i-1] + white_noise_sequence[i] ax[0].plot(red_noise_sequence1) ax[1].plot(red_noise_sequence2) ax[2].plot(red_noise_sequence3) .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/05/red_noise_binder.html",
            "relUrl": "/jupyter/2020/11/05/red_noise_binder.html",
            "date": " • Nov 5, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Main site florianboergel.github.io [^1]. . On this side, you can find some code and lecture examples. .",
          "url": "https://florianboergel.github.io/personal_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://florianboergel.github.io/personal_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}