{
  
    
        "post0": {
            "title": "Exercise 1, policy goals under uncertainty",
            "content": "Exercise 1, policy goals under uncertainty . A recent ground-breaking review paper produced the most comprehensive and up-to-date estimate of the climate feedback parameter, which they find to be . $B approx mathcal{N}(-1.3, 0.4),$ . i.e. our knowledge of the real value is normally distributed with a mean value $ overline{B} = -1.3$ W/m²/K and a standard deviation $ sigma = 0.4$ W/m²/K. These values are not very intuitive, so let us convert them into more policy-relevant numbers. . Definition: Equilibrium climate sensitivity (ECS) is defined as the amount of warming $ Delta T$ caused by a doubling of CO₂ (e.g. from the pre-industrial value 280 ppm to 560 ppm), at equilibrium. . At equilibrium, the energy balance model equation is: . $0 = frac{S(1 - α)}{4} - (A - BT_{eq}) + a ln left( frac{2 ; text{CO}₂_{ text{PI}}}{ text{CO}₂_{ text{PI}}} right)$ . From this, we subtract the preindustrial energy balance, which is given by: . $0 = frac{S(1-α)}{4} - (A - BT_{0}),$ . The result of this subtraction, after rearranging, is our definition of $ text{ECS}$: . $ text{ECS} equiv T_{eq} - T_{0} = - frac{a ln(2)}{B}$ .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/14/climate-of-the-ocean-h1.html",
            "relUrl": "/jupyter/2020/11/14/climate-of-the-ocean-h1.html",
            "date": " • Nov 14, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Lecture 4, Snowball Earth, the ice-albedo feedback, and multiple equilibria",
            "content": "Thanks a lot to Henri Drake for providing the lecture. . The original lecture is part of the MIT class Introduction to Computational Thinking. . This class uses the Julia programming language. The orignal code can be found under https://github.com/hdrake/simplEarth/blob/master/2_ebm_multiple_equilibria.jl . Snowball Earth, the ice-albedo feedback, and multiple equilibria . Source (New York Times) . Review of Lecture 2 . Recall from the last Lecture that the zero-dimensional energy balance equation is . begin{gather} color{brown}{C frac{dT}{dt}} ; color{black}{=} ; color{orange}{ frac{(1 - α)S}{4}} ; color{black}{-} ; color{blue}{(A - BT)} ; color{black}{+} ; color{grey}{a ln left( frac{[ text{CO}₂]}{[ text{CO}₂]_{ text{PI}}} right)}, end{gather} . Today, we will ignore changes in CO$_2$, so that . $ ln left( frac{ [ text{CO}₂]_{ text{PI}} }{[ text{CO}₂]_{ text{PI}}} right) = ln(1) = 0$ . and the model simplifies to . begin{gather} color{brown}{C frac{dT}{dt}} ; color{black}{=} ; color{orange}{ frac{(1 - α)S}{4}} ; color{black}{-} ; color{blue}{(A - BT)}. end{gather}The dynamics of this Ordinary Differential Equation (ODE) are quite simple because it is linear: we can rewrite it in the form . $$ dot{T} = f(T(t))$$ . where . $$f(x) = alpha x + beta$$ . is a linear function of x. A linear ODE permits only one stable solution, $ dot{T} = 0$, which in Lecture 1 we found was Earth&#39;s pre-industrial temperature $T_{0} = 14$°C. . In this lecture, we show how a small modification that makes one term in our simple climate model non-linear completely changes its dynamics, allowing us to explain the existence of both &quot;Snowball Earth&quot; and the relatively warm pre-industrial climate that allowed humans to thrive. . import numpy as np import xarray as xr import matplotlib.pyplot as plt from ipywidgets import interact, interactive, fixed, interact_manual import ipywidgets as widgets from IPython.display import HTML from IPython.display import display . 1) Background: Snowball Earth . Geological evidence shows that the Neoproterozoic Era (550 to 1000 million years ago) is marked by two global glaciation events, in which Earth&#39;s surface was covered in ice and snow from the Equator to the poles (see review by Pierrehumbert et al. 2011. . . 1.1) The ice-albedo feedback . In Lecture 1, we used a constant value $α = 0.3$ for Earth&#39;s planetary albedo, which is a reasonable thing to do for small climate variations relative to the present (such as the difference between the present-day and preindustrial climates). In the case of large variations, however, this approximation is not very reliable. . While oceans are dark and absorbant, $α_{ocean} approx 0.05$, ice and snow are bright and reflective: $ alpha_{ice, ,snow} approx 0.5$ to $0.9$. Thus, if much of the ocean&#39;s surface freezes over, we expect Earth&#39;s albedo to rise dramatically, causing more sunlight to be reflected to space, which in turn causes even more cooling and more of the ocean to freeze, etc. This non-linear positive feedback effect is referred to as the ice-albedo feedback (see illustration below). . . We can represent the ice-albedo feedback crudely in our energy balance model by allowing the albedo to depend on temperature: . $$ alpha(T) = begin{cases} alpha_{i} &amp; mbox{if } ; ; T leq -10 text{°C} &amp; text{(completely frozen)} alpha_{i} + ( alpha_{0}- alpha_{i}) frac{T + 10}{20} &amp; mbox{if } ; ; -10 text{°C} leq T leq 10 text{°C} &amp; text{(partially frozen)} alpha_{0} &amp; mbox{if } ; ; T geq 10 text{°C} &amp; text{(no ice)} end{cases}$$ 1.2) Adding the ice-albedo feedback to our simple climate model . First, we program albedo as a function of temperature. . def calc_alpha(T, alpha0, alphai = 0.5, deltaT=10.): if T &lt; - deltaT: return alphai elif -deltaT &lt;= T &lt; deltaT: return alphai + (alpha0 - alphai)*(T + deltaT) / (2*deltaT) elif T &gt;= deltaT: return alpha0 . calc_alpha_vec = np.vectorize(calc_alpha) # boolean evaluations need to be vectorized T_example = np.arange(-20, 20) plt.plot(T_example, calc_alpha_vec(T_example[:], 0.3), color = &quot;black&quot;) plt.ylim(0.2,0.6) plt.plot([-20, -10], [0.2, 0.2]) plt.fill_between([-20, -10], y1=0.2, y2=0.6, color = &quot;lightblue&quot;, alpha = 0.2) plt.fill_between([10, 20], y1=0.2, y2=0.6, color = &quot;red&quot;, alpha = 0.12) plt.ylabel(&quot;albedo $α$ n(planetary reflectivity)&quot;) plt.xlabel(&quot;Temperature [°C]&quot;) plt.text(-18.5, 0.252, s=&quot;completely nfrozen&quot;, size=10, color=&quot;darkblue&quot;) plt.text(-3, 0.252, s=&quot;partiall frozen&quot;, size=10, color=&quot;darkgrey&quot;) plt.text(13, 0.252, s=&quot;no ice&quot;, size=10, color=&quot;darkred&quot;) . Text(13, 0.252, &#39;no ice&#39;) . To add this function into our energy balance model from Lecture 1 (which we&#39;ve copied into the cell below), all we have to do is overwrite the definition of the timestep! method to specify that the temperature-dependent albedo should be updated based on the current state: . class ebm(): &quot;&quot;&quot; Zero order energy balance model &quot;&quot;&quot; def __init__(self, T, t, deltat, CO2): self.T = np.array(T) self.t = t self.deltat = deltat self.C = 51. self.a = 5. self.B = -1.3 self.co2_pi = 280. self.alpha = 0.3 self.S = 1368. self.co2 = CO2 self.CO2_PI = 280. self.A = 221.2 def absorbed_solar_radiation(self): return (self.S*(1-self.alpha2)/4.) # [W/m^2] def outgoing_thermal_radiation(self): if self.T.size == 1: return self.A - self.B*self.T else: return self.A - self.B*self.T[-1] def greenhouse_effect(self): if self.T.size == 1: return self.a*np.log(self.co2(self.t)/self.CO2_PI) else: return self.a*np.log(self.co2(self.t[-1])/self.CO2_PI) def tendency(self): if self.T.size == 1: return 1. / self.C * ( + self.absorbed_solar_radiation() - self.outgoing_thermal_radiation() + self.greenhouse_effect() ) else: return 1. / self.C * ( + self.absorbed_solar_radiation() - self.outgoing_thermal_radiation() + self.greenhouse_effect() ) def run(self, end_year): for year in range(end_year): self.timestep() def timestep(self): if self.T.size == 1: self.alpha2 = calc_alpha(self.T, alpha0=self.alpha) # Added the function call here self.T = np.append(self.T, self.T + self.deltat * self.tendency()) self.t = np.append(self.t, self.t + self.deltat) else: self.alpha2 = calc_alpha(self.T[-1], alpha0=self.alpha) # Added the function call here self.T = np.append(self.T, self.T[-1] + self.deltat * self.tendency()) self.t = np.append(self.t, self.t[-1] + self.deltat) . 2) Multiple Equilibria . OR: the existence of &quot;alternate Earths&quot; . Human civilization flourished over the last several thousand years in part because Earth&#39;s global climate has been remarkably stable and forgiving. The preindustrial combination of natural greenhouse effect and incoming solar radiation yielded temperatures between the freezing and boiling points of water across most of the planet, allowing ecoystems based on liquid water to thrive. . The climate system, however, is rife with non-linear effects like the ice-albedo effect, which reveal just how fragile our habitable planet is and just how unique our stable pre-industrial climate was. . We learned in the last lecture that in response to temperature fluctuations, net-negative feedbacks act to restore Earth&#39;s temperature back towards a single equilibrium state in which absorbed solar radiation is balanced by outgoing thermal radiation. Here, we explore how non-linear positive feedbacks can temporarily result in a net-positive feedback and modify Earth&#39;s state space. . def CO2_const(t): # define CO2 scenario return 280 . f, (ax) = plt.subplots(1, figsize = (8,8)) for count, T0_sample in enumerate(range(-60, 30, 5)): EBM = ebm(T0_sample, 0, 1., CO2_const) EBM.run(200) ax.plot(EBM.t, EBM.T) ax.set_xlabel(&quot;year&quot;) ax.set_ylabel(&quot;Temperature [°C]&quot;) ax.set_ylim(-60,30) ax.text(120,-25, s=&quot;Completly frozen&quot;, size = 10, color = &quot;darkblue&quot;) ax.fill_between([0, 200], y1=-60, y2=-10, color = &quot;lightblue&quot;, alpha = 0.2) ax.fill_between([0, 200], y1=10, y2=30, alpha=0.09, color=&quot;red&quot;) ax.text(120,20, s=&quot;no ice&quot;, size = 10, color = &quot;darkred&quot;) T_un = 7.5472 deltaTs = 1e-2*np.array([-2, -1., 0., 1., 2.]) for deltaT in deltaTs: ebm_un = ebm(T_un+deltaT, 0., 1, CO2_const) ebm_un.run(200) ax.plot(ebm_un.t, ebm_un.T, ls = &quot;--&quot;) ax.grid() ax.plot(200, 14, marker=&quot;o&quot;, label=&quot;Our pre-industrial climate (stable &#39;&#39;warm&#39;&#39; branch)&quot;, color=&quot;orange&quot;, markersize=8) ax.plot(200, -38.3, marker=&quot;o&quot;, label=&quot;Alternate universe pre-industrial climate (stable &#39;&#39;cold&#39;&#39; branch)&quot;, color=&quot;aqua&quot;, markersize=8) ax.plot(200, T_un, marker=&quot;o&quot;, label=&quot;Impossible alternate climate (unstable branch&quot;, color=&quot;lightgrey&quot;, markersize=8) ax.legend(loc=4) . &lt;matplotlib.legend.Legend at 0x7f7c5296b340&gt; . We see that for T₀ ⪆ 7.55 °C, all of the curves seem to converge on the T = 14°C equilibrium (or fixed point) that we saw in Lecture 20. Curves that start below this value warm up and while curves that start above this value will cool down. For T₀ ⪅ 7.55 °C, however, the temperatures converge on a much colder equilibrium around T = -40°C. This is the Snowball Earth equilibrium. These two states are referred to as stable equilibria because even if the state gets temporarily pushed slightly away from its equilibrium, it will eventually converge right back to its equilibrium. . So what happens is T₀ ≈ 7.55 °C? For some exact temperature near there, there is indeed an equilibrim state: if you start with that temperature you will stay there forever. However, if the temperature starts off even one one-hundredth of a degree above or below this exact value, we see that temperatures eventually converge to one of the other two equilibria. Thus, we call this intermediate equilibrium an unstable equilibrium, because any infinitesimal push away will cause it to careen away towards another state. . Excourse: . Nonlinear dynamics: stability and bifurcations | . https://github.com/mitmath/18S191/blob/master/lecture_notebooks/week11/nonlinear_dynamics_bifurcations.jl . 2.2) Radiative stability analysis . We can understand why our model has two stable equilibria and one unstable equilibrium by applying concepts from dynamical systems theory. . Recall that, with fixed CO₂ concentrations, our energy balance model differential equation can be expressed as: . $$C frac{dT}{dT} = ASR(T) - OTR(T)$$ . where now the Absorbed Solar Radiatio (ASR) is also temperature dependent because the albedeo $ alpha (T)$ is. . In particular, by plotting the right-hand-side tendency terms as a function of the state variable $T$, we can plot a stability diagram for our system that tells us whether the plan will warm ($C frac{dT}{dt}$ &gt; 0) or cool ($C frac{dT}{dt}$ &lt; 0) . EBM = ebm(T_un, 0., 1, CO2_const) temp_range = np.arange(-60, 30) OTR, ASR = np.zeros((len(temp_range))), np.zeros((len(temp_range))) for count, i in enumerate(temp_range): EBM.T = np.array(i) EBM.alpha2 = calc_alpha(EBM.T, EBM.alpha) OTR[count] = EBM.outgoing_thermal_radiation() ASR[count] = EBM.absorbed_solar_radiation() imbalance = ASR - OTR . f, (ax, bx) = plt.subplots(1,2, figsize=(8,4)) ax.plot(temp_range, OTR, label= &quot;Outgoing Thermal Radiation&quot;) ax.plot(temp_range, ASR, label = &quot;Absorbed Solar Radiation&quot;) ax.set_xlabel(&quot;temperature [°C]&quot;) ax.set_ylabel(&quot;energy flux [W/$m^2$]&quot;) bx.fill_between([-60, 30], y1=0, y2=40, alpha=0.2, color=&quot;red&quot;) bx.fill_between([-60, 30], y1=-50, y2=0, alpha=0.2, color=&quot;blue&quot;) bx.set_xlabel(&quot;temperature [°C]&quot;) bx.set_ylabel(&quot;energy flux [W/$m^2$]&quot;) bx.set_ylim(-50,40) bx.plot(temp_range, imbalance, color = &quot;black&quot;, label = &quot;Radiative Imbalance n (ASR-OTR)&quot;) bx.text(-60, 35, &quot;warming&quot;, color =&quot;darkred&quot;, size = 12) bx.text(-60, -40, &quot;cooling&quot;, color =&quot;darkblue&quot;, size = 12) ax.legend(); bx.legend() ax.grid(); bx.grid() f.tight_layout() . 3) Transitioning to and from Snowball Earth . 3.1) Turning up the Sun . Over the entire history of the Earth, the Sun is thought to have brightened by about 40%. . . In the Neoproterozoic (~700 million years ago), the Sun was 93% as bright as it is today, such that the incoming solar radiation was $S$ = 1272 W/m², Earth&#39;s average temperature plunged to $T = -50$°C, and Earth&#39;s ice-covered surface had a high albedo (reflectivity) of $ alpha_i = 0.5$. . 3.2) Did the increasing brightness of the Sun melt the Snowball? . If we start out in the Neoproterozoic climate and all we do is increase solar insolation to today&#39;s value of $ S = 1368 W/m^2$, can we warm the planet up to the pre-industrial temperature of T = 14°C? . smin = 1200 smax = 1800 smax_limited = 1650 svec = np.arange(smin, smax) svec = np.append(svec, svec[::-1]) tvec = np.zeros(svec.size) . t_restart = -100 for i, S in enumerate(svec): EBM = ebm(t_restart, 0., 5., CO2_const); EBM.S = S EBM.run(400) t_restart = EBM.T[-1] tvec[i] = EBM.T[-1] . plt.figure(figsize = (8,6)) plt.plot(svec[0:len(svec)//2], tvec[0:len(svec)//2], color = &quot;blue&quot;, label = &quot;cool branch&quot;, alpha = 0.3) plt.plot(svec[len(svec)//2:], tvec[len(svec)//2:], color = &quot;red&quot;, label = &quot;warm branch&quot;, alpha = 0.3) plt.axvline(1368, color = &quot;yellow&quot;, lw = 5, alpha = 0.2, label = &quot;Pre-industiral / present insolation&quot;) plt.plot(1368, tvec[svec==1368][1], marker=&quot;o&quot;, label=&quot;Our preindustrial climate&quot;, color=&quot;orange&quot;, markersize=8) plt.plot(1368, tvec[svec==1368][0], marker=&quot;o&quot;, label=&quot;Alternate preindustrial climate&quot;, color=&quot;lightblue&quot;, markersize=8) plt.plot(1368*0.93, -48, marker=&quot;o&quot;, label=&quot;neoproterozoic (700 Mya)&quot;, color=&quot;lightgrey&quot;, markersize=8) plt.xlabel(&quot;solar insolation S [W/m$^2$]&quot;) plt.ylabel(&quot;Global temperature T [°C]&quot;) plt.fill_between([1200, 1800], y1=-60, y2=-10, color = &quot;lightblue&quot;, alpha = 0.2) plt.fill_between([1200, 1800], y1=10, y2=70, alpha=0.09, color=&quot;red&quot;) plt.ylim(-60,70) plt.xlim(1200,1800) plt.legend() plt.grid() . Abrupt climate transitions . In this model, temperature variations are fairly smooth unless temperatures rise above -10°C or fall below 10°C, in which case the ice-albedo positive feedback kicks in and causes an abrupt climate transition. While this is just a simple hypothetical model, these kinds of abrupt climate transitions show up all the time in the paleoclimate record and in more realistic climate model simulations. . This simulation teaches us that we should not take the stability of our climate for granted and that pushing our present climate outside of its historical regime of stability could trigger catastrophic abrupt climate transitions. . 3.3) If not the Sun, how did Snowball Earth melt? . The leading theory is that a slow but steady outgassing of CO$_2$ from volcanoes eventually caused a strong enough greenhouse gas effect to offset the cooling effect of the frozen surface&#39;s high albedo and raise temperatures above the melting point $-10$°C. . . In Homework 1, you will extend the above model to include the effect of CO₂ and determine how much CO2 would need to be added to the snowball for it to melt. . Towards realistic climate modelling . In this simple model, the preindustrial climate of °C is so warm that there is no ice anywhere on the planet. Indeed, the only two valid stable climates are one with no ice or one with ice everywhere. . So how did Earth&#39;s preindustrial climate, which was relatively stable for thousands of years, have substantial ice caps at the poles? . The &quot;Aquaplanet&quot;, a simple three-dimensional ocean-world climate model . An &quot;Aquaplanet&quot; is a three-dimensional global climate simulation of a hypothetical planet covered entirely by a single global Ocean. While this is of course very different from Earth, where 27% of the planet is covered in land, the &quot;Aquaplanet&quot; exhibits many of the same characteristics as Earth and is much more realistic than our zero-dimensional climate model above. . The video below shows that the Aquaplanet simulation exhibits a third equilibrium state, with a mostly-liquid ocean but ice caps at the poles, in addition to the two we found in our zero-dimensional model. . In Homework 10, you will build a simple two-dimensional version of the aqua-planet and explore its stability. .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/13/ice-albedo.html",
            "relUrl": "/jupyter/2020/11/13/ice-albedo.html",
            "date": " • Nov 13, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Lecture 3, Nonlinear dynamics, stability and bifurcations",
            "content": "Thanks a lot to David P. Sanders for providing the lecture. The original lecture is part of the MIT class Introduction to Computational Thinking. . This class uses the Julia programming language. The orignal code can be found under github.com . import numpy as np import matplotlib.pyplot as plt from ipywidgets import interact, interactive, fixed, interact_manual import ipywidgets as widgets from IPython.display import HTML from IPython.display import display . import warnings warnings.filterwarnings(&quot;ignore&quot;) . %matplotlib inline . How does the climate change over time? In the last lecture we saw that our simple model is already quite good simulating how the climate changes over time. . Our simple model is based on ordinary differential equations (ODEs), where some variables change in time - with the rate of change as function of their current values. . $$ frac{dx(t)}{dt} = f(x(t)) $$ . The simplest numerical method to solve such an equation is the (forward) Euler method, in which we convert this equation into an explicit time-stepping routine: . $$ frac{dx(t)}{dt} = frac{x(t+ Delta t) - x(t)}{ Delta t}$$ . with the approximation . $$ x(t+ Delta t) simeq x(t) + Delta t f(x(t)) $$ . Solving the ODE: Euler method . Let&#39;s use this to simulate a simple nonlinear ODE that describes the dynamics of a population of bacteria. The bacteria will grow by reproduction at a rate $ lambda$ provided there is sufficient food, in which case we would have $ dot{x} = lambda x$. But the available food will actually always limit the sustainable population to a value $K$. A simple model for this is as follows: . $$ dot{x} = lambda , x , (K - x).$$ . When $x$ is close to $0$, the growth rate is $ lambda$, but that rate decreases as $x$ increases. . This is sometimes called the logistic differential equation (although the name does not seem particularly helpful). . Our goal is to use computational thinking, but we will actually not be interested so much in the exact dynamics in time, but rather in the qualitative features of the behaviour of the system. For example, at long times (formally $t to infty$) does the population get arbitrarily large? Or does it, for example, oscillate around a particular value? Or does it converge to a particular size? This forms the subject of nonlinear dynamics or dynamical systems theory. . Let&#39;s simulate the system using the Euler method to try to guess the answer to this question. We should never use the Euler method in practice, but should use a tried and tested library instead, and algorithms that provide much better accuracy in the solutions, if we are interested in faithful numerical results. . We&#39;ll rescale the variables to the simplest form: . $$ frac{dx}{dt} = x ,(1-x) $$ . $$ x_{n+1} = x_n + Delta t cdot text{tendency}(x_n; ...)$$ . def logistic(x, timesteps): x = np.asarray(x) for i in np.diff(timesteps): if x.size == 1: x = np.append(x, x + i * x * (1-x)) else: x = np.append(x, x[-1] + i * x[-1] * (1-x[-1])) return x . t1 = np.arange(0,20, 0.01) dxdt = logistic(0.5, t1) . plt.plot(t1, dxdt) . [&lt;matplotlib.lines.Line2D at 0x7f7078e22bb0&gt;] . We see that for this particular initial condition, the solution seems to settle down to a fixed value after some time, and then remains at that value thereafter. Such a value is called a fixed point or a stationary point of the ODE. . Qualitative behaviour: Fixed points and their stability . But what happens if we have a different initial condition: . tag = HTML(&#39;&#39;&#39;&lt;script&gt; code_show=true; function code_toggle() { if (code_show){ $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).hide(); } else { $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).show(); } code_show = !code_show } $( document ).ready(code_toggle); &lt;/script&gt; To show/hide this cell&#39;s raw code input, click &lt;a href=&quot;javascript:code_toggle()&quot;&gt;here&lt;/a&gt;.&#39;&#39;&#39;) display(tag) def plot_func(initial_condition): plt.figure(figsize=(8,8)) plt.plot(t1, logistic(initial_condition, t1)) plt.xlabel(&quot;t&quot;) plt.ylabel(&quot;x(t)&quot;) plt.xlim([0,10]) plt.ylim(-1, 2) plt.grid() plt.show() interact(plot_func, initial_condition = widgets.FloatSlider(value = 0.5, min = -1, max = 2, step = 0.1)) . &lt;function __main__.plot_func(initial_condition)&gt; . To get an overview, we can draw all graphs in a single plot. . plt.figure(figsize=(8,8)) for initial_condition in np.arange(-1, 2, 0.1): plt.plot(t1, logistic(initial_condition, t1)) plt.xlabel(&quot;t&quot;) plt.ylabel(&quot;x(t)&quot;) plt.xlim([0,10]) plt.ylim(-1, 2) plt.grid() plt.show() . We see that all the curves starting near to $x_0=1.0$ seem to converge to 1 at long times. If the system starts exactly at 0 then it stays there forever. However, if it starts close to 0, on either side, then it moves away from 0 (on that same side of 0) -- starting from a negative value $x$ becomes ever more negative. (Even though negative populations have no meaning in the original interpretation as the dynamics of a population, we can still ask study the dynamics of the equation with negative initial conditions, since it may model other systems too.) . The special values $x^*_1=1$ and $x^*_2=0$ are called stationary points or fixed points of the differential equation. If we start at $x^*_i$, then the derivative there is $f&#39;(x^*_i) = 0$, and hence we cannot move away from $x^*_i$! The fixed points can be found as zeros or roots of the function $f$, i.e. values $x^*$ such that $f(x^*) = 0$. . We see, though, that the two types of fixed points are qualitatively different: trajectories that start close to $x^*_1 = 1$ move towards $x^*_1$, whereas trajectories that start close to $x^*_2 = 0$ move away from it. We say that $x^*_1$ is a stable fixed point and $x^*_2$ is an unstable fixed point. . In general it is not possible to find analytical formulas for the position and stability of fixed points; instead, we can use numerical root-finding algorithms, for example the Newton method. . State space: Vector field and phase portrait . If we want to find the whole trajectory for a given initial condition then we need to solve the equations, either numerically or analytically. . However, we may want less information about the system, for example the long-time or asymptotic dynamics. It turns out that we can obtain some information about that without explicitly solving the ODE! This is the qualitative approach to studying nonlinear systems. . Instead of drawing trajectories $x(t)$ as a function of time $t$, as we did above, let&#39;s use a different graphical representation, where we draw state space or phase space: This is the set (&quot;space&quot;) of all possible values of the dependent variables (&quot;states&quot;). For the above ODE there is only a single dependent variable, $x$, so the state space is the real line, $ mathbb{R}$. . At each possible value of $x$, the ODE gives us information about the rate of change of $x(t)$ at that point. Let&#39;s draw an arrow at that point, pointing in the direction that a particle placed at that point would move: to the right if $ dot{x} &gt; 0$ and to the left if $ dot{x} &lt; 0$. . tag = HTML(&#39;&#39;&#39;&lt;script&gt; code_show=true; function code_toggle() { if (code_show){ $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).hide(); } else { $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).show(); } code_show = !code_show } $( document ).ready(code_toggle); &lt;/script&gt; To show/hide this cell&#39;s raw code input, click &lt;a href=&quot;javascript:code_toggle()&quot;&gt;here&lt;/a&gt;.&#39;&#39;&#39;) display(tag) states = np.array([]) initial_conditions = np.arange(-1, 2, 0.1) for initial_condition in initial_conditions: states = np.append(states, logistic(initial_condition, t1)[-1]) X = np.ones(len(states)) Y = initial_conditions.copy() U = np.zeros(len(states)) V = np.ones(len(states)) V[states - initial_conditions &lt; 0] = -1 states[states == -np.inf] = 2 plt.figure(figsize=(2,8)) plt.quiver(X, Y, U, V, scale = 10, width = 0.02) plt.plot([1,1],[1,1], marker = &#39;o&#39;, markersize = 12) plt.plot([1,1],[0,0], marker = &#39;o&#39;, markersize = 12) plt.xlim([1,1]) plt.xlabel([]) . To show/hide this cell&#39;s raw code input, click here. Text(0.5, 0, &#39;[]&#39;) . This vector field indeed gives us a qualitative picture of the dynamics. It does not tell us how fast the dynamics will occur in each region, but it indicates what the tendency is. We have coded the fixed points according to their stability; this may be calculated using the derivative evaluated at the fixed point, $f&#39;(x^*)$, since this derivative controls the behaviour of nearby initial conditions $x^* + delta x$. . Bifurcations . Now suppose that there is a parameter $ mu$ in the system that can be varied. For each value of $ mu$ we have a different ODE . $$ dot{x} = f_ mu(x).$$ For example, $$ dot{x} = mu + x^2.$$ Let&#39;s draw the state space for each different value of $ mu$: . tag = HTML(&#39;&#39;&#39;&lt;script&gt; code_show=true; function code_toggle() { if (code_show){ $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).hide(); } else { $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).show(); } code_show = !code_show } $( document ).ready(code_toggle); &lt;/script&gt; To show/hide this cell&#39;s raw code input, click &lt;a href=&quot;javascript:code_toggle()&quot;&gt;here&lt;/a&gt;.&#39;&#39;&#39;) display(tag) def xdot(mu, x): return mu + x**2 t = np.arange(-5, 5, 0.001) def plot_func(initial_condition): plt.figure(figsize=(8,8)) a = xdot(mu = initial_condition, x = t) plt.plot(t, a) plt.xlabel(&quot;t&quot;) plt.ylabel(&quot;x(t)&quot;) plt.xlim([-5,5]) plt.ylim(-2, 2) plt.grid() try: zero_crossings = np.where(np.diff(np.signbit(a)))[0] plt.vlines(t[zero_crossings+1], ymin=-2,ymax=2) for arrows in np.arange(-5,t[zero_crossings[0]],0.5): plt.arrow(arrows, 0, 0.25, 0,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.05, color =&quot;blue&quot;) for arrows in np.arange(t[zero_crossings[0]]+0.5, t[zero_crossings[1]],0.5): plt.arrow(arrows, 0, -0.25, 0,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.05, color = &quot;blue&quot;) for arrows in np.arange(t[zero_crossings[1]], 5,0.5): plt.arrow(arrows, 0, +0.25, 0,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.05, color =&quot;red&quot;) plt.plot([t[zero_crossings],t[zero_crossings]],[0,0], marker=&#39;o&#39;, markersize = 12) except: for arrows in np.arange(-5,5,0.5): plt.arrow(arrows, 0, 0.25, 0,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.05, color =&quot;blue&quot;) plt.show() interact(plot_func, initial_condition = widgets.FloatSlider(value = -1, min = -2, max = 2, step = 0.1)) . &lt;function __main__.plot_func(initial_condition)&gt; . Now let&#39;s collect all the vector fields into a single plot. We rotate the vector field to now be vertical, thinking of the dynamics of $x$ as occurring along the vertical direction. The horizontal axis now represents the different possible values of the parameter $ mu$: . tag = HTML(&#39;&#39;&#39;&lt;script&gt; code_show=true; function code_toggle() { if (code_show){ $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).hide(); } else { $(&#39;div.cell.code_cell.rendered.selected div.input&#39;).show(); } code_show = !code_show } $( document ).ready(code_toggle); &lt;/script&gt; To show/hide this cell&#39;s raw code input, click &lt;a href=&quot;javascript:code_toggle()&quot;&gt;here&lt;/a&gt;.&#39;&#39;&#39;) display(tag) saddle_points0 = np.array([]) saddle_points1 = np.array([]) stepsize = 0.1 for mu in np.arange(-2, 2, stepsize): a = xdot(mu = mu, x = t) zero_crossings = np.where(np.diff(np.signbit(a)))[0] if zero_crossings.size &gt; 1: saddle_points0 = np.append(saddle_points0, t[zero_crossings[0]]) saddle_points1 = np.append(saddle_points1, t[zero_crossings[1]]) for arrows in np.arange(-5,t[zero_crossings[0]],0.25): plt.arrow(mu, arrows, 0.0, 0.1,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.025, color =&quot;blue&quot;) for arrows in np.arange(t[zero_crossings[0]], t[zero_crossings[1]],0.25): plt.arrow(mu, arrows, 0.0, -0.1,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.025, color =&quot;red&quot;) for arrows in np.arange(t[zero_crossings[1]],2,0.25): plt.arrow(mu, arrows, 0.0, 0.1,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.025, color =&quot;blue&quot;) elif zero_crossings.size == 1: saddle_points0 = np.append(saddle_points0, t[zero_crossings]) saddle_points1 = np.append(saddle_points0, np.nan) else: saddle_points0 = np.append(saddle_points0, np.nan) saddle_points1 = np.append(saddle_points1, np.nan) for arrows in np.arange(-2,2,0.25): plt.arrow(mu, arrows, 0.0, 0.1,shape=&#39;full&#39;, lw=1, length_includes_head=True, head_width=.025, color =&quot;blue&quot;) plt.ylim(-2,2) plt.xlim(-2,2) plt.scatter(np.arange(-2,2,stepsize), saddle_points0, color=&quot;green&quot;, marker=&#39;D&#39;) plt.scatter(np.arange(-2,2,stepsize), saddle_points1, color=&quot;black&quot;, marker=&#39;o&#39;) plt.ylabel(&quot;fixed points and dynamics with given $ mu$&quot;) plt.xlabel(&quot;$ mu$&quot;) . To show/hide this cell&#39;s raw code input, click here. Text(0.5, 0, &#39;$ mu$&#39;) . Now let&#39;s collect all the vector fields into a single plot. We rotate the vector field to now be vertical, thinking of the dynamics of $x$ as occurring along the vertical direction. The horizontal axis now represents the different possible values of the parameter $ mu$: . We see that at the critical value $ mu_c = 0$ there is a qualitative change in behaviour in the system: for $ mu_c &lt; 0$ there are two fixed points, whereas for $ mu_c &gt; 0$ there are no fixed points at all. In this particular ODE the two fixed points collide in a saddle--node or fold bifurcation. . Bistability and hysteresis . Now let&#39;s look at the dynamics of the following system: . $$ dot{x} = mu + x - x^3.$$ . def h(mu, x): return mu + x - x**3 . saddle_points = [] stepsize = 0.1 for mu in (np.arange(-2, 2, stepsize)): a = h(mu = mu, x = t) zero_crossings = np.where(np.diff(np.signbit(a)))[0] plt.scatter(np.ones(len(zero_crossings))*mu, t[zero_crossings], color=&quot;green&quot;, marker=&#39;D&#39;) plt.grid() plt.title(&quot;Bifurcation Diagramm&quot;) plt.ylabel(&quot;fixed points and dynamics with given $ mu$&quot;) plt.xlabel(&quot;$ mu$&quot;) plt.ylim(-2,2) plt.xlim(-2,2) . (-2.0, 2.0) . We see that there is a range of values of $ mu$ for which there are three coexisting fixed points, two stable and one unstable. Since there are two stable fixed points in which the system can remain, we say that the system is bistable. . Now that we understand what the plots mean and the dynamics, let&#39;s plot just the fixed points $x^*( mu)$ as a function of $ mu$. Such a plot is called a bifurcation diagram: . The pieces of curve are called branches. . Hysteresis . Suppose we now think about slowly varying the parameter $ mu$. If we change the parameter $ mu$ by a little, the system is no longer at a fixed point, since the position of the fixed point moves when $ mu$ changes. However, the system will theb relax by following the dynamics at the new value of $ mu$, and will rapidly converge to the new fixed point nearby. For example, starting at $ mu=-2$, the system will stay on the lower black (stable) branch until $ mu=0.4$ or so. At that point, two fixed points collide and annihilate each other! After that there is no longer a fixed point nearby. However, there is another fixed point much further up that will now attract all trajectories, so the system rapidly transitions to that fixed point. Now suppose we decrease the parameter again. The system will now track the upper branch until $ mu=-0.4$ or so, when again it will jump back down. For each parameter value $ mu$ in the interval $[-0.4, 0.4]$ there is bistability, i.e. coexistence of two fixed points with the same value of $ mu$ (together with a third, unstable fixed point that is not observable). The fact that the system tracks different stable branches depending on where we started, i.e. on the history, is known as hysteresis. &quot;&quot;&quot; . Hysteretic behaviour like this is found in many scientific and engineering contexts, including switches in biology, for example genetic switches, and in the historical dynamics of the earth&#39;s climate. &quot;&quot;&quot; . Slow--fast systems . What are we actually doing when we let the parameter $ mu$ vary? Effectively we now have a system with two equations, for example $$ dot{x} = mu + x - x^3;$$ $$ dot{ mu} = epsilon,$$ where $ mu$ varies at some slow speed $ epsilon$. On a time scale much shorter than $1 / epsilon$, the dynamics of $x$ &quot;does not know&quot; that $ mu$ is changing, so it will converge to a fixed point $x^*( mu)$ for the current value of $ mu$. [An associated term is adiabatic approximation.] However, $ mu$ does gradually change, so the value of $x$ will effectively &quot;slide along&quot; the curve $x(t) simeq x^*( mu(t))$, tracking the curve of fixed points as $ mu$ changes. Once $ mu$ reaches a critical value $ mu_c$, however, there is no longer a nearby fixed point, and the dynamics will rapidly transition to the far away alternative fixed point. If we now reverse the dynamics of $ mu$, we slide back along the upper branch. &quot;&quot;&quot; .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/12/non-linear-dynamics.html",
            "relUrl": "/jupyter/2020/11/12/non-linear-dynamics.html",
            "date": " • Nov 12, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Lecture 2, A "zero-dimensional" energy balance model of Earth's climate",
            "content": "Thanks a lot to Henri Drake for providing the lecture. . The original lecture is part of the MIT class Introduction to Computational Thinking. . This class uses the Julia programming language. The orignal code can be found under https://github.com/hdrake/simplEarth/blob/master/1_energy_balance_model.jl . import xarray as xr import numpy as np import matplotlib.pyplot as plt . 1) Background: climate physics . The simplest climate model can be conceptualized as: . change in heat content = . $+$ absorbed solar radiation (energy from the Sun&#39;s rays) . $-$ outgoing thermal radiation (i.e. blackbody cooling to space) . $+$ human-caused greenhouse effect (trapped outgoing radiation) . where each of these is interpreted as an average over the entire globe (hence &quot;zero-dimensional&quot;). . . To make this simple conceptual model quantitative, we need a mathematical formulation for each of these four processes. . 1.1 Absorbed solar radiation . At Earth&#39;s orbital distance from the Sun, the power of the Sun&#39;s rays that intercept the Earth is equal to . S = 1368 # solar insolation [W/m^2] (energy per unit time per unit area) . A small fraction . alpha = 0.3 # albedo, or planetary reflectivity [unitless] . of this incoming solar radiation is reflected back out to space (by reflective surfaces like white clouds, snow, and ice), with the remaining fraction $(1- alpha)$ being absorbed. Since the incoming solar rays are all approximately parallel this far from the Sun, the cross-sectional area of the Earth that intercepts them is just a disc of area $ pi R^{2}$. Since all of the other terms we will consider act on the entire surface area $4 pi R^{2}$ of the spherical Earth, the absorbed solar radiation per unit surface area (averaged over the entire globe) is reduced by a factor of 4. . . The absorbed solar radiation per unit area is thus . $ text{absorbed solar radiation} equiv frac{S(1- alpha)}{4}$ . def absorbed_solar_radiation(S, alpha): return (S*(1-alpha)/4) # [W/m^2] . 1.2) Outgoing thermal radiation . The outgoing thermal radiation term (or &quot;blackbody cooling to space&quot;) represents the combined effects of negative feedbacks that dampen warming, such as blackbody radiation, and positive feedbacks that amplify warming, such as the water vapor feedback. . Since these physics are too complicated to deal with here, we linearize the model by considering only the first term of a Taylor Series expansion . $$ G(T) sim G(T_0) + G^{&#39;}(T_0) (T-T_0) = G^{&#39;}(T_0)T + (G(T_0)-G^{&#39;}(T_0)T_0) $$ . around the pre-industrial equilibrium temperature . T0 = 14. # preindustrial temperature [°C] . To simplify the expression, we define: . $ A equiv G^{&#39;}(T_0)T_0 $ . $ B equiv - G^{&#39;}(T_0) text{ (the climate feedback parameter),}$ . which gives . $$ text{outgoing thermal radiation} equiv G(T) sim A - BT$$ . def outgoing_thermal_radiation(T, A, B): return A - B*T . The value of the climate feedback parameter used here, . B = -1.3 # climate feedback parameter [W/m^2/°C], . comes from a bottom-up estimate based on the best understanding of the various climate feedbacks (read more here). . Note: Since $B&lt;0$ , this tells us that the overall climate feedback is negative (i.e. stabilizing). Positivefeedbacks cause to become less negative, reducing the efficiency with which Earth cools itself by radiating thermal energy to space, and thus amplifying warming. . The value $A$ of is given by the definition of a preindustrial equilibrium, i.e. the fact that before human influence, Earth&#39;s energy budget was perfectly balanced: . absorbed solar radiation = outgoing thermal radiation . or . $ frac{S (1- alpha)}{4} equiv A - BT_0$ . By rearanging this equation, we find that the value of $A$ is given by . A = S*(1. - alpha)/4 + B*T0 # [W/m^2]. A . 221.2 . Human-caused greenhouse effect . Empirically, the greenhouse effect is known to be a logarithmic function of gaseous carbon dioxide (CO$_2$) concentrations . $$ text{Human-caused greenhouse effect} = a * ln frac{CO_2}{CO{_2}_{PI}} $$ . where . a = 5 # CO2 forcing coefficient [W/m^2] . CO2_PI = 280 # preindustrial CO2 concentration [parts per million; ppm]; . def greenhouse_effect(CO2, a=5, CO2_PI = 280): return a*np.log(CO2/CO2_PI) . co2_present = 420 co2_range = 280*2**np.linspace(-1,3,100) plt.plot(co2_range, greenhouse_effect(co2_range), color = &quot;black&quot;) plt.ylabel(&#39;Radiative forcing [$W/m^2$]&#39;) plt.xlabel(&#39;$CO_2$ concentration [ppm]&#39;) plt.plot(CO2_PI, greenhouse_effect(CO2_PI), marker=&quot;.&quot;, markersize = 20, label = &quot;pre-industrial (PI)&quot;, color = &quot;blue&quot;) plt.plot(co2_present, greenhouse_effect(co2_present), marker=&quot;.&quot;, markersize = 20, label = &quot;present day (2020)&quot;, color = &quot;red&quot;) plt.xticks([280, 280*2, 280*4, 280*8]) plt.legend(loc = 4) plt.grid() . 1.4) Change in heat content . The heat content $CT$ is determined by the temperature $T$ (in Kelvin) and the heat capacity of the climate system. While we are interested in the temperature of the atmosphere, which has a very small heat capacity, its heat is closely coupled with that of the upper ocean, which has a much larger heat capacity of . C = 51 . The change in heat content over time is thus simply given by $ frac{d(CT)}{dt}$. Since the heat capacity of sea water hardly changes with temperature, we can rewrite this in terms of the change in temperature with time as: . $$ text{change in heat content} = C frac{dT}{dt} $$ . 1.5) &quot;zero-dimensional&quot; climate model equation . Combining all of these subcomponent models, we write the governing equation of the &quot;zero-dimensional&quot; energy balance climate model as the Ordinary Differential Equation (ODE) . $$ C frac{dT}{dt} = frac{S (1- alpha)}{4} - ( A - BT_0) + a * ln frac{CO_2}{CO{_2}_{PI}} $$ . which determines the time evolution of Earth&#39;s globally-averaged surface temperature. . 2) Numerical solution method and data structures . 2.1) Discretization . The energy balance model equation above can be discretized in time as . $$ C frac{T(t+ Delta t) - T(t)}{ Delta t} = frac{S (1- alpha)}{4} - ( A - BT_0) + a * ln frac{CO_2}{CO{_2}_{PI}} $$ . Our finite difference equation, which results from a first-order truncation of the Taylor series expansion, approximates the exact ordinary differential equation above in the limit that $ Delta t rightarrow 0$. In practice, we can keep decreasing $ Delta t$ until the solution converges within a tolerable error. . Hereafter, we use the subscript $n$ to denote the $n$-th timestep, where $T_{n+1} equiv T(t_{n+1})$ denotes the temperature at the next timestep $t_{n+1} = t_n + Delta t$. . By re-arranging the equation, we can solve for the temperature at the next timestep $n+1$ based on the known temperature at the present timestep $n$: . $$ T_{n+1} = T_n + frac{ Delta t}{C} bigg[ frac{S (1- alpha)}{4} - ( A - BT_n) + a * ln frac{CO_2}{CO{_2}_{PI}} bigg] $$ . 2.2) Timestepping . More generally, we recognize this equation to be of the form: . $$ T_{n+1} = T_n + Delta t cdot text{tendency}(T_n; ...),$$ . which we implement below (don&#39;t forget to update the time as well, $t_{n+1} = t_n + Delta t$), which takes in an instance of our anticipated energy balance model EBM type as its only argument. . class ebm(): &quot;&quot;&quot; Zero order energy balance model &quot;&quot;&quot; def __init__(self, T, t, deltat, CO2): self.T = np.array(T) self.t = t self.deltat = deltat self.C = C self.a = a self.A = A self.B = B self.co2_pi = CO2_PI self.alpha = alpha self.S = S self.co2 = CO2 def tendency(self): if self.T.size == 1: return 1. / self.C * ( + absorbed_solar_radiation(alpha = self.alpha, S=self.S) - outgoing_thermal_radiation(self.T, A = self.A, B=self.B) + greenhouse_effect(self.co2(self.t), a = self.a, CO2_PI=self.co2_pi) ) else: return 1. / self.C * ( + absorbed_solar_radiation(alpha = self.alpha, S=self.S) - outgoing_thermal_radiation(self.T[-1], A = self.A, B=self.B) + greenhouse_effect(self.co2(self.t[-1]), a = self.a, CO2_PI=self.co2_pi) ) @property def timestep(self): if self.T.size == 1: self.T = np.append(self.T, self.T + self.deltat * self.tendency()) self.t = np.append(self.t, self.t + self.deltat) else: self.T = np.append(self.T, self.T[-1] + self.deltat * self.tendency()) self.t = np.append(self.t, self.t[-1] + self.deltat) . 2.4) Running simulations of the energy balance model . Let&#39;s define a function that runs an EBM simulation by timestepping forward until a given end_year. . def run_ebm(ebm, end_year): for year in range(end_year): ebm.timestep . For example, let us consider the case where CO₂ emissions increase by 1% year-over-year from the preindustrial value [CO$_2$] = $280.0$ ppm, starting at T=T₀=14°C in year t=0 and with a timestep Δt = 1 year. . def CO2_test(t): return CO2_PI ** (1 + 1/100)**t EBM = ebm(T0, t=0, deltat=1, CO2=CO2_test) . EBM.timestep . EBM.T . array([14., 14.]) . 3) Energy balance model applications . 3.1) Why was Earth&#39;s preindustrial climate so stable? . Let us consider the simple case where CO₂ concentrations remain at their pre-industrial temperatures. . def CO2_test(t): return 280 EBM = ebm(T0, 0, 1, CO2_test) . run_ebm(EBM, 200) . t0s = np.arange(0,28,2) for i in t0s: EBM = ebm(i, 0, 1, CO2_test) run_ebm(EBM, 200) plt.plot(EBM.T) plt.grid() plt.xlabel(&quot;year&quot;) plt.ylabel(&quot;temperature [°C]&quot;) . Text(0, 0.5, &#39;temperature [°C]&#39;) . This figure shows that, no matter where we start out, the overall negative feedbacks ($B&lt;0$) restore the temperature to the preindustrial equilibrum value of $T_0$ = 14.0 °C, over an exponential timescale of about 100 years. . 3.2) Historical global warming fueled by greenhouse gas emissions . Human greenhouse gas emissions have fundamentally altered Earth&#39;s energy balance, moving us away from the stable preindustrial climate of the past few thousand years. . Since human CO₂ emissions are the main driver of global warming, we expect that if we plug historical CO₂ increases into our model (&quot;forcing&quot; it), we should roughly reproduce the observed historical global warming. . The observed increase of CO2 concentrations can be fairly accurately modelled by the simple cubic formula below. . def co2_hist(t): return 280 * (1+ ((t-1850)/220)**3) . EBM = ebm(T0, 1850, 1, co2_hist) run_ebm(EBM, 170) . import pandas as pd url = &quot;https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt&quot; temp = pd.read_csv(url, header = None, skiprows=5, index_col=0, delimiter=&quot; &quot;) temp = temp + 14.15 CO2_url = &quot;https://scrippsco2.ucsd.edu/assets/data/atmospheric/stations/in_situ_co2/monthly/monthly_in_situ_co2_mlo.csv&quot; co2_data = pd.read_csv(CO2_url, header = 46,skiprows=8, index_col=0) co2_data = co2_data.iloc[4:] co2_data = pd.to_numeric(co2_data.iloc[:,5]) co2_data[co2_data&lt;= 0] = np.nan co2_data.index = pd.to_datetime(co2_data.index) co2_data = co2_data.groupby(co2_data.index.year).mean() . &lt;ipython-input-35-ad0381c77880&gt;:3: ParserWarning: Falling back to the &#39;python&#39; engine because the &#39;c&#39; engine does not support regex separators (separators &gt; 1 char and different from &#39; s+&#39; are interpreted as regex); you can avoid this warning by specifying engine=&#39;python&#39;. temp = pd.read_csv(url, header = None, . f, (ax, bx) = plt.subplots(1,2, figsize=(8,4)) ax.plot(np.arange(1850, 2020), co2_hist(np.arange(1850, 2020)), label = &quot;EBM model&quot;) ax.plot(co2_data.index, co2_data.values, label=&quot;Keeling Curve&quot;) ax.set_ylabel(&quot;$CO_2$ concentration [ppm]&quot;) ax.grid() ax.set_xlabel(&quot;Year&quot;) ax.legend() bx.plot(np.arange(1850, 2021), EBM.T, label=&quot;EBM model&quot;) temp.plot(ax = bx) bx.set_ylabel(&quot;Temperature [°C]&quot;) bx.grid() bx.legend([&quot;EBM Model&quot;, &quot;NASA Observations&quot;, &quot;NASA Obs roll. mean&quot;]) bx.set_xlabel(&quot;Year&quot;) f.tight_layout() . CO$_2$ emissions predict the trend, but what about the climate noise? . CO$_2$ emissions predict the trend, but what about the climate noise? Our model does a good job of predicting the long-term trend of increasing temperatures, but what about all of the noise in the observations? These are real signals due to natural variability of the Earth system, not artifacts due to instrumental noise. . This natural noise arises due to the turbulent and chaotic fluid dynamics of the atmosphere and ocean, which we will explore further in Lecture 4 and are illustrated below. . youtube . Now that we&#39;ve convinced ourselves that the model accurately reproduces historical warming, we can use it to project how much warming we might expect due to future CO₂ emissions. . 3.3) Best- and worst-case projections of future global warming . Consider two divergent hypothetical futures: . 1) a low-emissions world in which emissions decrease such that CO2 concentrations stay below 500 ppm by 2100 (known in climate circles as &quot;RCP2.6&quot;) and . 2) a high-emissions world in which emissions continue increasing and CO2 concentrations soar upwards of 1200 ppm (&quot;RCP8.5&quot;). . def CO2_RCP26(t): return 280 * (1+ ((t-1850)/220)**3 * np.minimum(1., np.exp(-((t-1850)-170)/100))) def CO2_RCP85(t): return 280 * (1+ ((t-1850)/220)**3 * np.maximum(1., np.exp(((t-1850)-170)/100))) . In the low-emissions scenario, the temperature increase stays below $ Delta T$ = 2 °C by 2100, while in the high-emissions scenario temperatures soar upwards of 3.5ºC above pre-industrial levels. . EBM1 = ebm(T0, 1850, 1, CO2_RCP26) EBM2 = ebm(T0, 1850, 1, CO2_RCP85) run_ebm(EBM1, 249) run_ebm(EBM2, 249) . f, (ax, bx) = plt.subplots(1,2, figsize = (8,4)) ax.plot(np.arange(1850, 2100), CO2_RCP26(np.arange(1850,2100)), color = &quot;Blue&quot;, label = &quot;RCP 2.6 low emissions&quot;) ax.plot(np.arange(1850, 2100), CO2_RCP85(np.arange(1850,2100)), color = &quot;Red&quot;, label = &quot;RCP 8.5 High emissions&quot;) ax.plot(2020, CO2_RCP26(2020), marker=&quot;.&quot;, markersize = 20, label = &quot;we are here&quot;, color = &quot;black&quot;) ax.set_ylabel(&quot;$CO_2$ concentration [ppm]&quot;) ax.legend() bx.plot(np.arange(1850, 2100), EBM1.T, color = &quot;Blue&quot;) bx.plot(np.arange(1850, 2100), EBM2.T, color = &quot;Red&quot;) bx.axhline(y = 16, label = &quot;Paris Agreement n threshold (2°C warming)&quot;, ls=&quot;--&quot;, color = &quot;black&quot;) bx.set_ylabel(&quot;Temperature [°C]&quot;) bx.plot(2020, EBM1.T[170], marker=&quot;.&quot;, markersize = 20, label = &quot;we are here&quot;, color = &quot;black&quot;) bx.legend() f.tight_layout() .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/11/energy-model.html",
            "relUrl": "/jupyter/2020/11/11/energy-model.html",
            "date": " • Nov 11, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Lecture 1, Introduction to python",
            "content": "Getting started . Introduction to Python . What are we doing during the course? . The course aims to introduce you to the first steps of data analysis . save data | organize and manipulate data | further tools for data analysis | . If you never coded before than starting with Python is perfect! Python is one of the easiest and most straight forward languages. . x = 1 . x = &quot;abcd&quot; . x as an integer and then a string? The same concept is applicable for many other different examples. Python has a minimalistic approech and follows a simple syntax. This is why source code is very easy to read. . x = 0 if x &gt; 0: statement = &quot;x is positive&quot; elif x &lt; 0: statement = &quot;x is negative&quot; else: statement = &quot;x is zero or none&quot; print(statement) . x is zero or none . x = 5 - 4 # Comments are made with a hash Raute y = &quot;Hello&quot; # Everything after the hash will be a comment if y == &quot;hallo&quot;: z = x * 2 y = y + &quot; World&quot; # This is how you combine strings! print(&quot;x :&quot;, x) # The letter x and the our variable x print(&quot;y :&quot;, y) . x : 1 y : Hello . First summary: . Indenting of the source code has a meaning! the indentation of your code organizes it into blocks within blocks within blocks. | . | the first assignment of a variable creates it we don&#39;t care if it is an integer, float or string | . | assignments of variables use =, to compare two variables we use == | also: logical operators are words (and, or, not) not symbols | . Variables and types . Variable . The value of a variable can be obtained by writing its name. . height = 1.79 weight = 68.7 weight . 68.7 . Second example: . Calculate your BMI . BMI = $ frac{weight [kg]}{size^2 [m]}$ . Exponentiation in Python is defined as . Variable ** 2 . . BMI = 60/(1.65**2) print(BMI) . 22.03856749311295 . Types . Without going into detail: . pi = 3.141516546859754674896794 days_of_week = 5 x = &#39;Hey Guys&#39; y = &quot;Also works this way ...&quot; z = True print(&#39;days_of_week: &#39;, type(days_of_week)) print(&#39;pi: &#39;, type(pi)) print(&#39;x: &#39;, type(x)) print(&#39;y: &#39;, type(y)) print(&#39;z: &#39;, type(z)) . days_of_week: &lt;class &#39;int&#39;&gt; pi: &lt;class &#39;float&#39;&gt; x: &lt;class &#39;str&#39;&gt; y: &lt;class &#39;str&#39;&gt; z: &lt;class &#39;bool&#39;&gt; . Does this really matter? Actually, no, since Python&#39;s use of variables is very intuitive. Still, keep in mind that a different variable type can lead to different behaviour: . 2 + 3 . 5 . &#39;ab&#39; + &#39;cd&#39; . &#39;abcd&#39; . a = 1 b = 5 c = a / b . What is the value of c? . print(c) . 0.2 . Lists . As opposed to int, bool etc., a list is a compound data type; you can group values together: . a = &quot;is&quot; b = &quot;nice&quot; my_list = [&quot;my&quot;, &quot;list&quot;, a, b] . After measuring the height of your family, you decide to collect some information on the house you&#39;re living in. The areas of the different parts of your house are stored in separate variables for now, as shown in the script. . List of lists . As a data scientist, you&#39;ll often be dealing with a lot of data, and it will make sense to group some of this data. . Instead of creating a flat list containing strings and floats, representing the names and areas of the rooms in your house, you can create a list of lists. The script on the right can already give you an idea. . Don&#39;t get confused here: &quot;hallway&quot; is a string, while hall is a variable that represents the float 11.25 you specified earlier. . hall = 11.25 kit = 18.0 liv = 20.0 bed = 10.75 bath = 9.50 # house information as list of lists house = [[&quot;hallway&quot;, hall], [&quot;kitchen&quot;, kit], [&quot;living room&quot;, liv]] # Print out house # Print out the type of house . Subset and conquer . Subsetting Python lists is a piece of cake. Take the code sample below, which creates a list x and then selects &quot;b&quot; from it. Remember that this is the second element, so it has index 1. You can also use negative indexing. . x = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;] x[1] x[-3] # same result! . Remember the areas list from before, containing both strings and floats? Its definition is already in the script. Can you add the correct code to do some Python subsetting? . Familiar functions . Out of the box, Python offers a bunch of built-in functions to make your life as a data scientist easier. You already know two such functions: print() and type(). You&#39;ve also used the functions str(), int(), bool() and float() to switch between data types. These are built-in functions as well. . Calling a function is easy. To get the type of 3.0 and store the output as a new variable, result, you can use the following: . result = type(3.0) . The general recipe for calling functions and saving the result to a variable is thus: . output = function_name(input) . var1 = [1, 2, 3, 4] var2 = False # Print out type of var1 print(type(var1)) # Print out length of var1 print(len(var1)) # Convert var2 to an integer: out2 int(var2) . &lt;class &#39;list&#39;&gt; 4 . 0 . Numpy . import numpy as np # List a = [1,2,3,4,5,6,7,8,9] # numpy array A = np.array([1,2,3,4,5,6,7,8,9]) print(&quot;This is a list: {} and looks like n {}&quot;.format(type(a), a)) print(&quot;This is an array: {} and looks like n {}&quot;.format(type(A), A)) . This is a list: &lt;class &#39;list&#39;&gt; and looks like [1, 2, 3, 4, 5, 6, 7, 8, 9] This is an array: &lt;class &#39;numpy.ndarray&#39;&gt; and looks like [1 2 3 4 5 6 7 8 9] . Create arrays of a give length . y_ar = np.arange(0, 1, 0.1) print(&quot;Lenght of array y_ar is {}.&quot;.format(len(y_ar))) print(y_ar) x_ar = np.linspace(1, 10, 5) #creates an array of length 5 between 1 and 10 print(&quot;Lenght of array x_ar is {}.&quot;.format(len(x_ar))) print(x_ar) . Lenght of array y_ar is 10. [0. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9] Lenght of array x_ar is 5. [ 1. 3.25 5.5 7.75 10. ] . Multidimensional arrays . z_ar = np.zeros((100)) #creates an array of shape (100,) with zeros print(&quot;Shape of z_ar is {}&quot;.format(z_ar.shape)) z_ar = np.zeros((100,1)) print(&quot;Shape of z_ar is {}&quot;.format(z_ar.shape)) z_ar = np.zeros((100, 1, 3, 5)) print(&quot;Shape of z_ar is {}&quot;.format(z_ar.shape)) z_ar[0, 0, 1, 2] . Shape of z_ar is (100,) Shape of z_ar is (100, 1) Shape of z_ar is (100, 1, 3, 5) . 0.0 . .shape gives you the dimensions of the array, while len() only returns the lenght of the first dimension! . import time a = [1, 2, 3] b = [3, 4, 5] print(a + b) c = [] for count in range(len(a)): c.append(a[count] + b [count]) print(c) . [1, 2, 3, 3, 4, 5] [4, 6, 8] . a = np.array([1., 2., 3.]) b = np.array([3., 4., 5.]) print(a + b) . [4. 6. 8.] . Why do we do this? . a = [1 for x in range(1000000)] b = [1 for x in range(1000000)] time1 = time.time() c = [] for count in range(len(a)): c.append(a[count] + b[count]) time2 = time.time() print(&#39;This took %0.3f ms&#39; % ((time2-time1)*1000.0)) a = np.ones(1000000) b = np.ones(1000000) time1 = time.time() c = a + b time2 = time.time() print(&#39;This took %0.3f ms&#39; % ((time2-time1)*1000.0)) . This took 190.984 ms This took 22.381 ms . Useful functions: . z = np.random.rand(10, 20, 30) print(z.shape) . (10, 20, 30) . z_mean = np.nanmean(z, axis = 1) print(z_mean.shape) z_mean = np.nanmean(z, axis = (1,2)) print(z_mean.shape) z_mean_sqrt = np.sqrt(z_mean) # square root . (10, 30) (10,) . masked arrays . z = np.random.rand(20, 20) mask = (z &lt; 0.5) print(mask) print(mask.shape) . [[False True True True False True False False False True True False True False True True True True False True] [False True False False True True False False False True True True False True True False True False True False] [ True False False False True False True True True True False True True True True True False True False True] [ True True True False False True False False False True True True False False True True True False True True] [ True True True False True False True True True False True True False True True False False True True True] [ True True True True False True False False True True True True False False True False False False False False] [False False True True True False False True False True False True False True False False False False True False] [ True False True True False False True True True True False False False False True False False False False True] [False True False False True True False True False False False True True True True False True False False False] [False False False False False False False True False True False False False False True False True False False False] [ True True True False False True True False False True False False False False False False True True True True] [ True False False True False False True False True True False False True False True False True False True True] [ True False False False False True True True True False False True False False False True False False True True] [False False True False True True False False False False True False False True True False False False False True] [ True False False False True True False True True True True True False False True True True True True False] [ True True False True True True True False False True False True True True False True False False False True] [ True True False True False True True False False True False True False True True True False True True True] [False False False True True False False False False True False False True True True False True True False False] [ True True False True False False True False True False False False True True False True False True True True] [False True True False True True True True True True True True True False False False True False False True]] (20, 20) . z_masked = np.ma.asarray(z) z_masked.mask = mask print(z_masked) . [[0.5978333056634115 -- -- -- 0.9152501522824146 -- 0.7916287392512159 0.7928566155462591 0.8296902624971217 -- -- 0.6852856720906341 -- 0.8341387004206775 -- -- -- -- 0.8094767459639305 --] [0.5284749786477574 -- 0.9692448492945632 0.5068885461498903 -- -- 0.9982033801792924 0.6446449735549381 0.8982505405882799 -- -- -- 0.8202508382388177 -- -- 0.5371093964909518 -- 0.8842660402220104 -- 0.7842271087394086] [-- 0.7127430422749206 0.6130407399050007 0.5077916555865725 -- 0.7123875777621683 -- -- -- -- 0.9257742767168362 -- -- -- -- -- 0.7893866060110892 -- 0.8219722516595986 --] [-- -- -- 0.9511395789894707 0.5064100784906008 -- 0.7628344896078808 0.6899599400205454 0.8545623119356198 -- -- -- 0.8966124582837998 0.6751098614621039 -- -- -- 0.5599346115350089 -- --] [-- -- -- 0.6866780820516447 -- 0.9612539063235854 -- -- -- 0.7549588003015492 -- -- 0.9815310576382813 -- -- 0.6690227959138888 0.8163426414073014 -- -- --] [-- -- -- -- 0.951122571524875 -- 0.7526234074825154 0.7814204821387767 -- -- -- -- 0.8856517620807556 0.6104034095672278 -- 0.9108432333505353 0.778538501878837 0.694587660065455 0.6362099310807572 0.5446806033519845] [0.765291341112839 0.5678977599825668 -- -- -- 0.7416145588543542 0.8235160533214866 -- 0.7707774894079225 -- 0.5023683957476383 -- 0.7408438608220037 -- 0.5296017698924947 0.5082239359783319 0.6419438019001998 0.7117301668945667 -- 0.657189876311379] [-- 0.8048803074817702 -- -- 0.5607659768586147 0.529414773085168 -- -- -- -- 0.9709522752112307 0.7176384967060485 0.6245701461766041 0.9152999699249196 -- 0.6950911056628933 0.6962333701452088 0.5117383305673276 0.6562077032544125 --] [0.7180394373263428 -- 0.9327420457969964 0.7313254081696123 -- -- 0.7834917208433687 -- 0.6564836814993806 0.9486566338745831 0.9503006501814885 -- -- -- -- 0.5000568267253331 -- 0.6698741053113492 0.5467225068483047 0.8331538309312719] [0.5215265735569622 0.8640238404698893 0.6408010961069202 0.5536938469380971 0.5200815875468717 0.8826848235280155 0.9053227732031718 -- 0.5533691730783306 -- 0.9810387471501621 0.8078583036076045 0.8484515454120168 0.6874302490110933 -- 0.8639022626997208 -- 0.8799500204693254 0.8718127716771297 0.8204912819617214] [-- -- -- 0.5795894406941741 0.9565448187520345 -- -- 0.7272968720111568 0.7831777859857665 -- 0.7436871646664872 0.8611617101928444 0.676023394786886 0.7450227896716436 0.9882858446251811 0.8853471456826659 -- -- -- --] [-- 0.6576507974124693 0.7491771982051983 -- 0.8574944676437715 0.9019680472758415 -- 0.6549695482515835 -- -- 0.520695721334124 0.6362144569619924 -- 0.7534416008072654 -- 0.6885848590222653 -- 0.6994537759876023 -- --] [-- 0.7188077162195455 0.6465685521337263 0.5600527195230722 0.7742831918520511 -- -- -- -- 0.5660026791003127 0.9032330848387855 -- 0.8763993137345346 0.6583560687724255 0.7959412900351969 -- 0.927068976533419 0.8568755032734119 -- --] [0.7476169752648986 0.5234545373235526 -- 0.904445394920723 -- -- 0.8712697529733069 0.915977932603021 0.6225238810151054 0.9404663455028375 -- 0.9591144618102622 0.7461094856964241 -- -- 0.9377281247401308 0.5513308605251162 0.8118229198135797 0.5270742341408144 --] [-- 0.6118588359307 0.5934121449766 0.5753664230566036 -- -- 0.9152199517735821 -- -- -- -- -- 0.608783502674255 0.7120681303458005 -- -- -- -- -- 0.8641303762940244] [-- -- 0.8518217111151136 -- -- -- -- 0.9189100974288652 0.5894730895585055 -- 0.9728163707667034 -- -- -- 0.6073285465931129 -- 0.8148482194462799 0.578153245458349 0.5084431399278518 --] [-- -- 0.598156557892885 -- 0.7035021684172477 -- -- 0.5334056944093172 0.905543047854529 -- 0.9522679680242473 -- 0.9378657320842904 -- -- -- 0.7456640454038644 -- -- --] [0.9956038986949931 0.7055672031819478 0.7235486594711124 -- -- 0.7537276307675379 0.6893951331706245 0.6175120103700737 0.9253538077205439 -- 0.7468392921370716 0.656673742458098 -- -- -- 0.5871707737184049 -- -- 0.6037769628317056 0.7816692644108565] [-- -- 0.6330044771323631 -- 0.8888459905368238 0.6809502172023364 -- 0.7768491453561011 -- 0.7901265574453287 0.6231098759671369 0.5124489616644249 -- -- 0.8968796664387609 -- 0.6682602708851448 -- -- --] [0.8033092843471001 -- -- 0.5285349139414175 -- -- -- -- -- -- -- -- -- 0.9578748973473007 0.7048769839177969 0.5168159767357904 -- 0.7133451231643838 0.5898115526109324 --]] . import matplotlib.pyplot as plt . plt.pcolor(z) . &lt;matplotlib.collections.PolyCollection at 0x7f6de7eb0d90&gt; . plt.pcolor(z_masked) . &lt;matplotlib.collections.PolyCollection at 0x7f6de86946a0&gt; . Functions . def multiply_constant(x, constant = 5): return x * constant print(multiply_constant(5)) print(multiply_constant(5, 3)) print(multiply_constant(x = 5, constant = 3)) print(multiply_constant(a, constant = 2.5)) . 25 15 15 [2.5 2.5 2.5 ... 2.5 2.5 2.5] . Data visualization . 1D Plot . import numpy as np import matplotlib.pyplot as plt import pandas as pd x = np.arange(0,300) # Numbers from 0 to 30 (30 not included) y = np.sin(np.arange(0,300)) + np.random.normal(0,5,300) # Create sinus ##signal and add noise dataFrame = pd.DataFrame({&#39;Intervals&#39;: x, &#39;values&#39;: y}) rolling_mean = dataFrame[&#39;values&#39;].rolling(10, min_periods=1, center=True).mean() plt.plot(x,y,label=&#39;Kurve&#39;, alpha=0.5) plt.plot(x, rolling_mean.values, label = &#39;Rolling Mean&#39;) plt.title(&#39;Sinus + Random&#39;) plt.xlabel(&#39;Interval&#39;) plt.ylabel(&#39;Values&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f6e101bdd60&gt; . 2D Plots . z = np.random.rand(20,20) levels = np.linspace(0, 1, 10) f, ax = plt.subplots(1) im = ax.pcolor(z) #im = ax.contourf(z, levels = levels) #ax.contour(z) ax.set_title(&#39;Random Noise from 0 - 1&#39;) f.colorbar(im) . &lt;matplotlib.colorbar.Colorbar at 0x7f6de59b43a0&gt; . netCDF4-files . import xarray as xr url = &quot;https://ds.nccs.nasa.gov/thredds/dodsC/CMIP5/ESGF/GISS/rcp45/E2-R_rcp45_r6i1p3_day/tos_day_GISS-E2-R_rcp45_r6i1p3_20910101-21001231.nc&quot; ds = xr.open_dataset(url) . ds.isel(time = 1) . Show/Hide data repr . . . Show/Hide attributes . . . . xarray.DatasetDimensions:bnds: 2 | lat: 90 | lon: 144 | . | Coordinates: (3)time()object2091-01-02 12:00:00bounds :time_bndsaxis :Tlong_name :timestandard_name :timearray(cftime.DatetimeNoLeap(2091-01-02 12:00:00), dtype=object) . | lat(lat)float64-89.0 -87.0 -85.0 ... 87.0 89.0bounds :lat_bndsunits :degrees_northaxis :Ylong_name :latitudestandard_name :latitudearray([-89., -87., -85., -83., -81., -79., -77., -75., -73., -71., -69., -67., -65., -63., -61., -59., -57., -55., -53., -51., -49., -47., -45., -43., -41., -39., -37., -35., -33., -31., -29., -27., -25., -23., -21., -19., -17., -15., -13., -11., -9., -7., -5., -3., -1., 1., 3., 5., 7., 9., 11., 13., 15., 17., 19., 21., 23., 25., 27., 29., 31., 33., 35., 37., 39., 41., 43., 45., 47., 49., 51., 53., 55., 57., 59., 61., 63., 65., 67., 69., 71., 73., 75., 77., 79., 81., 83., 85., 87., 89.]) . | lon(lon)float641.25 3.75 6.25 ... 356.2 358.8bounds :lon_bndsunits :degrees_eastaxis :Xlong_name :longitudestandard_name :longitudearray([ 1.25, 3.75, 6.25, 8.75, 11.25, 13.75, 16.25, 18.75, 21.25, 23.75, 26.25, 28.75, 31.25, 33.75, 36.25, 38.75, 41.25, 43.75, 46.25, 48.75, 51.25, 53.75, 56.25, 58.75, 61.25, 63.75, 66.25, 68.75, 71.25, 73.75, 76.25, 78.75, 81.25, 83.75, 86.25, 88.75, 91.25, 93.75, 96.25, 98.75, 101.25, 103.75, 106.25, 108.75, 111.25, 113.75, 116.25, 118.75, 121.25, 123.75, 126.25, 128.75, 131.25, 133.75, 136.25, 138.75, 141.25, 143.75, 146.25, 148.75, 151.25, 153.75, 156.25, 158.75, 161.25, 163.75, 166.25, 168.75, 171.25, 173.75, 176.25, 178.75, 181.25, 183.75, 186.25, 188.75, 191.25, 193.75, 196.25, 198.75, 201.25, 203.75, 206.25, 208.75, 211.25, 213.75, 216.25, 218.75, 221.25, 223.75, 226.25, 228.75, 231.25, 233.75, 236.25, 238.75, 241.25, 243.75, 246.25, 248.75, 251.25, 253.75, 256.25, 258.75, 261.25, 263.75, 266.25, 268.75, 271.25, 273.75, 276.25, 278.75, 281.25, 283.75, 286.25, 288.75, 291.25, 293.75, 296.25, 298.75, 301.25, 303.75, 306.25, 308.75, 311.25, 313.75, 316.25, 318.75, 321.25, 323.75, 326.25, 328.75, 331.25, 333.75, 336.25, 338.75, 341.25, 343.75, 346.25, 348.75, 351.25, 353.75, 356.25, 358.75]) . | . | Data variables: (4)time_bnds(bnds)object...array([cftime.DatetimeNoLeap(2091-01-02 00:00:00), cftime.DatetimeNoLeap(2091-01-03 00:00:00)], dtype=object) . | lat_bnds(lat, bnds)float64...array([[-90., -88.], [-88., -86.], [-86., -84.], [-84., -82.], [-82., -80.], [-80., -78.], [-78., -76.], [-76., -74.], [-74., -72.], [-72., -70.], [-70., -68.], [-68., -66.], [-66., -64.], [-64., -62.], [-62., -60.], [-60., -58.], [-58., -56.], [-56., -54.], [-54., -52.], [-52., -50.], [-50., -48.], [-48., -46.], [-46., -44.], [-44., -42.], [-42., -40.], [-40., -38.], [-38., -36.], [-36., -34.], [-34., -32.], [-32., -30.], [-30., -28.], [-28., -26.], [-26., -24.], [-24., -22.], [-22., -20.], [-20., -18.], [-18., -16.], [-16., -14.], [-14., -12.], [-12., -10.], [-10., -8.], [ -8., -6.], [ -6., -4.], [ -4., -2.], [ -2., 0.], [ 0., 2.], [ 2., 4.], [ 4., 6.], [ 6., 8.], [ 8., 10.], [ 10., 12.], [ 12., 14.], [ 14., 16.], [ 16., 18.], [ 18., 20.], [ 20., 22.], [ 22., 24.], [ 24., 26.], [ 26., 28.], [ 28., 30.], [ 30., 32.], [ 32., 34.], [ 34., 36.], [ 36., 38.], [ 38., 40.], [ 40., 42.], [ 42., 44.], [ 44., 46.], [ 46., 48.], [ 48., 50.], [ 50., 52.], [ 52., 54.], [ 54., 56.], [ 56., 58.], [ 58., 60.], [ 60., 62.], [ 62., 64.], [ 64., 66.], [ 66., 68.], [ 68., 70.], [ 70., 72.], [ 72., 74.], [ 74., 76.], [ 76., 78.], [ 78., 80.], [ 80., 82.], [ 82., 84.], [ 84., 86.], [ 86., 88.], [ 88., 90.]]) . | lon_bnds(lon, bnds)float64...array([[ 0. , 2.5], [ 2.5, 5. ], [ 5. , 7.5], ..., [352.5, 355. ], [355. , 357.5], [357.5, 360. ]]) . | tos(lat, lon)float32...standard_name :surface_temperaturelong_name :Sea Surface Temperaturecomment :temperature of liquid ocean. Note that the correct standard_name for this variable is &quot;&quot;sea_surface_temperature&quot;&quot;, not &quot;&quot;surface_temperature&quot;&quot;, but this was discovered too late to correct. To maintain consistency across CMIP5 models, the wrong standard_name will continue to be used.units :Koriginal_name :dummycell_methods :time: meancell_measures :area: areacellohistory :2012-09-27T15:35:07Z altered by CMOR: replaced missing value flag (-1e+30) with standard missing value (1e+20).associated_files :baseURL: http://cmip-pcmdi.llnl.gov/CMIP5/dataLocation gridspecFile: gridspec_ocean_fx_GISS-E2-R_rcp45_r0i0p0.nc areacello: areacello_fx_GISS-E2-R_rcp45_r0i0p0.ncarray([[ nan, nan, nan, ..., nan, nan, nan], [ nan, nan, nan, ..., nan, nan, nan], [ nan, nan, nan, ..., nan, nan, nan], ..., [271.45233, 271.45172, 271.49725, ..., 271.50067, 271.48697, 271.47012], [271.5155 , 271.50873, 271.50183, ..., 271.53275, 271.52777, 271.5219 ], [271.56015, 271.56015, 271.56015, ..., 271.56015, 271.56015, 271.56015]], dtype=float32) . | . | Attributes: (28)institution :NASA/GISS (Goddard Institute for Space Studies) New York, NYinstitute_id :NASA-GISSexperiment_id :rcp45source :GISS-E2-R-E134TcadiRCP45fF40oQ32 Atmosphere: GISS-E2; Ocean: Rmodel_id :GISS-E2-Rforcing :GHG, LU, Sl, Vl, BC, OC, SA, Oz (also includes orbital change - BC on snow - Nitrate aerosols - interactive CH4)parent_experiment_id :historicalparent_experiment_rip :r6i1p3branch_time :2006.0contact :Kenneth Lo (cdkkl@giss.nasa.gov)references :http://data.giss.nasa.gov/modelE/ar5initialization_method :1physics_version :3tracking_id :b2041a15-ef72-4217-914e-fbbb361a5f72product :outputexperiment :RCP4.5frequency :daycreation_date :2012-09-27T15:35:07Zhistory :2012-09-27T15:35:07Z CMOR rewrote data to comply with CF standards and CMIP5 requirements.Conventions :CF-1.4project_id :CMIP5table_id :Table day (27 April 2011) 86d1558d99b6ed1e7a886ab3fd717b58title :GISS-E2-R model output prepared for CMIP5 RCP4.5parent_experiment :historicalmodeling_realm :oceanrealization :6cmor_version :2.5.7DODS_EXTRA.Unlimited_Dimension :time | . ds.isel(time = 1).tos.plot() . &lt;matplotlib.collections.QuadMesh at 0x7f6de295a4f0&gt; . tmp = ds.sel(lon = slice(150,200)).isel(time = slice(1,100)).tos.mean([&quot;lon&quot;,&quot;lat&quot;]) . tmp.plot() . [&lt;matplotlib.lines.Line2D at 0x7f6de2770310&gt;] . tmp.rolling(time = 10, min_periods =1).mean().plot() . [&lt;matplotlib.lines.Line2D at 0x7f6de281cc10&gt;] .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/09/introduction_to_python.html",
            "relUrl": "/jupyter/2020/11/09/introduction_to_python.html",
            "date": " • Nov 9, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Red noise",
            "content": "Hasselmann (as explained by Dommenget and Latif, 2000) . Hasselmann (1976) attempts to explain the mechanism of natural climate variabilty by dividing the climate system into a fast system and a slow system. The fast system could be the atmosphere, represented as white noise. The slower component is the ocean and is explained by the integration of white noise (AR-1). In this picture the ocean is merely a passive part of the climate system, which amplifies long-term variability, due to its large heat capacity, but dynamical processes in the ocean are not considered. . The resulting stochastic model of the SST variability is described by an autoregressive process of the first order, which is the simplest statistical model that can be applied to a stationary process. The stochastic climate model by Hasselmann is tehrefore often chosen as the null hypothesis of SST variability. . Slab ocean-atmosphere models can be regarded as a numerical realization of the null hypothesis (AR(1)-process) of Hasselmann&#39;s stochastic climate model. . The null hypothesis of SST variability in the midlatitudes, described by Hasselmann&#39;s stochastic climate model, assumes that the SST variability is well described by the integration of the atmospheric heat flux with the heat capacity of the ocean&#39;s mixed layer. . $ frac{d SST}{dT} = frac{1}{C_p rho_w d_{mix}}* F + Delta T_c$ . $C_p$ = specifc heat of sea water . $ rho_w$ = density of sea water . $d_{mix}$ = depth of mixed layer . $F$ = net atmospheric heat flux . $ Delta T_c$ = climatology temperature correction . The only free parameter in this eqaution is the mixed layer depth, which was chosen to be 50 meters for all points. This value is roughly the global mean vlaue for the mixed layer depth as was determinded from the observations by Levitus (1982). . Redness of the SST anomalies . The standard deviation of the SST anoamlies do not aloine describe the large-scale character of the SST varaiblity. An important feature of the SSt variability is the increase of the variance in the SST power spectra with period, which is the so called redness of the spectra. If the SST anomalies follow an AR(1)-process than the redness can be estimated by the lag-1 correlation. . $C( omega) = frac{ sigma^2}{(1- alpha)^2+ omega^2}$ . $ sigma$ = standard deviation . $ omega$ = frequency . $ alpha$ = lag-1 correlation based on monthly mean time series . The increase of $C( omega)$ is only a function of $ alpha$, hence the redness $Q_{red}$ can be defined as . $Q_{red}$ = $ frac{1}{(1- alpha)^2}$ . Conclusions . fully coupled models are signifcantly different in terms of large-scale features of the SST variability than slab ocean models | only slab ocean models can be regarded as an AR(1) process | The diference between the AR(1)-process and the SST spectra in the simulations with fully dynamical ocean models is characterized by a slower increase of the SST variance from the shorter time periods to the longer time periods, which leads to increased variance of the SST on the seasonal and the decadal timescale relative to the fitted AR(1)-process. AMO and AMOC. . Simple red noise null hypothesis . c1 = 1 c2 = 0.86 c3 = 0.01 f, ax = plt.subplots(3, figsize = (12,4)) ax = ax.ravel() for realisation in range(0,3): white_noise_sequence = np.random.normal(0, 1, 1000) red_noise_sequence1 = np.zeros((len(white_noise_sequence))) red_noise_sequence2 = np.zeros((len(white_noise_sequence))) red_noise_sequence3 = np.zeros((len(white_noise_sequence))) for i in range(1, len(white_noise_sequence)): red_noise_sequence1[i] = c1 * red_noise_sequence1[i-1] + white_noise_sequence[i] red_noise_sequence2[i] = c2 * red_noise_sequence2[i-1] + white_noise_sequence[i] red_noise_sequence3[i] = c3 * red_noise_sequence3[i-1] + white_noise_sequence[i] ax[0].plot(red_noise_sequence1) ax[1].plot(red_noise_sequence2) ax[2].plot(red_noise_sequence3) .",
            "url": "https://florianboergel.github.io/personal_blog/jupyter/2020/11/05/red_noise_binder.html",
            "relUrl": "/jupyter/2020/11/05/red_noise_binder.html",
            "date": " • Nov 5, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Main site florianboergel.github.io [^1]. . On this side, you can find some code and lecture examples. .",
          "url": "https://florianboergel.github.io/personal_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://florianboergel.github.io/personal_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}